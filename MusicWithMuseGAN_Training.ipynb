{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MusicWithMuseGAN_Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1RH5v-sj2WSCUAArlwSaf_SO3-cigKDYa",
      "authorship_tag": "ABX9TyNA/rJdu/bEek6naboEEq59",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubham1m/MusicGeneration/blob/main/MusicWithMuseGAN_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clJBNkQTWb3A",
        "outputId": "24f08c79-74db-4b35-f876-0472924fdb49"
      },
      "source": [
        "!pip install music21==5.3.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting music21==5.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/db/317c21f4b5b970c3bfb5ff321e333059faf775621ae6433abcd4c68c69db/music21-5.3.0.tar.gz (18.0MB)\n",
            "\u001b[K     |████████████████████████████████| 18.0MB 1.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: music21\n",
            "  Building wheel for music21 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for music21: filename=music21-5.3.0-cp37-none-any.whl size=21291740 sha256=b4adde902df097f8513fc5ca2a36744124e12f7fbfe5d1a93583376f9fb63900\n",
            "  Stored in directory: /root/.cache/pip/wheels/53/8b/a6/be1921c60a68f0bea31c6b6a0a7b125badd61294d6a694407f\n",
            "Successfully built music21\n",
            "Installing collected packages: music21\n",
            "  Found existing installation: music21 5.5.0\n",
            "    Uninstalling music21-5.5.0:\n",
            "      Successfully uninstalled music21-5.5.0\n",
            "Successfully installed music21-5.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifmdYDh3WffQ",
        "outputId": "1e8efb0f-5bf1-4058-bb33-5631f4d9a201"
      },
      "source": [
        "# enables music21 to render images of musical notes\n",
        "print('installing lilypond...')\n",
        "!apt-get install lilypond #> /dev/null\n",
        "\n",
        "# converts midi files to wav files into order to play them\n",
        "print('installing fluidsynth...')\n",
        "!apt-get install fluidsynth #> /dev/null\n",
        "!cp /usr/share/sounds/sf2/FluidR3_GM.sf2 ./font.sf2\n",
        "\n",
        "print('done!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "installing lilypond...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  fonts-droid-fallback fonts-lmodern fonts-noto-mono ghostscript gsfonts\n",
            "  libauthen-sasl-perl libcupsfilters1 libcupsimage2 libdata-dump-perl\n",
            "  libencode-locale-perl libfile-listing-perl libfont-afm-perl libgs9\n",
            "  libgs9-common libhtml-form-perl libhtml-format-perl libhtml-parser-perl\n",
            "  libhtml-tagset-perl libhtml-tree-perl libhttp-cookies-perl\n",
            "  libhttp-daemon-perl libhttp-date-perl libhttp-message-perl\n",
            "  libhttp-negotiate-perl libijs-0.35 libio-html-perl libio-socket-ssl-perl\n",
            "  libjbig2dec0 libkpathsea6 liblwp-mediatypes-perl liblwp-protocol-https-perl\n",
            "  libmailtools-perl libnet-http-perl libnet-smtp-ssl-perl libnet-ssleay-perl\n",
            "  libpotrace0 libptexenc1 libsynctex1 libtexlua52 libtexluajit2\n",
            "  libtext-unidecode-perl libtimedate-perl libtry-tiny-perl liburi-perl\n",
            "  libwww-perl libwww-robotrules-perl libxml-libxml-perl\n",
            "  libxml-namespacesupport-perl libxml-parser-perl libxml-sax-base-perl\n",
            "  libxml-sax-expat-perl libxml-sax-perl libzzip-0-13 lilypond-data lmodern\n",
            "  netbase perl-openssl-defaults poppler-data t1utils tex-common texinfo\n",
            "  texlive-base texlive-binaries texlive-latex-base\n",
            "Suggested packages:\n",
            "  fonts-noto ghostscript-x libdigest-hmac-perl libgssapi-perl\n",
            "  libcrypt-ssleay-perl libauthen-ntlm-perl lilypond-doc poppler-utils\n",
            "  fonts-japanese-mincho | fonts-ipafont-mincho fonts-japanese-gothic\n",
            "  | fonts-ipafont-gothic fonts-arphic-ukai fonts-arphic-uming fonts-nanum\n",
            "  debhelper texlive-generic-recommended texinfo-doc-nonfree\n",
            "  texlive-fonts-recommended perl-tk xpdf-reader | pdf-viewer\n",
            "  texlive-latex-base-doc\n",
            "The following NEW packages will be installed:\n",
            "  fonts-droid-fallback fonts-lmodern fonts-noto-mono ghostscript gsfonts\n",
            "  libauthen-sasl-perl libcupsfilters1 libcupsimage2 libdata-dump-perl\n",
            "  libencode-locale-perl libfile-listing-perl libfont-afm-perl libgs9\n",
            "  libgs9-common libhtml-form-perl libhtml-format-perl libhtml-parser-perl\n",
            "  libhtml-tagset-perl libhtml-tree-perl libhttp-cookies-perl\n",
            "  libhttp-daemon-perl libhttp-date-perl libhttp-message-perl\n",
            "  libhttp-negotiate-perl libijs-0.35 libio-html-perl libio-socket-ssl-perl\n",
            "  libjbig2dec0 libkpathsea6 liblwp-mediatypes-perl liblwp-protocol-https-perl\n",
            "  libmailtools-perl libnet-http-perl libnet-smtp-ssl-perl libnet-ssleay-perl\n",
            "  libpotrace0 libptexenc1 libsynctex1 libtexlua52 libtexluajit2\n",
            "  libtext-unidecode-perl libtimedate-perl libtry-tiny-perl liburi-perl\n",
            "  libwww-perl libwww-robotrules-perl libxml-libxml-perl\n",
            "  libxml-namespacesupport-perl libxml-parser-perl libxml-sax-base-perl\n",
            "  libxml-sax-expat-perl libxml-sax-perl libzzip-0-13 lilypond lilypond-data\n",
            "  lmodern netbase perl-openssl-defaults poppler-data t1utils tex-common\n",
            "  texinfo texlive-base texlive-binaries texlive-latex-base\n",
            "0 upgraded, 65 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 63.4 MB of archives.\n",
            "After this operation, 227 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 poppler-data all 0.4.8-2 [1,479 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 tex-common all 6.09 [33.0 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 netbase all 5.4 [12.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-lmodern all 2.004.5-3 [4,551 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-noto-mono all 20171026-2 [75.5 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsimage2 amd64 2.2.7-1ubuntu2.8 [18.6 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libijs-0.35 amd64 0.35-13 [15.5 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjbig2dec0 amd64 0.13-6 [55.9 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9-common all 9.26~dfsg+0-0ubuntu0.18.04.14 [5,092 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9 amd64 9.26~dfsg+0-0ubuntu0.18.04.14 [2,265 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 ghostscript amd64 9.26~dfsg+0-0ubuntu0.18.04.14 [51.3 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 gsfonts all 1:8.11+urwcyr1.0.7~pre44-4.4 [3,120 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsfilters1 amd64 1.20.2-0ubuntu3.1 [108 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libdata-dump-perl all 1.23-1 [27.0 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 libencode-locale-perl all 1.05-1 [12.3 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtimedate-perl all 2.3000-2 [37.5 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-date-perl all 6.02-1 [10.4 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfile-listing-perl all 6.04-1 [9,774 B]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfont-afm-perl all 1.20-2 [13.2 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-tagset-perl all 3.20-3 [12.1 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/main amd64 liburi-perl all 1.73-1 [77.2 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-parser-perl amd64 3.72-3build1 [85.9 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/main amd64 libio-html-perl all 1.001-1 [14.9 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic/main amd64 liblwp-mediatypes-perl all 6.02-1 [21.7 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-message-perl all 6.14-1 [72.1 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-form-perl all 6.03-1 [23.5 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-tree-perl all 5.07-1 [200 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-format-perl all 2.12-1 [41.3 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-cookies-perl all 6.04-1 [17.2 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-daemon-perl all 6.01-1 [17.0 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-negotiate-perl all 6.00-2 [13.4 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu bionic/main amd64 perl-openssl-defaults amd64 3build1 [7,012 B]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libnet-ssleay-perl amd64 1.84-1ubuntu0.2 [283 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libio-socket-ssl-perl all 2.060-3~ubuntu18.04.1 [173 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libkpathsea6 amd64 2017.20170613.44572-8ubuntu0.1 [54.9 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu bionic/main amd64 libnet-http-perl all 6.17-1 [22.7 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtry-tiny-perl all 0.30-1 [20.5 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu bionic/main amd64 libwww-robotrules-perl all 6.01-1 [14.1 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libwww-perl all 6.31-1ubuntu0.1 [137 kB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu bionic/main amd64 liblwp-protocol-https-perl all 6.07-2 [8,284 B]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu bionic/main amd64 libnet-smtp-ssl-perl all 1.04-1 [5,948 B]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmailtools-perl all 2.18-1 [74.0 kB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpotrace0 amd64 1.14-2 [17.4 kB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libptexenc1 amd64 2017.20170613.44572-8ubuntu0.1 [34.5 kB]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libsynctex1 amd64 2017.20170613.44572-8ubuntu0.1 [41.4 kB]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libtexlua52 amd64 2017.20170613.44572-8ubuntu0.1 [91.2 kB]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libtexluajit2 amd64 2017.20170613.44572-8ubuntu0.1 [230 kB]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libtext-unidecode-perl all 1.30-1 [99.0 kB]\n",
            "Get:50 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxml-namespacesupport-perl all 1.12-1 [13.2 kB]\n",
            "Get:51 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxml-sax-base-perl all 1.09-1 [18.8 kB]\n",
            "Get:52 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxml-sax-perl all 0.99+dfsg-2ubuntu1 [64.6 kB]\n",
            "Get:53 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxml-libxml-perl amd64 2.0128+dfsg-5 [316 kB]\n",
            "Get:54 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxml-parser-perl amd64 2.44-2build3 [199 kB]\n",
            "Get:55 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxml-sax-expat-perl all 0.40-2 [11.5 kB]\n",
            "Get:56 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libzzip-0-13 amd64 0.13.62-3.1ubuntu0.18.04.1 [26.0 kB]\n",
            "Get:57 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texinfo amd64 6.5.0.dfsg.1-2 [752 kB]\n",
            "Get:58 http://archive.ubuntu.com/ubuntu bionic/main amd64 t1utils amd64 1.41-2 [56.0 kB]\n",
            "Get:59 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 texlive-binaries amd64 2017.20170613.44572-8ubuntu0.1 [8,179 kB]\n",
            "Get:60 http://archive.ubuntu.com/ubuntu bionic/universe amd64 lilypond-data all 2.18.2-12build1 [1,799 kB]\n",
            "Get:61 http://archive.ubuntu.com/ubuntu bionic/universe amd64 lilypond amd64 2.18.2-12build1 [1,928 kB]\n",
            "Get:62 http://archive.ubuntu.com/ubuntu bionic/main amd64 lmodern all 2.004.5-3 [9,631 kB]\n",
            "Get:63 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-base all 2017.20180305-1 [18.7 MB]\n",
            "Get:64 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-latex-base all 2017.20180305-1 [951 kB]\n",
            "Get:65 http://archive.ubuntu.com/ubuntu bionic/main amd64 libauthen-sasl-perl all 2.1600-1 [48.7 kB]\n",
            "Fetched 63.4 MB in 4s (17.7 MB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package fonts-droid-fallback.\n",
            "(Reading database ... 160706 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1_all.deb ...\n",
            "Unpacking fonts-droid-fallback (1:6.0.1r16-1.1) ...\n",
            "Selecting previously unselected package poppler-data.\n",
            "Preparing to unpack .../01-poppler-data_0.4.8-2_all.deb ...\n",
            "Unpacking poppler-data (0.4.8-2) ...\n",
            "Selecting previously unselected package tex-common.\n",
            "Preparing to unpack .../02-tex-common_6.09_all.deb ...\n",
            "Unpacking tex-common (6.09) ...\n",
            "Selecting previously unselected package netbase.\n",
            "Preparing to unpack .../03-netbase_5.4_all.deb ...\n",
            "Unpacking netbase (5.4) ...\n",
            "Selecting previously unselected package fonts-lmodern.\n",
            "Preparing to unpack .../04-fonts-lmodern_2.004.5-3_all.deb ...\n",
            "Unpacking fonts-lmodern (2.004.5-3) ...\n",
            "Selecting previously unselected package fonts-noto-mono.\n",
            "Preparing to unpack .../05-fonts-noto-mono_20171026-2_all.deb ...\n",
            "Unpacking fonts-noto-mono (20171026-2) ...\n",
            "Selecting previously unselected package libcupsimage2:amd64.\n",
            "Preparing to unpack .../06-libcupsimage2_2.2.7-1ubuntu2.8_amd64.deb ...\n",
            "Unpacking libcupsimage2:amd64 (2.2.7-1ubuntu2.8) ...\n",
            "Selecting previously unselected package libijs-0.35:amd64.\n",
            "Preparing to unpack .../07-libijs-0.35_0.35-13_amd64.deb ...\n",
            "Unpacking libijs-0.35:amd64 (0.35-13) ...\n",
            "Selecting previously unselected package libjbig2dec0:amd64.\n",
            "Preparing to unpack .../08-libjbig2dec0_0.13-6_amd64.deb ...\n",
            "Unpacking libjbig2dec0:amd64 (0.13-6) ...\n",
            "Selecting previously unselected package libgs9-common.\n",
            "Preparing to unpack .../09-libgs9-common_9.26~dfsg+0-0ubuntu0.18.04.14_all.deb ...\n",
            "Unpacking libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Selecting previously unselected package libgs9:amd64.\n",
            "Preparing to unpack .../10-libgs9_9.26~dfsg+0-0ubuntu0.18.04.14_amd64.deb ...\n",
            "Unpacking libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Selecting previously unselected package ghostscript.\n",
            "Preparing to unpack .../11-ghostscript_9.26~dfsg+0-0ubuntu0.18.04.14_amd64.deb ...\n",
            "Unpacking ghostscript (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Selecting previously unselected package gsfonts.\n",
            "Preparing to unpack .../12-gsfonts_1%3a8.11+urwcyr1.0.7~pre44-4.4_all.deb ...\n",
            "Unpacking gsfonts (1:8.11+urwcyr1.0.7~pre44-4.4) ...\n",
            "Selecting previously unselected package libcupsfilters1:amd64.\n",
            "Preparing to unpack .../13-libcupsfilters1_1.20.2-0ubuntu3.1_amd64.deb ...\n",
            "Unpacking libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n",
            "Selecting previously unselected package libdata-dump-perl.\n",
            "Preparing to unpack .../14-libdata-dump-perl_1.23-1_all.deb ...\n",
            "Unpacking libdata-dump-perl (1.23-1) ...\n",
            "Selecting previously unselected package libencode-locale-perl.\n",
            "Preparing to unpack .../15-libencode-locale-perl_1.05-1_all.deb ...\n",
            "Unpacking libencode-locale-perl (1.05-1) ...\n",
            "Selecting previously unselected package libtimedate-perl.\n",
            "Preparing to unpack .../16-libtimedate-perl_2.3000-2_all.deb ...\n",
            "Unpacking libtimedate-perl (2.3000-2) ...\n",
            "Selecting previously unselected package libhttp-date-perl.\n",
            "Preparing to unpack .../17-libhttp-date-perl_6.02-1_all.deb ...\n",
            "Unpacking libhttp-date-perl (6.02-1) ...\n",
            "Selecting previously unselected package libfile-listing-perl.\n",
            "Preparing to unpack .../18-libfile-listing-perl_6.04-1_all.deb ...\n",
            "Unpacking libfile-listing-perl (6.04-1) ...\n",
            "Selecting previously unselected package libfont-afm-perl.\n",
            "Preparing to unpack .../19-libfont-afm-perl_1.20-2_all.deb ...\n",
            "Unpacking libfont-afm-perl (1.20-2) ...\n",
            "Selecting previously unselected package libhtml-tagset-perl.\n",
            "Preparing to unpack .../20-libhtml-tagset-perl_3.20-3_all.deb ...\n",
            "Unpacking libhtml-tagset-perl (3.20-3) ...\n",
            "Selecting previously unselected package liburi-perl.\n",
            "Preparing to unpack .../21-liburi-perl_1.73-1_all.deb ...\n",
            "Unpacking liburi-perl (1.73-1) ...\n",
            "Selecting previously unselected package libhtml-parser-perl.\n",
            "Preparing to unpack .../22-libhtml-parser-perl_3.72-3build1_amd64.deb ...\n",
            "Unpacking libhtml-parser-perl (3.72-3build1) ...\n",
            "Selecting previously unselected package libio-html-perl.\n",
            "Preparing to unpack .../23-libio-html-perl_1.001-1_all.deb ...\n",
            "Unpacking libio-html-perl (1.001-1) ...\n",
            "Selecting previously unselected package liblwp-mediatypes-perl.\n",
            "Preparing to unpack .../24-liblwp-mediatypes-perl_6.02-1_all.deb ...\n",
            "Unpacking liblwp-mediatypes-perl (6.02-1) ...\n",
            "Selecting previously unselected package libhttp-message-perl.\n",
            "Preparing to unpack .../25-libhttp-message-perl_6.14-1_all.deb ...\n",
            "Unpacking libhttp-message-perl (6.14-1) ...\n",
            "Selecting previously unselected package libhtml-form-perl.\n",
            "Preparing to unpack .../26-libhtml-form-perl_6.03-1_all.deb ...\n",
            "Unpacking libhtml-form-perl (6.03-1) ...\n",
            "Selecting previously unselected package libhtml-tree-perl.\n",
            "Preparing to unpack .../27-libhtml-tree-perl_5.07-1_all.deb ...\n",
            "Unpacking libhtml-tree-perl (5.07-1) ...\n",
            "Selecting previously unselected package libhtml-format-perl.\n",
            "Preparing to unpack .../28-libhtml-format-perl_2.12-1_all.deb ...\n",
            "Unpacking libhtml-format-perl (2.12-1) ...\n",
            "Selecting previously unselected package libhttp-cookies-perl.\n",
            "Preparing to unpack .../29-libhttp-cookies-perl_6.04-1_all.deb ...\n",
            "Unpacking libhttp-cookies-perl (6.04-1) ...\n",
            "Selecting previously unselected package libhttp-daemon-perl.\n",
            "Preparing to unpack .../30-libhttp-daemon-perl_6.01-1_all.deb ...\n",
            "Unpacking libhttp-daemon-perl (6.01-1) ...\n",
            "Selecting previously unselected package libhttp-negotiate-perl.\n",
            "Preparing to unpack .../31-libhttp-negotiate-perl_6.00-2_all.deb ...\n",
            "Unpacking libhttp-negotiate-perl (6.00-2) ...\n",
            "Selecting previously unselected package perl-openssl-defaults:amd64.\n",
            "Preparing to unpack .../32-perl-openssl-defaults_3build1_amd64.deb ...\n",
            "Unpacking perl-openssl-defaults:amd64 (3build1) ...\n",
            "Selecting previously unselected package libnet-ssleay-perl.\n",
            "Preparing to unpack .../33-libnet-ssleay-perl_1.84-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libnet-ssleay-perl (1.84-1ubuntu0.2) ...\n",
            "Selecting previously unselected package libio-socket-ssl-perl.\n",
            "Preparing to unpack .../34-libio-socket-ssl-perl_2.060-3~ubuntu18.04.1_all.deb ...\n",
            "Unpacking libio-socket-ssl-perl (2.060-3~ubuntu18.04.1) ...\n",
            "Selecting previously unselected package libkpathsea6:amd64.\n",
            "Preparing to unpack .../35-libkpathsea6_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libkpathsea6:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libnet-http-perl.\n",
            "Preparing to unpack .../36-libnet-http-perl_6.17-1_all.deb ...\n",
            "Unpacking libnet-http-perl (6.17-1) ...\n",
            "Selecting previously unselected package libtry-tiny-perl.\n",
            "Preparing to unpack .../37-libtry-tiny-perl_0.30-1_all.deb ...\n",
            "Unpacking libtry-tiny-perl (0.30-1) ...\n",
            "Selecting previously unselected package libwww-robotrules-perl.\n",
            "Preparing to unpack .../38-libwww-robotrules-perl_6.01-1_all.deb ...\n",
            "Unpacking libwww-robotrules-perl (6.01-1) ...\n",
            "Selecting previously unselected package libwww-perl.\n",
            "Preparing to unpack .../39-libwww-perl_6.31-1ubuntu0.1_all.deb ...\n",
            "Unpacking libwww-perl (6.31-1ubuntu0.1) ...\n",
            "Selecting previously unselected package liblwp-protocol-https-perl.\n",
            "Preparing to unpack .../40-liblwp-protocol-https-perl_6.07-2_all.deb ...\n",
            "Unpacking liblwp-protocol-https-perl (6.07-2) ...\n",
            "Selecting previously unselected package libnet-smtp-ssl-perl.\n",
            "Preparing to unpack .../41-libnet-smtp-ssl-perl_1.04-1_all.deb ...\n",
            "Unpacking libnet-smtp-ssl-perl (1.04-1) ...\n",
            "Selecting previously unselected package libmailtools-perl.\n",
            "Preparing to unpack .../42-libmailtools-perl_2.18-1_all.deb ...\n",
            "Unpacking libmailtools-perl (2.18-1) ...\n",
            "Selecting previously unselected package libpotrace0.\n",
            "Preparing to unpack .../43-libpotrace0_1.14-2_amd64.deb ...\n",
            "Unpacking libpotrace0 (1.14-2) ...\n",
            "Selecting previously unselected package libptexenc1:amd64.\n",
            "Preparing to unpack .../44-libptexenc1_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libptexenc1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libsynctex1:amd64.\n",
            "Preparing to unpack .../45-libsynctex1_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libsynctex1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libtexlua52:amd64.\n",
            "Preparing to unpack .../46-libtexlua52_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtexlua52:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libtexluajit2:amd64.\n",
            "Preparing to unpack .../47-libtexluajit2_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtexluajit2:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libtext-unidecode-perl.\n",
            "Preparing to unpack .../48-libtext-unidecode-perl_1.30-1_all.deb ...\n",
            "Unpacking libtext-unidecode-perl (1.30-1) ...\n",
            "Selecting previously unselected package libxml-namespacesupport-perl.\n",
            "Preparing to unpack .../49-libxml-namespacesupport-perl_1.12-1_all.deb ...\n",
            "Unpacking libxml-namespacesupport-perl (1.12-1) ...\n",
            "Selecting previously unselected package libxml-sax-base-perl.\n",
            "Preparing to unpack .../50-libxml-sax-base-perl_1.09-1_all.deb ...\n",
            "Unpacking libxml-sax-base-perl (1.09-1) ...\n",
            "Selecting previously unselected package libxml-sax-perl.\n",
            "Preparing to unpack .../51-libxml-sax-perl_0.99+dfsg-2ubuntu1_all.deb ...\n",
            "Unpacking libxml-sax-perl (0.99+dfsg-2ubuntu1) ...\n",
            "Selecting previously unselected package libxml-libxml-perl.\n",
            "Preparing to unpack .../52-libxml-libxml-perl_2.0128+dfsg-5_amd64.deb ...\n",
            "Unpacking libxml-libxml-perl (2.0128+dfsg-5) ...\n",
            "Selecting previously unselected package libxml-parser-perl.\n",
            "Preparing to unpack .../53-libxml-parser-perl_2.44-2build3_amd64.deb ...\n",
            "Unpacking libxml-parser-perl (2.44-2build3) ...\n",
            "Selecting previously unselected package libxml-sax-expat-perl.\n",
            "Preparing to unpack .../54-libxml-sax-expat-perl_0.40-2_all.deb ...\n",
            "Unpacking libxml-sax-expat-perl (0.40-2) ...\n",
            "Selecting previously unselected package libzzip-0-13:amd64.\n",
            "Preparing to unpack .../55-libzzip-0-13_0.13.62-3.1ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libzzip-0-13:amd64 (0.13.62-3.1ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package texinfo.\n",
            "Preparing to unpack .../56-texinfo_6.5.0.dfsg.1-2_amd64.deb ...\n",
            "Unpacking texinfo (6.5.0.dfsg.1-2) ...\n",
            "Selecting previously unselected package t1utils.\n",
            "Preparing to unpack .../57-t1utils_1.41-2_amd64.deb ...\n",
            "Unpacking t1utils (1.41-2) ...\n",
            "Selecting previously unselected package texlive-binaries.\n",
            "Preparing to unpack .../58-texlive-binaries_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking texlive-binaries (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package lilypond-data.\n",
            "Preparing to unpack .../59-lilypond-data_2.18.2-12build1_all.deb ...\n",
            "Unpacking lilypond-data (2.18.2-12build1) ...\n",
            "Selecting previously unselected package lilypond.\n",
            "Preparing to unpack .../60-lilypond_2.18.2-12build1_amd64.deb ...\n",
            "warning: kpathsea: configuration file texmf.cnf not found in these directories: /etc/texmf/web2c:/usr/local/share/texmf/web2c:/usr/share/texmf/web2c:/usr/share/texlive/texmf-dist/web2c://share/texmf/web2c.\n",
            "warning: kpathsea: configuration file texmf.cnf not found in these directories: /etc/texmf/web2c:/usr/local/share/texmf/web2c:/usr/share/texmf/web2c:/usr/share/texlive/texmf-dist/web2c://share/texmf/web2c.\n",
            "Unpacking lilypond (2.18.2-12build1) ...\n",
            "Selecting previously unselected package lmodern.\n",
            "Preparing to unpack .../61-lmodern_2.004.5-3_all.deb ...\n",
            "Unpacking lmodern (2.004.5-3) ...\n",
            "Selecting previously unselected package texlive-base.\n",
            "Preparing to unpack .../62-texlive-base_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-base (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-latex-base.\n",
            "Preparing to unpack .../63-texlive-latex-base_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-latex-base (2017.20180305-1) ...\n",
            "Selecting previously unselected package libauthen-sasl-perl.\n",
            "Preparing to unpack .../64-libauthen-sasl-perl_2.1600-1_all.deb ...\n",
            "Unpacking libauthen-sasl-perl (2.1600-1) ...\n",
            "Setting up libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Setting up libhtml-tagset-perl (3.20-3) ...\n",
            "Setting up libkpathsea6:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up libtexlua52:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up libtry-tiny-perl (0.30-1) ...\n",
            "Setting up fonts-droid-fallback (1:6.0.1r16-1.1) ...\n",
            "Setting up libfont-afm-perl (1.20-2) ...\n",
            "Setting up libsynctex1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up libptexenc1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up tex-common (6.09) ...\n",
            "update-language: texlive-base not installed and configured, doing nothing!\n",
            "Setting up libxml-namespacesupport-perl (1.12-1) ...\n",
            "Setting up gsfonts (1:8.11+urwcyr1.0.7~pre44-4.4) ...\n",
            "Setting up libencode-locale-perl (1.05-1) ...\n",
            "Setting up libtimedate-perl (2.3000-2) ...\n",
            "Setting up poppler-data (0.4.8-2) ...\n",
            "Setting up perl-openssl-defaults:amd64 (3build1) ...\n",
            "Setting up libio-html-perl (1.001-1) ...\n",
            "Setting up libtext-unidecode-perl (1.30-1) ...\n",
            "Setting up fonts-noto-mono (20171026-2) ...\n",
            "Setting up libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n",
            "Setting up libcupsimage2:amd64 (2.2.7-1ubuntu2.8) ...\n",
            "Setting up libxml-sax-base-perl (1.09-1) ...\n",
            "Setting up libjbig2dec0:amd64 (0.13-6) ...\n",
            "Setting up liblwp-mediatypes-perl (6.02-1) ...\n",
            "Setting up liburi-perl (1.73-1) ...\n",
            "Setting up t1utils (1.41-2) ...\n",
            "Setting up libdata-dump-perl (1.23-1) ...\n",
            "Setting up libhtml-parser-perl (3.72-3build1) ...\n",
            "Setting up libijs-0.35:amd64 (0.35-13) ...\n",
            "Setting up libpotrace0 (1.14-2) ...\n",
            "Setting up libnet-http-perl (6.17-1) ...\n",
            "Setting up libzzip-0-13:amd64 (0.13.62-3.1ubuntu0.18.04.1) ...\n",
            "Setting up libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Setting up libwww-robotrules-perl (6.01-1) ...\n",
            "Setting up libtexluajit2:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up libauthen-sasl-perl (2.1600-1) ...\n",
            "Setting up fonts-lmodern (2.004.5-3) ...\n",
            "Setting up netbase (5.4) ...\n",
            "Setting up libxml-sax-perl (0.99+dfsg-2ubuntu1) ...\n",
            "update-perl-sax-parsers: Registering Perl SAX parser XML::SAX::PurePerl with priority 10...\n",
            "update-perl-sax-parsers: Updating overall Perl SAX parser modules info file...\n",
            "\n",
            "Creating config file /etc/perl/XML/SAX/ParserDetails.ini with new version\n",
            "Setting up libhttp-date-perl (6.02-1) ...\n",
            "Setting up libnet-ssleay-perl (1.84-1ubuntu0.2) ...\n",
            "Setting up ghostscript (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Setting up texlive-binaries (2017.20170613.44572-8ubuntu0.1) ...\n",
            "update-alternatives: using /usr/bin/xdvi-xaw to provide /usr/bin/xdvi.bin (xdvi.bin) in auto mode\n",
            "update-alternatives: using /usr/bin/bibtex.original to provide /usr/bin/bibtex (bibtex) in auto mode\n",
            "Setting up libio-socket-ssl-perl (2.060-3~ubuntu18.04.1) ...\n",
            "Setting up libhtml-tree-perl (5.07-1) ...\n",
            "Setting up texlive-base (2017.20180305-1) ...\n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXLIVEDIST... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXMFMAIN... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R... \n",
            "mktexlsr: Done.\n",
            "tl-paper: setting paper size for dvips to a4: /var/lib/texmf/dvips/config/config-paper.ps\n",
            "tl-paper: setting paper size for dvipdfmx to a4: /var/lib/texmf/dvipdfmx/dvipdfmx-paper.cfg\n",
            "tl-paper: setting paper size for xdvi to a4: /var/lib/texmf/xdvi/XDvi-paper\n",
            "tl-paper: setting paper size for pdftex to a4: /var/lib/texmf/tex/generic/config/pdftexconfig.tex\n",
            "Setting up libfile-listing-perl (6.04-1) ...\n",
            "Setting up libhttp-message-perl (6.14-1) ...\n",
            "Setting up libxml-libxml-perl (2.0128+dfsg-5) ...\n",
            "update-perl-sax-parsers: Registering Perl SAX parser XML::LibXML::SAX::Parser with priority 50...\n",
            "update-perl-sax-parsers: Registering Perl SAX parser XML::LibXML::SAX with priority 50...\n",
            "update-perl-sax-parsers: Updating overall Perl SAX parser modules info file...\n",
            "Replacing config file /etc/perl/XML/SAX/ParserDetails.ini with new version\n",
            "Setting up texlive-latex-base (2017.20180305-1) ...\n",
            "Setting up lmodern (2.004.5-3) ...\n",
            "Setting up libhttp-negotiate-perl (6.00-2) ...\n",
            "Setting up libnet-smtp-ssl-perl (1.04-1) ...\n",
            "Setting up libhtml-format-perl (2.12-1) ...\n",
            "Setting up libhttp-cookies-perl (6.04-1) ...\n",
            "Setting up libhttp-daemon-perl (6.01-1) ...\n",
            "Setting up libhtml-form-perl (6.03-1) ...\n",
            "Setting up texinfo (6.5.0.dfsg.1-2) ...\n",
            "Running mktexlsr. This may take some time. ... done.\n",
            "Setting up libmailtools-perl (2.18-1) ...\n",
            "Setting up lilypond-data (2.18.2-12build1) ...\n",
            "Setting up lilypond (2.18.2-12build1) ...\n",
            "Setting up liblwp-protocol-https-perl (6.07-2) ...\n",
            "Setting up libwww-perl (6.31-1ubuntu0.1) ...\n",
            "Setting up libxml-parser-perl (2.44-2build3) ...\n",
            "Setting up libxml-sax-expat-perl (0.40-2) ...\n",
            "update-perl-sax-parsers: Registering Perl SAX parser XML::SAX::Expat with priority 50...\n",
            "update-perl-sax-parsers: Updating overall Perl SAX parser modules info file...\n",
            "Replacing config file /etc/perl/XML/SAX/ParserDetails.ini with new version\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for tex-common (6.09) ...\n",
            "Running updmap-sys. This may take some time... done.\n",
            "Running mktexlsr /var/lib/texmf ... done.\n",
            "Building format(s) --all.\n",
            "\tThis may take some time... done.\n",
            "installing fluidsynth...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  fluid-soundfont-gm libfluidsynth1 libqt5x11extras5 qsynth\n",
            "Suggested packages:\n",
            "  fluid-soundfont-gs timidity jackd\n",
            "The following NEW packages will be installed:\n",
            "  fluid-soundfont-gm fluidsynth libfluidsynth1 libqt5x11extras5 qsynth\n",
            "0 upgraded, 5 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 120 MB of archives.\n",
            "After this operation, 150 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fluid-soundfont-gm all 3.1-5.1 [119 MB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libfluidsynth1 amd64 1.1.9-1 [137 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fluidsynth amd64 1.1.9-1 [20.7 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libqt5x11extras5 amd64 5.9.5-0ubuntu1 [8,596 B]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 qsynth amd64 0.5.0-2 [191 kB]\n",
            "Fetched 120 MB in 5s (25.5 MB/s)\n",
            "Selecting previously unselected package fluid-soundfont-gm.\n",
            "(Reading database ... 168898 files and directories currently installed.)\n",
            "Preparing to unpack .../fluid-soundfont-gm_3.1-5.1_all.deb ...\n",
            "Unpacking fluid-soundfont-gm (3.1-5.1) ...\n",
            "Selecting previously unselected package libfluidsynth1:amd64.\n",
            "Preparing to unpack .../libfluidsynth1_1.1.9-1_amd64.deb ...\n",
            "Unpacking libfluidsynth1:amd64 (1.1.9-1) ...\n",
            "Selecting previously unselected package fluidsynth.\n",
            "Preparing to unpack .../fluidsynth_1.1.9-1_amd64.deb ...\n",
            "Unpacking fluidsynth (1.1.9-1) ...\n",
            "Selecting previously unselected package libqt5x11extras5:amd64.\n",
            "Preparing to unpack .../libqt5x11extras5_5.9.5-0ubuntu1_amd64.deb ...\n",
            "Unpacking libqt5x11extras5:amd64 (5.9.5-0ubuntu1) ...\n",
            "Selecting previously unselected package qsynth.\n",
            "Preparing to unpack .../qsynth_0.5.0-2_amd64.deb ...\n",
            "Unpacking qsynth (0.5.0-2) ...\n",
            "Setting up libqt5x11extras5:amd64 (5.9.5-0ubuntu1) ...\n",
            "Setting up fluid-soundfont-gm (3.1-5.1) ...\n",
            "Setting up libfluidsynth1:amd64 (1.1.9-1) ...\n",
            "Setting up fluidsynth (1.1.9-1) ...\n",
            "Setting up qsynth (0.5.0-2) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htpA7-EPBUBw"
      },
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import types\n",
        "\n",
        "!cp /content/drive/MyDrive/ColabNotebooks/models/MuseGAN.py .\n",
        "from MuseGAN import MuseGAN\n",
        "\n",
        "!cp /content/drive/MyDrive/ColabNotebooks/utils/loaders.py .\n",
        "from loaders import load_music\n",
        "\n",
        "import music21\n",
        "from music21 import midi\n",
        "from music21 import note, stream, duration\n",
        "\n",
        "from IPython.display import Image, Audio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "-K7k2oiaWFLh",
        "outputId": "4e6e4a03-c156-47aa-c752-3760add503b2"
      },
      "source": [
        "!fluidsynth --version\n",
        "print('-------------------------')\n",
        "!lilypond --version\n",
        "print('-------------------------')\n",
        "music21.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FluidSynth version 1.1.9\n",
            "Copyright (C) 2000-2018 Peter Hanappe and others.\n",
            "Distributed under the LGPL license.\n",
            "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
            "\n",
            "FluidSynth 1.1.9\n",
            "-------------------------\n",
            "GNU LilyPond 2.18.2\n",
            "\n",
            "Copyright (c) 1996--2012 by\n",
            "  Han-Wen Nienhuys <hanwen@xs4all.nl>\n",
            "  Jan Nieuwenhuizen <janneke@gnu.org>\n",
            "  and others.\n",
            "\n",
            "This program is free software.  It is covered by the GNU General Public\n",
            "License and you are welcome to change it and/or distribute copies of it\n",
            "under certain conditions.  Invoke as `lilypond --warranty' for more\n",
            "information.\n",
            "\n",
            "-------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'5.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IdGvee1VnGAz",
        "outputId": "0b1b4675-32a9-46ac-ac95-2908d411b249"
      },
      "source": [
        "import tensorflow\n",
        "tensorflow.keras.__version__ #2.4.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYwzQO6LLqZ6"
      },
      "source": [
        "from tensorflow.python.framework.ops import disable_eager_execution\n",
        "disable_eager_execution()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VcN1LxpVqI-"
      },
      "source": [
        "def show(music):\n",
        "  display(Image(str(music.write('lily.png'))))\n",
        "\n",
        "def play(music):\n",
        "  filename = music.write('mid')\n",
        "  !fluidsynth -ni font.sf2 $filename -F $filename\\.wav -r 16000 > /dev/null\n",
        "  display(Audio(filename + '.wav'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB6WzuARjFG8"
      },
      "source": [
        "# run params\n",
        "SECTION = '/content/drive/MyDrive/ColabNotebooks/MusicGeneration/MusicWithMuseGAN_Data'\n",
        "RUN_ID = '0017'\n",
        "DATA_NAME = 'chorales'\n",
        "FILENAME = 'Jsb16thSeparated.npz'\n",
        "RUN_FOLDER = '{}/'.format(SECTION)\n",
        "RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])\n",
        "\n",
        "\n",
        "\n",
        "if not os.path.exists(RUN_FOLDER):\n",
        "    os.mkdir(RUN_FOLDER)\n",
        "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
        "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
        "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
        "    os.mkdir(os.path.join(RUN_FOLDER, 'samples'))\n",
        "\n",
        "mode =  'build' # ' 'load' #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCiyeBPTNiYr"
      },
      "source": [
        "#Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UN3JKe_MB2Cr"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "n_bars = 2\n",
        "n_steps_per_bar = 16\n",
        "n_pitches = 84\n",
        "n_tracks = 4\n",
        "\n",
        "data_binary, data_ints, raw_data = load_music(RUN_FOLDER, FILENAME, n_bars, n_steps_per_bar)\n",
        "data_binary = np.squeeze(data_binary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1s8Xr72Nm_9"
      },
      "source": [
        "#Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNGWjSxODO9a"
      },
      "source": [
        "gan = MuseGAN(input_dim = data_binary.shape[1:]\n",
        "        , critic_learning_rate = 0.001\n",
        "        , generator_learning_rate = 0.001\n",
        "        , optimiser = 'adam'\n",
        "        , grad_weight = 10\n",
        "        , z_dim = 32\n",
        "        , batch_size = BATCH_SIZE\n",
        "        , n_tracks = n_tracks\n",
        "        , n_bars = n_bars\n",
        "        , n_steps_per_bar = n_steps_per_bar\n",
        "        , n_pitches = n_pitches\n",
        "        )\n",
        "\n",
        "if mode == 'build':\n",
        "    gan.save(RUN_FOLDER)\n",
        "else:                 \n",
        "    gan.load_weights(RUN_FOLDER)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5k7vnoTNphx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac10fa83-114b-48d0-c30e-cbb2698241ea"
      },
      "source": [
        "gan.chords_tempNetwork.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"temporal_network\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "temporal_input (InputLayer)  [(None, 32)]              0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 1, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose (Conv2DTran (None, 2, 1, 1024)        66560     \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 2, 1, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 2, 1, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 2, 1, 32)          32800     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 2, 1, 32)          128       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 2, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 2, 32)             0         \n",
            "=================================================================\n",
            "Total params: 103,584\n",
            "Trainable params: 101,472\n",
            "Non-trainable params: 2,112\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJBKx00A2LDN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69ae5a2f-83d9-4817-90ba-681c93799ab0"
      },
      "source": [
        "gan.barGen[0].summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bar_generator_input (InputLa [(None, 128)]             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1024)              132096    \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "reshape_10 (Reshape)         (None, 2, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_10 (Conv2DT (None, 4, 1, 512)         524800    \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 4, 1, 512)         2048      \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 4, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_11 (Conv2DT (None, 8, 1, 256)         262400    \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 8, 1, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 8, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_12 (Conv2DT (None, 16, 1, 256)        131328    \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 16, 1, 256)        1024      \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 16, 1, 256)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_13 (Conv2DT (None, 16, 7, 256)        459008    \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 16, 7, 256)        1024      \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 16, 7, 256)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_14 (Conv2DT (None, 16, 84, 1)         3073      \n",
            "_________________________________________________________________\n",
            "reshape_11 (Reshape)         (None, 1, 16, 84, 1)      0         \n",
            "=================================================================\n",
            "Total params: 1,521,921\n",
            "Trainable params: 1,517,313\n",
            "Non-trainable params: 4,608\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pO6LLIU42Uh7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ab39932-da04-4150-8a3d-78ba85bd1bf6"
      },
      "source": [
        "gan.generator.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "melody_input (InputLayer)       [(None, 4, 32)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "chords_input (InputLayer)       [(None, 32)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 32)           0           melody_input[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 32)           0           melody_input[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 32)           0           melody_input[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 32)           0           melody_input[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "temporal_network (Functional)   (None, 2, 32)        103584      chords_input[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "model_2 (Functional)            (None, 2, 32)        103584      lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "groove_input (InputLayer)       [(None, 4, 32)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_3 (Functional)            (None, 2, 32)        103584      lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "model_4 (Functional)            (None, 2, 32)        103584      lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "model_5 (Functional)            (None, 2, 32)        103584      lambda_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "chords_input_bar_0 (Lambda)     (None, 32)           0           temporal_network[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "style_input (InputLayer)        [(None, 32)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4 (Lambda)               (None, 32)           0           model_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_5 (Lambda)               (None, 32)           0           groove_input[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lambda_6 (Lambda)               (None, 32)           0           model_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_7 (Lambda)               (None, 32)           0           groove_input[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lambda_8 (Lambda)               (None, 32)           0           model_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_9 (Lambda)               (None, 32)           0           groove_input[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lambda_10 (Lambda)              (None, 32)           0           model_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_11 (Lambda)              (None, 32)           0           groove_input[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "chords_input_bar_1 (Lambda)     (None, 32)           0           temporal_network[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "lambda_12 (Lambda)              (None, 32)           0           model_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_13 (Lambda)              (None, 32)           0           groove_input[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lambda_14 (Lambda)              (None, 32)           0           model_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_15 (Lambda)              (None, 32)           0           groove_input[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lambda_16 (Lambda)              (None, 32)           0           model_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_17 (Lambda)              (None, 32)           0           groove_input[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lambda_18 (Lambda)              (None, 32)           0           model_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_19 (Lambda)              (None, 32)           0           groove_input[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "total_input_bar_0_track_0 (Conc (None, 128)          0           chords_input_bar_0[0][0]         \n",
            "                                                                 style_input[0][0]                \n",
            "                                                                 lambda_4[0][0]                   \n",
            "                                                                 lambda_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "total_input_bar_0_track_1 (Conc (None, 128)          0           chords_input_bar_0[0][0]         \n",
            "                                                                 style_input[0][0]                \n",
            "                                                                 lambda_6[0][0]                   \n",
            "                                                                 lambda_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "total_input_bar_0_track_2 (Conc (None, 128)          0           chords_input_bar_0[0][0]         \n",
            "                                                                 style_input[0][0]                \n",
            "                                                                 lambda_8[0][0]                   \n",
            "                                                                 lambda_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "total_input_bar_0_track_3 (Conc (None, 128)          0           chords_input_bar_0[0][0]         \n",
            "                                                                 style_input[0][0]                \n",
            "                                                                 lambda_10[0][0]                  \n",
            "                                                                 lambda_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "total_input_bar_1_track_0 (Conc (None, 128)          0           chords_input_bar_1[0][0]         \n",
            "                                                                 style_input[0][0]                \n",
            "                                                                 lambda_12[0][0]                  \n",
            "                                                                 lambda_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "total_input_bar_1_track_1 (Conc (None, 128)          0           chords_input_bar_1[0][0]         \n",
            "                                                                 style_input[0][0]                \n",
            "                                                                 lambda_14[0][0]                  \n",
            "                                                                 lambda_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "total_input_bar_1_track_2 (Conc (None, 128)          0           chords_input_bar_1[0][0]         \n",
            "                                                                 style_input[0][0]                \n",
            "                                                                 lambda_16[0][0]                  \n",
            "                                                                 lambda_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "total_input_bar_1_track_3 (Conc (None, 128)          0           chords_input_bar_1[0][0]         \n",
            "                                                                 style_input[0][0]                \n",
            "                                                                 lambda_18[0][0]                  \n",
            "                                                                 lambda_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "model_6 (Functional)            (None, 1, 16, 84, 1) 1521921     total_input_bar_0_track_0[0][0]  \n",
            "                                                                 total_input_bar_1_track_0[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "model_7 (Functional)            (None, 1, 16, 84, 1) 1521921     total_input_bar_0_track_1[0][0]  \n",
            "                                                                 total_input_bar_1_track_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "model_8 (Functional)            (None, 1, 16, 84, 1) 1521921     total_input_bar_0_track_2[0][0]  \n",
            "                                                                 total_input_bar_1_track_2[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "model_9 (Functional)            (None, 1, 16, 84, 1) 1521921     total_input_bar_0_track_3[0][0]  \n",
            "                                                                 total_input_bar_1_track_3[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 1, 16, 84, 4) 0           model_6[0][0]                    \n",
            "                                                                 model_7[0][0]                    \n",
            "                                                                 model_8[0][0]                    \n",
            "                                                                 model_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 1, 16, 84, 4) 0           model_6[1][0]                    \n",
            "                                                                 model_7[1][0]                    \n",
            "                                                                 model_8[1][0]                    \n",
            "                                                                 model_9[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concat_bars (Concatenate)       (None, 2, 16, 84, 4) 0           concatenate[0][0]                \n",
            "                                                                 concatenate_1[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 6,605,604\n",
            "Trainable params: 6,576,612\n",
            "Non-trainable params: 28,992\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFDIHBeL2gD9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "319d36a6-63e0-47eb-9115-77691bd24f0c"
      },
      "source": [
        "gan.critic.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "critic_input (InputLayer)    [(None, 2, 16, 84, 4)]    0         \n",
            "_________________________________________________________________\n",
            "conv3d (Conv3D)              multiple                  1152      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv3d_1 (Conv3D)            multiple                  16512     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv3d_2 (Conv3D)            multiple                  196736    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv3d_3 (Conv3D)            multiple                  114816    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv3d_4 (Conv3D)            multiple                  32896     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv3d_5 (Conv3D)            multiple                  32896     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv3d_6 (Conv3D)            multiple                  131328    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv3d_7 (Conv3D)            multiple                  393728    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  525312    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  1025      \n",
            "=================================================================\n",
            "Total params: 1,446,401\n",
            "Trainable params: 1,446,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KG4DYS4K25Ca"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rh_gPmTN2km1"
      },
      "source": [
        "EPOCHS = 6000\n",
        "gan.epoch = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oz3pPnpC29O-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "64442c99-3a6d-4f93-dafa-57dbb41471d5"
      },
      "source": [
        "gan.train(     \n",
        "    data_binary\n",
        "    , batch_size = BATCH_SIZE\n",
        "    , epochs = EPOCHS\n",
        "    , run_folder = RUN_FOLDER\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "0 (5, 1) [D loss: (9.3)(R -0.6, F 0.0, G 1.0)] [G loss: -0.0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1 (5, 1) [D loss: (-243.2)(R -288.6, F -2.1, G 4.7)] [G loss: -35.6]\n",
            "2 (5, 1) [D loss: (-283.7)(R -553.3, F -15.5, G 28.5)] [G loss: -182.0]\n",
            "3 (5, 1) [D loss: (-326.7)(R -482.9, F 5.1, G 15.1)] [G loss: -252.4]\n",
            "4 (5, 1) [D loss: (-318.1)(R -643.0, F 9.1, G 31.6)] [G loss: 6.3]\n",
            "5 (5, 1) [D loss: (-295.7)(R -595.0, F 123.5, G 17.6)] [G loss: -583.4]\n",
            "6 (5, 1) [D loss: (-240.3)(R -669.7, F 200.4, G 22.9)] [G loss: -459.4]\n",
            "7 (5, 1) [D loss: (-183.4)(R -531.0, F 223.2, G 12.4)] [G loss: -466.3]\n",
            "8 (5, 1) [D loss: (-119.6)(R -456.5, F 255.0, G 8.2)] [G loss: -424.2]\n",
            "9 (5, 1) [D loss: (-67.0)(R -354.5, F 246.7, G 4.1)] [G loss: -369.5]\n",
            "10 (5, 1) [D loss: (-40.5)(R -210.0, F 160.2, G 0.9)] [G loss: -265.5]\n",
            "11 (5, 1) [D loss: (-19.1)(R -278.6, F 240.7, G 1.9)] [G loss: -261.2]\n",
            "12 (5, 1) [D loss: (-4.1)(R -88.4, F 83.2, G 0.1)] [G loss: -105.3]\n",
            "13 (5, 1) [D loss: (-33.9)(R -99.8, F 62.3, G 0.4)] [G loss: 73.9]\n",
            "14 (5, 1) [D loss: (-59.3)(R -76.0, F -0.3, G 1.7)] [G loss: 375.9]\n",
            "15 (5, 1) [D loss: (-99.5)(R 529.3, F -665.1, G 3.6)] [G loss: 837.5]\n",
            "16 (5, 1) [D loss: (-88.8)(R 542.7, F -686.6, G 5.5)] [G loss: 584.2]\n",
            "17 (5, 1) [D loss: (-81.6)(R 469.2, F -592.0, G 4.1)] [G loss: 528.5]\n",
            "18 (5, 1) [D loss: (-91.1)(R 506.2, F -627.6, G 3.0)] [G loss: 707.1]\n",
            "19 (5, 1) [D loss: (-62.8)(R 498.6, F -587.5, G 2.6)] [G loss: 530.3]\n",
            "20 (5, 1) [D loss: (-53.6)(R 461.5, F -541.6, G 2.6)] [G loss: 469.2]\n",
            "21 (5, 1) [D loss: (-25.9)(R 232.0, F -266.6, G 0.9)] [G loss: 277.0]\n",
            "22 (5, 1) [D loss: (-23.3)(R 240.9, F -277.6, G 1.3)] [G loss: 292.1]\n",
            "23 (5, 1) [D loss: (-27.6)(R 218.0, F -257.5, G 1.2)] [G loss: 249.3]\n",
            "24 (5, 1) [D loss: (-21.6)(R 177.0, F -204.6, G 0.6)] [G loss: 220.3]\n",
            "25 (5, 1) [D loss: (-12.1)(R 164.4, F -177.8, G 0.1)] [G loss: 190.0]\n",
            "26 (5, 1) [D loss: (-8.3)(R 235.8, F -245.6, G 0.2)] [G loss: 259.3]\n",
            "27 (5, 1) [D loss: (-11.5)(R 414.8, F -431.5, G 0.5)] [G loss: 298.5]\n",
            "28 (5, 1) [D loss: (-15.4)(R 317.4, F -339.6, G 0.7)] [G loss: 255.6]\n",
            "29 (5, 1) [D loss: (-23.5)(R 299.0, F -330.8, G 0.8)] [G loss: 384.1]\n",
            "30 (5, 1) [D loss: (-17.2)(R 91.6, F -109.7, G 0.1)] [G loss: 141.1]\n",
            "31 (5, 1) [D loss: (-24.6)(R 213.2, F -241.4, G 0.4)] [G loss: 299.7]\n",
            "32 (5, 1) [D loss: (-28.1)(R 263.3, F -300.6, G 0.9)] [G loss: 380.9]\n",
            "33 (5, 1) [D loss: (-26.9)(R 194.0, F -228.3, G 0.7)] [G loss: 291.1]\n",
            "34 (5, 1) [D loss: (-28.8)(R 228.7, F -265.4, G 0.8)] [G loss: 342.2]\n",
            "35 (5, 1) [D loss: (-27.2)(R 258.9, F -294.5, G 0.8)] [G loss: 307.6]\n",
            "36 (5, 1) [D loss: (-30.1)(R 345.3, F -388.8, G 1.3)] [G loss: 364.2]\n",
            "37 (5, 1) [D loss: (-29.9)(R 289.3, F -335.5, G 1.6)] [G loss: 264.4]\n",
            "38 (5, 1) [D loss: (-26.2)(R 414.2, F -459.3, G 1.9)] [G loss: 301.1]\n",
            "39 (5, 1) [D loss: (-26.7)(R 320.0, F -356.6, G 1.0)] [G loss: 357.1]\n",
            "40 (5, 1) [D loss: (-29.8)(R 355.7, F -395.7, G 1.0)] [G loss: 409.1]\n",
            "41 (5, 1) [D loss: (-34.6)(R 290.8, F -345.5, G 2.0)] [G loss: 258.0]\n",
            "42 (5, 1) [D loss: (-22.7)(R 132.1, F -155.3, G 0.0)] [G loss: 173.1]\n",
            "43 (5, 1) [D loss: (-29.7)(R 161.7, F -197.4, G 0.6)] [G loss: 212.5]\n",
            "44 (5, 1) [D loss: (-28.7)(R 171.0, F -209.0, G 0.9)] [G loss: 252.3]\n",
            "45 (5, 1) [D loss: (-30.4)(R 286.7, F -335.7, G 1.9)] [G loss: 209.0]\n",
            "46 (5, 1) [D loss: (-23.0)(R 137.8, F -162.4, G 0.2)] [G loss: 249.5]\n",
            "47 (5, 1) [D loss: (-28.9)(R 179.3, F -216.0, G 0.8)] [G loss: 249.2]\n",
            "48 (5, 1) [D loss: (-27.2)(R 162.9, F -197.7, G 0.8)] [G loss: 218.8]\n",
            "49 (5, 1) [D loss: (-28.8)(R 136.8, F -172.9, G 0.7)] [G loss: 178.9]\n",
            "50 (5, 1) [D loss: (-30.2)(R 153.1, F -195.8, G 1.3)] [G loss: 201.6]\n",
            "51 (5, 1) [D loss: (-27.8)(R 135.9, F -169.1, G 0.5)] [G loss: 184.8]\n",
            "52 (5, 1) [D loss: (-33.3)(R 191.3, F -240.2, G 1.6)] [G loss: 217.1]\n",
            "53 (5, 1) [D loss: (-31.0)(R 197.3, F -241.2, G 1.3)] [G loss: 223.2]\n",
            "54 (5, 1) [D loss: (-30.7)(R 223.3, F -263.5, G 0.9)] [G loss: 285.7]\n",
            "55 (5, 1) [D loss: (-28.8)(R 158.7, F -195.8, G 0.8)] [G loss: 206.4]\n",
            "56 (5, 1) [D loss: (-26.6)(R 223.9, F -268.3, G 1.8)] [G loss: 189.7]\n",
            "57 (5, 1) [D loss: (-29.3)(R 223.2, F -268.2, G 1.6)] [G loss: 186.0]\n",
            "58 (5, 1) [D loss: (-31.3)(R 233.5, F -277.9, G 1.3)] [G loss: 252.5]\n",
            "59 (5, 1) [D loss: (-34.5)(R 242.6, F -289.7, G 1.3)] [G loss: 345.0]\n",
            "60 (5, 1) [D loss: (-36.3)(R 249.2, F -289.5, G 0.4)] [G loss: 342.2]\n",
            "61 (5, 1) [D loss: (-34.9)(R 222.2, F -266.9, G 1.0)] [G loss: 326.5]\n",
            "62 (5, 1) [D loss: (-70.8)(R 529.5, F -615.4, G 1.5)] [G loss: 988.7]\n",
            "63 (5, 1) [D loss: (-36.1)(R 1194.1, F -1356.1, G 12.6)] [G loss: 564.4]\n",
            "64 (5, 1) [D loss: (-136.5)(R 1031.3, F -1228.5, G 6.1)] [G loss: 1622.5]\n",
            "65 (5, 1) [D loss: (-192.9)(R 1594.3, F -1949.7, G 16.2)] [G loss: 1785.6]\n",
            "66 (5, 1) [D loss: (-192.7)(R 1383.4, F -1699.9, G 12.4)] [G loss: 1799.7]\n",
            "67 (5, 1) [D loss: (-136.7)(R 1330.8, F -1670.6, G 20.3)] [G loss: 900.7]\n",
            "68 (5, 1) [D loss: (-160.2)(R 954.2, F -1189.1, G 7.5)] [G loss: 1376.3]\n",
            "69 (5, 1) [D loss: (-111.4)(R 737.8, F -899.0, G 5.0)] [G loss: 875.4]\n",
            "70 (5, 1) [D loss: (-81.5)(R 717.3, F -850.7, G 5.2)] [G loss: 743.3]\n",
            "71 (5, 1) [D loss: (-90.2)(R 663.3, F -796.1, G 4.3)] [G loss: 730.5]\n",
            "72 (5, 1) [D loss: (-60.7)(R 583.2, F -670.2, G 2.6)] [G loss: 605.3]\n",
            "73 (5, 1) [D loss: (-40.4)(R 623.7, F -677.6, G 1.3)] [G loss: 621.6]\n",
            "74 (5, 1) [D loss: (-24.8)(R 794.4, F -834.9, G 1.6)] [G loss: 580.9]\n",
            "75 (5, 1) [D loss: (-38.6)(R 731.6, F -786.7, G 1.7)] [G loss: 770.8]\n",
            "76 (5, 1) [D loss: (-35.3)(R 569.5, F -623.3, G 1.8)] [G loss: 591.0]\n",
            "77 (5, 1) [D loss: (-38.3)(R 642.4, F -700.1, G 1.9)] [G loss: 638.1]\n",
            "78 (5, 1) [D loss: (-33.4)(R 490.3, F -537.0, G 1.3)] [G loss: 537.1]\n",
            "79 (5, 1) [D loss: (-30.8)(R 463.0, F -503.2, G 0.9)] [G loss: 529.3]\n",
            "80 (5, 1) [D loss: (-28.6)(R 344.2, F -379.3, G 0.6)] [G loss: 448.2]\n",
            "81 (5, 1) [D loss: (-24.3)(R 251.5, F -278.5, G 0.3)] [G loss: 329.4]\n",
            "82 (5, 1) [D loss: (-24.5)(R 258.1, F -285.1, G 0.3)] [G loss: 329.4]\n",
            "83 (5, 1) [D loss: (-25.5)(R 266.1, F -295.4, G 0.4)] [G loss: 405.8]\n",
            "84 (5, 1) [D loss: (-19.8)(R 350.5, F -390.7, G 2.0)] [G loss: 179.0]\n",
            "85 (5, 1) [D loss: (-26.9)(R 263.9, F -298.8, G 0.8)] [G loss: 328.8]\n",
            "86 (5, 1) [D loss: (-26.3)(R 226.6, F -258.2, G 0.5)] [G loss: 308.1]\n",
            "87 (5, 1) [D loss: (-25.6)(R 214.3, F -246.8, G 0.7)] [G loss: 284.8]\n",
            "88 (5, 1) [D loss: (-20.4)(R 111.4, F -132.3, G 0.0)] [G loss: 138.7]\n",
            "89 (5, 1) [D loss: (-25.2)(R 91.5, F -121.0, G 0.4)] [G loss: 210.1]\n",
            "90 (5, 1) [D loss: (-19.7)(R 159.9, F -180.5, G 0.1)] [G loss: 174.8]\n",
            "91 (5, 1) [D loss: (-24.1)(R 258.5, F -290.9, G 0.8)] [G loss: 275.0]\n",
            "92 (5, 1) [D loss: (-23.1)(R 262.3, F -293.7, G 0.8)] [G loss: 276.4]\n",
            "93 (5, 1) [D loss: (-24.6)(R 258.0, F -290.7, G 0.8)] [G loss: 291.9]\n",
            "94 (5, 1) [D loss: (-23.2)(R 207.2, F -235.5, G 0.5)] [G loss: 259.8]\n",
            "95 (5, 1) [D loss: (-23.8)(R 293.5, F -326.6, G 0.9)] [G loss: 291.4]\n",
            "96 (5, 1) [D loss: (-21.5)(R 211.8, F -238.1, G 0.5)] [G loss: 284.0]\n",
            "97 (5, 1) [D loss: (-23.0)(R 239.6, F -272.4, G 1.0)] [G loss: 209.6]\n",
            "98 (5, 1) [D loss: (-23.2)(R 267.9, F -298.7, G 0.8)] [G loss: 299.5]\n",
            "99 (5, 1) [D loss: (-21.3)(R 219.6, F -242.8, G 0.2)] [G loss: 277.8]\n",
            "100 (5, 1) [D loss: (-21.6)(R 253.2, F -279.1, G 0.4)] [G loss: 332.9]\n",
            "101 (5, 1) [D loss: (-22.6)(R 210.1, F -237.7, G 0.5)] [G loss: 250.0]\n",
            "102 (5, 1) [D loss: (-23.2)(R 219.5, F -246.7, G 0.4)] [G loss: 319.0]\n",
            "103 (5, 1) [D loss: (-23.4)(R 219.9, F -250.4, G 0.7)] [G loss: 262.0]\n",
            "104 (5, 1) [D loss: (-20.4)(R 288.5, F -324.9, G 1.6)] [G loss: 211.0]\n",
            "105 (5, 1) [D loss: (-20.8)(R 182.6, F -210.2, G 0.7)] [G loss: 200.4]\n",
            "106 (5, 1) [D loss: (-22.8)(R 171.7, F -199.8, G 0.5)] [G loss: 310.1]\n",
            "107 (5, 1) [D loss: (-19.6)(R 143.5, F -165.6, G 0.2)] [G loss: 184.4]\n",
            "108 (5, 1) [D loss: (-21.0)(R 227.8, F -259.9, G 1.1)] [G loss: 171.5]\n",
            "109 (5, 1) [D loss: (-22.2)(R 239.4, F -267.4, G 0.6)] [G loss: 357.0]\n",
            "110 (5, 1) [D loss: (-20.9)(R 130.1, F -162.5, G 1.1)] [G loss: 115.4]\n",
            "111 (5, 1) [D loss: (-19.0)(R 205.2, F -232.0, G 0.8)] [G loss: 151.7]\n",
            "112 (5, 1) [D loss: (-20.8)(R 143.0, F -169.1, G 0.5)] [G loss: 221.3]\n",
            "113 (5, 1) [D loss: (-18.9)(R 253.0, F -284.5, G 1.3)] [G loss: 148.8]\n",
            "114 (5, 1) [D loss: (-21.4)(R 227.2, F -258.8, G 1.0)] [G loss: 201.7]\n",
            "115 (5, 1) [D loss: (-20.1)(R 171.5, F -194.0, G 0.2)] [G loss: 229.3]\n",
            "116 (5, 1) [D loss: (-19.1)(R 90.5, F -112.2, G 0.3)] [G loss: 157.9]\n",
            "117 (5, 1) [D loss: (-21.0)(R 95.5, F -119.5, G 0.3)] [G loss: 278.7]\n",
            "118 (5, 1) [D loss: (-20.3)(R 134.3, F -157.7, G 0.3)] [G loss: 217.2]\n",
            "119 (5, 1) [D loss: (-20.8)(R 175.2, F -197.9, G 0.2)] [G loss: 263.9]\n",
            "120 (5, 1) [D loss: (-23.2)(R 185.6, F -216.6, G 0.8)] [G loss: 203.3]\n",
            "121 (5, 1) [D loss: (-21.9)(R 176.0, F -206.5, G 0.9)] [G loss: 202.2]\n",
            "122 (5, 1) [D loss: (-18.8)(R 221.6, F -251.8, G 1.1)] [G loss: 169.8]\n",
            "123 (5, 1) [D loss: (-20.6)(R 203.8, F -231.8, G 0.7)] [G loss: 196.0]\n",
            "124 (5, 1) [D loss: (-19.5)(R 132.6, F -159.0, G 0.7)] [G loss: 119.1]\n",
            "125 (5, 1) [D loss: (-18.5)(R 122.5, F -151.9, G 1.1)] [G loss: 119.2]\n",
            "126 (5, 1) [D loss: (-19.9)(R 115.1, F -138.9, G 0.4)] [G loss: 186.3]\n",
            "127 (5, 1) [D loss: (-20.3)(R 56.3, F -79.3, G 0.3)] [G loss: 104.5]\n",
            "128 (5, 1) [D loss: (-20.3)(R 138.3, F -165.7, G 0.7)] [G loss: 154.2]\n",
            "129 (5, 1) [D loss: (-19.1)(R 77.9, F -98.5, G 0.2)] [G loss: 123.3]\n",
            "130 (5, 1) [D loss: (-21.3)(R 118.2, F -148.2, G 0.9)] [G loss: 139.3]\n",
            "131 (5, 1) [D loss: (-19.1)(R 137.4, F -158.9, G 0.2)] [G loss: 194.5]\n",
            "132 (5, 1) [D loss: (-19.6)(R 73.0, F -99.3, G 0.7)] [G loss: 88.7]\n",
            "133 (5, 1) [D loss: (-22.1)(R 147.2, F -177.9, G 0.9)] [G loss: 161.3]\n",
            "134 (5, 1) [D loss: (-20.5)(R 97.3, F -122.3, G 0.4)] [G loss: 141.1]\n",
            "135 (5, 1) [D loss: (-19.2)(R 89.4, F -110.8, G 0.2)] [G loss: 186.4]\n",
            "136 (5, 1) [D loss: (-18.3)(R 17.5, F -36.8, G 0.1)] [G loss: 140.8]\n",
            "137 (5, 1) [D loss: (-14.0)(R -0.7, F -13.5, G 0.0)] [G loss: 127.8]\n",
            "138 (5, 1) [D loss: (-18.1)(R 90.6, F -110.4, G 0.2)] [G loss: 126.6]\n",
            "139 (5, 1) [D loss: (-20.5)(R 92.6, F -121.8, G 0.9)] [G loss: 100.3]\n",
            "140 (5, 1) [D loss: (-21.1)(R 125.6, F -159.8, G 1.3)] [G loss: 107.6]\n",
            "141 (5, 1) [D loss: (-16.1)(R 59.8, F -76.1, G 0.0)] [G loss: 99.2]\n",
            "142 (5, 1) [D loss: (-19.3)(R 82.2, F -112.6, G 1.1)] [G loss: 94.0]\n",
            "143 (5, 1) [D loss: (-20.7)(R 117.2, F -140.6, G 0.3)] [G loss: 164.4]\n",
            "144 (5, 1) [D loss: (-21.9)(R 112.9, F -141.2, G 0.6)] [G loss: 162.7]\n",
            "145 (5, 1) [D loss: (-19.2)(R 75.7, F -96.2, G 0.1)] [G loss: 122.2]\n",
            "146 (5, 1) [D loss: (-20.3)(R 89.1, F -113.1, G 0.4)] [G loss: 132.7]\n",
            "147 (5, 1) [D loss: (-20.0)(R 34.3, F -56.6, G 0.2)] [G loss: 102.7]\n",
            "148 (5, 1) [D loss: (-19.2)(R 74.6, F -95.0, G 0.1)] [G loss: 147.3]\n",
            "149 (5, 1) [D loss: (-19.4)(R 79.8, F -101.6, G 0.2)] [G loss: 149.3]\n",
            "150 (5, 1) [D loss: (-20.9)(R 105.7, F -132.4, G 0.6)] [G loss: 129.2]\n",
            "151 (5, 1) [D loss: (-20.4)(R 126.4, F -151.6, G 0.5)] [G loss: 212.0]\n",
            "152 (5, 1) [D loss: (-19.1)(R 112.7, F -132.8, G 0.1)] [G loss: 158.2]\n",
            "153 (5, 1) [D loss: (-20.1)(R 124.3, F -153.5, G 0.9)] [G loss: 117.6]\n",
            "154 (5, 1) [D loss: (-20.8)(R 65.0, F -90.7, G 0.5)] [G loss: 100.4]\n",
            "155 (5, 1) [D loss: (-20.6)(R 118.7, F -146.1, G 0.7)] [G loss: 104.7]\n",
            "156 (5, 1) [D loss: (-21.6)(R 106.5, F -132.7, G 0.5)] [G loss: 143.8]\n",
            "157 (5, 1) [D loss: (-22.0)(R 132.9, F -160.1, G 0.5)] [G loss: 203.5]\n",
            "158 (5, 1) [D loss: (-20.4)(R 73.6, F -96.7, G 0.3)] [G loss: 121.3]\n",
            "159 (5, 1) [D loss: (-20.8)(R 156.8, F -186.7, G 0.9)] [G loss: 153.1]\n",
            "160 (5, 1) [D loss: (-21.9)(R 110.9, F -135.6, G 0.3)] [G loss: 201.7]\n",
            "161 (5, 1) [D loss: (-21.0)(R 131.0, F -155.8, G 0.4)] [G loss: 169.6]\n",
            "162 (5, 1) [D loss: (-21.3)(R 111.9, F -141.6, G 0.8)] [G loss: 129.9]\n",
            "163 (5, 1) [D loss: (-21.9)(R 123.2, F -147.2, G 0.2)] [G loss: 177.7]\n",
            "164 (5, 1) [D loss: (-22.0)(R 89.0, F -115.7, G 0.5)] [G loss: 156.1]\n",
            "165 (5, 1) [D loss: (-22.2)(R 68.9, F -95.7, G 0.5)] [G loss: 109.4]\n",
            "166 (5, 1) [D loss: (-19.1)(R 42.1, F -62.1, G 0.1)] [G loss: 84.3]\n",
            "167 (5, 1) [D loss: (-20.1)(R 39.4, F -61.0, G 0.1)] [G loss: 168.5]\n",
            "168 (5, 1) [D loss: (-23.2)(R 139.7, F -170.7, G 0.8)] [G loss: 141.6]\n",
            "169 (5, 1) [D loss: (-22.5)(R 72.8, F -100.0, G 0.5)] [G loss: 122.0]\n",
            "170 (5, 1) [D loss: (-22.4)(R 76.4, F -103.1, G 0.4)] [G loss: 151.0]\n",
            "171 (5, 1) [D loss: (-21.6)(R 99.2, F -127.4, G 0.7)] [G loss: 122.8]\n",
            "172 (5, 1) [D loss: (-22.5)(R 73.8, F -99.2, G 0.3)] [G loss: 119.9]\n",
            "173 (5, 1) [D loss: (-22.0)(R 71.7, F -98.3, G 0.5)] [G loss: 129.1]\n",
            "174 (5, 1) [D loss: (-21.4)(R 90.6, F -115.5, G 0.4)] [G loss: 146.5]\n",
            "175 (5, 1) [D loss: (-22.4)(R 104.6, F -132.7, G 0.6)] [G loss: 62.0]\n",
            "176 (5, 1) [D loss: (-23.4)(R 140.0, F -173.5, G 1.0)] [G loss: 177.3]\n",
            "177 (5, 1) [D loss: (-21.5)(R 60.3, F -85.5, G 0.4)] [G loss: 89.3]\n",
            "178 (5, 1) [D loss: (-23.1)(R 63.4, F -95.3, G 0.9)] [G loss: 98.9]\n",
            "179 (5, 1) [D loss: (-21.7)(R 64.9, F -96.5, G 1.0)] [G loss: 71.6]\n",
            "180 (5, 1) [D loss: (-23.4)(R 77.4, F -109.0, G 0.8)] [G loss: 114.5]\n",
            "181 (5, 1) [D loss: (-22.8)(R 57.3, F -86.7, G 0.7)] [G loss: 103.8]\n",
            "182 (5, 1) [D loss: (-23.1)(R 93.5, F -129.3, G 1.3)] [G loss: 132.2]\n",
            "183 (5, 1) [D loss: (-22.9)(R 99.6, F -132.8, G 1.0)] [G loss: 89.0]\n",
            "184 (5, 1) [D loss: (-24.4)(R 76.1, F -106.8, G 0.6)] [G loss: 126.8]\n",
            "185 (5, 1) [D loss: (-22.7)(R 77.6, F -107.1, G 0.7)] [G loss: 98.4]\n",
            "186 (5, 1) [D loss: (-22.8)(R 98.0, F -126.1, G 0.5)] [G loss: 171.6]\n",
            "187 (5, 1) [D loss: (-20.5)(R 44.4, F -66.1, G 0.1)] [G loss: 109.5]\n",
            "188 (5, 1) [D loss: (-23.6)(R 88.6, F -121.8, G 1.0)] [G loss: 111.2]\n",
            "189 (5, 1) [D loss: (-20.1)(R 53.4, F -74.7, G 0.1)] [G loss: 90.2]\n",
            "190 (5, 1) [D loss: (-24.1)(R 68.6, F -101.0, G 0.8)] [G loss: 107.2]\n",
            "191 (5, 1) [D loss: (-20.4)(R 33.6, F -55.7, G 0.2)] [G loss: 80.9]\n",
            "192 (5, 1) [D loss: (-24.5)(R 70.8, F -102.6, G 0.7)] [G loss: 113.8]\n",
            "193 (5, 1) [D loss: (-21.4)(R 148.7, F -177.0, G 0.7)] [G loss: 164.4]\n",
            "194 (5, 1) [D loss: (-23.2)(R 161.8, F -194.2, G 0.9)] [G loss: 175.5]\n",
            "195 (5, 1) [D loss: (-21.6)(R 87.8, F -112.7, G 0.3)] [G loss: 126.9]\n",
            "196 (5, 1) [D loss: (-22.1)(R 107.3, F -138.2, G 0.9)] [G loss: 131.8]\n",
            "197 (5, 1) [D loss: (-21.3)(R 74.3, F -102.6, G 0.7)] [G loss: 93.9]\n",
            "198 (5, 1) [D loss: (-19.6)(R 40.5, F -62.9, G 0.3)] [G loss: 75.1]\n",
            "199 (5, 1) [D loss: (-22.3)(R 79.6, F -106.2, G 0.4)] [G loss: 139.5]\n",
            "200 (5, 1) [D loss: (-21.4)(R 39.1, F -66.4, G 0.6)] [G loss: 61.9]\n",
            "201 (5, 1) [D loss: (-19.3)(R 146.3, F -180.0, G 1.4)] [G loss: 115.9]\n",
            "202 (5, 1) [D loss: (-20.4)(R 76.6, F -100.6, G 0.4)] [G loss: 105.3]\n",
            "203 (5, 1) [D loss: (-20.5)(R 88.4, F -116.9, G 0.8)] [G loss: 85.0]\n",
            "204 (5, 1) [D loss: (-20.8)(R 63.6, F -90.0, G 0.6)] [G loss: 104.5]\n",
            "205 (5, 1) [D loss: (-15.9)(R 52.2, F -87.7, G 2.0)] [G loss: 40.0]\n",
            "206 (5, 1) [D loss: (-20.2)(R 92.4, F -115.1, G 0.2)] [G loss: 111.4]\n",
            "207 (5, 1) [D loss: (-22.4)(R 75.9, F -104.2, G 0.6)] [G loss: 105.8]\n",
            "208 (5, 1) [D loss: (-22.4)(R 73.3, F -99.7, G 0.4)] [G loss: 116.5]\n",
            "209 (5, 1) [D loss: (-21.6)(R 92.8, F -124.9, G 1.1)] [G loss: 107.5]\n",
            "210 (5, 1) [D loss: (-17.5)(R 47.8, F -65.9, G 0.1)] [G loss: 94.4]\n",
            "211 (5, 1) [D loss: (-22.5)(R 89.5, F -120.2, G 0.8)] [G loss: 115.1]\n",
            "212 (5, 1) [D loss: (-21.9)(R 80.0, F -112.4, G 1.0)] [G loss: 85.0]\n",
            "213 (5, 1) [D loss: (-22.8)(R 43.9, F -73.9, G 0.7)] [G loss: 79.4]\n",
            "214 (5, 1) [D loss: (-19.7)(R 45.2, F -66.4, G 0.1)] [G loss: 112.1]\n",
            "215 (5, 1) [D loss: (-22.2)(R 23.4, F -49.1, G 0.4)] [G loss: 76.0]\n",
            "216 (5, 1) [D loss: (-21.9)(R 67.0, F -95.5, G 0.7)] [G loss: 98.6]\n",
            "217 (5, 1) [D loss: (-18.6)(R 46.1, F -65.7, G 0.1)] [G loss: 71.1]\n",
            "218 (5, 1) [D loss: (-20.9)(R 115.7, F -149.1, G 1.2)] [G loss: 115.8]\n",
            "219 (5, 1) [D loss: (-22.2)(R 48.7, F -74.7, G 0.4)] [G loss: 82.0]\n",
            "220 (5, 1) [D loss: (-23.0)(R 59.8, F -87.7, G 0.5)] [G loss: 112.1]\n",
            "221 (5, 1) [D loss: (-22.7)(R 55.1, F -85.4, G 0.8)] [G loss: 81.3]\n",
            "222 (5, 1) [D loss: (-22.7)(R 63.9, F -90.5, G 0.4)] [G loss: 110.9]\n",
            "223 (5, 1) [D loss: (-21.7)(R 50.0, F -74.5, G 0.3)] [G loss: 87.9]\n",
            "224 (5, 1) [D loss: (-19.6)(R 75.3, F -107.0, G 1.2)] [G loss: 66.7]\n",
            "225 (5, 1) [D loss: (-23.0)(R 45.7, F -77.2, G 0.9)] [G loss: 70.3]\n",
            "226 (5, 1) [D loss: (-21.7)(R 67.8, F -103.7, G 1.4)] [G loss: 60.4]\n",
            "227 (5, 1) [D loss: (-22.6)(R 54.7, F -84.7, G 0.7)] [G loss: 89.4]\n",
            "228 (5, 1) [D loss: (-22.0)(R 51.9, F -77.0, G 0.3)] [G loss: 98.0]\n",
            "229 (5, 1) [D loss: (-21.6)(R 27.9, F -52.0, G 0.3)] [G loss: 102.6]\n",
            "230 (5, 1) [D loss: (-23.0)(R 94.8, F -122.4, G 0.5)] [G loss: 151.3]\n",
            "231 (5, 1) [D loss: (-23.3)(R 86.9, F -118.4, G 0.8)] [G loss: 118.2]\n",
            "232 (5, 1) [D loss: (-22.3)(R 60.2, F -87.8, G 0.5)] [G loss: 107.0]\n",
            "233 (5, 1) [D loss: (-22.5)(R 43.5, F -73.1, G 0.7)] [G loss: 63.8]\n",
            "234 (5, 1) [D loss: (-19.1)(R 58.4, F -78.9, G 0.1)] [G loss: 97.5]\n",
            "235 (5, 1) [D loss: (-21.7)(R 65.6, F -93.9, G 0.7)] [G loss: 99.1]\n",
            "236 (5, 1) [D loss: (-23.8)(R 74.0, F -103.3, G 0.6)] [G loss: 137.0]\n",
            "237 (5, 1) [D loss: (-21.7)(R 21.2, F -47.1, G 0.4)] [G loss: 92.9]\n",
            "238 (5, 1) [D loss: (-22.0)(R 71.5, F -104.5, G 1.1)] [G loss: 77.5]\n",
            "239 (5, 1) [D loss: (-22.4)(R 62.7, F -91.9, G 0.7)] [G loss: 100.2]\n",
            "240 (5, 1) [D loss: (-22.6)(R 57.9, F -83.6, G 0.3)] [G loss: 106.3]\n",
            "241 (5, 1) [D loss: (-21.1)(R 65.9, F -101.2, G 1.4)] [G loss: 62.5]\n",
            "242 (5, 1) [D loss: (-22.6)(R 36.6, F -66.4, G 0.7)] [G loss: 64.1]\n",
            "243 (5, 1) [D loss: (-21.9)(R 39.6, F -64.6, G 0.3)] [G loss: 88.2]\n",
            "244 (5, 1) [D loss: (-23.9)(R 74.6, F -106.0, G 0.8)] [G loss: 96.0]\n",
            "245 (5, 1) [D loss: (-23.0)(R 104.0, F -142.8, G 1.6)] [G loss: 84.9]\n",
            "246 (5, 1) [D loss: (-19.9)(R 68.6, F -90.0, G 0.2)] [G loss: 133.2]\n",
            "247 (5, 1) [D loss: (-23.4)(R 82.1, F -115.2, G 1.0)] [G loss: 98.4]\n",
            "248 (5, 1) [D loss: (-23.4)(R 42.7, F -69.9, G 0.4)] [G loss: 98.0]\n",
            "249 (5, 1) [D loss: (-22.6)(R 44.0, F -74.7, G 0.8)] [G loss: 70.0]\n",
            "250 (5, 1) [D loss: (-23.1)(R 60.1, F -92.1, G 0.9)] [G loss: 76.1]\n",
            "251 (5, 1) [D loss: (-20.4)(R 57.4, F -90.1, G 1.2)] [G loss: 60.6]\n",
            "252 (5, 1) [D loss: (-22.1)(R 50.0, F -79.4, G 0.7)] [G loss: 80.6]\n",
            "253 (5, 1) [D loss: (-22.4)(R 53.6, F -81.3, G 0.5)] [G loss: 85.0]\n",
            "254 (5, 1) [D loss: (-21.2)(R 64.4, F -97.4, G 1.2)] [G loss: 73.8]\n",
            "255 (5, 1) [D loss: (-26.4)(R 51.7, F -83.9, G 0.6)] [G loss: 108.3]\n",
            "256 (5, 1) [D loss: (-23.2)(R 62.2, F -88.2, G 0.3)] [G loss: 86.4]\n",
            "257 (5, 1) [D loss: (-23.4)(R 37.9, F -64.9, G 0.4)] [G loss: 69.4]\n",
            "258 (5, 1) [D loss: (-24.0)(R 44.3, F -75.0, G 0.7)] [G loss: 77.6]\n",
            "259 (5, 1) [D loss: (-22.6)(R 47.6, F -73.7, G 0.3)] [G loss: 76.7]\n",
            "260 (5, 1) [D loss: (-23.9)(R 52.2, F -81.7, G 0.6)] [G loss: 92.2]\n",
            "261 (5, 1) [D loss: (-22.7)(R 40.9, F -72.1, G 0.9)] [G loss: 59.8]\n",
            "262 (5, 1) [D loss: (-22.6)(R 39.9, F -71.8, G 0.9)] [G loss: 59.4]\n",
            "263 (5, 1) [D loss: (-24.6)(R 38.9, F -72.4, G 0.9)] [G loss: 71.5]\n",
            "264 (5, 1) [D loss: (-22.3)(R 31.2, F -59.8, G 0.6)] [G loss: 63.4]\n",
            "265 (5, 1) [D loss: (-21.8)(R 31.2, F -55.0, G 0.2)] [G loss: 66.8]\n",
            "266 (5, 1) [D loss: (-19.3)(R 67.0, F -104.8, G 1.9)] [G loss: 52.7]\n",
            "267 (5, 1) [D loss: (-22.5)(R 45.4, F -73.3, G 0.5)] [G loss: 90.0]\n",
            "268 (5, 1) [D loss: (-24.4)(R 59.7, F -91.1, G 0.7)] [G loss: 92.0]\n",
            "269 (5, 1) [D loss: (-22.0)(R 59.3, F -90.6, G 0.9)] [G loss: 85.4]\n",
            "270 (5, 1) [D loss: (-23.7)(R 51.6, F -83.4, G 0.8)] [G loss: 82.4]\n",
            "271 (5, 1) [D loss: (-22.5)(R 28.4, F -53.2, G 0.2)] [G loss: 77.4]\n",
            "272 (5, 1) [D loss: (-22.7)(R 47.2, F -73.1, G 0.3)] [G loss: 83.5]\n",
            "273 (5, 1) [D loss: (-21.4)(R 48.6, F -78.3, G 0.8)] [G loss: 66.7]\n",
            "274 (5, 1) [D loss: (-21.9)(R 39.5, F -76.8, G 1.5)] [G loss: 46.9]\n",
            "275 (5, 1) [D loss: (-23.7)(R 33.8, F -61.6, G 0.4)] [G loss: 80.8]\n",
            "276 (5, 1) [D loss: (-22.8)(R 35.4, F -65.1, G 0.7)] [G loss: 66.4]\n",
            "277 (5, 1) [D loss: (-23.6)(R 46.6, F -78.7, G 0.8)] [G loss: 80.5]\n",
            "278 (5, 1) [D loss: (-24.0)(R 37.5, F -66.1, G 0.5)] [G loss: 82.3]\n",
            "279 (5, 1) [D loss: (-22.3)(R 17.2, F -42.6, G 0.3)] [G loss: 67.3]\n",
            "280 (5, 1) [D loss: (-24.3)(R 53.5, F -88.5, G 1.1)] [G loss: 75.2]\n",
            "281 (5, 1) [D loss: (-23.5)(R 28.8, F -56.9, G 0.5)] [G loss: 64.8]\n",
            "282 (5, 1) [D loss: (-24.3)(R 39.0, F -68.7, G 0.5)] [G loss: 80.5]\n",
            "283 (5, 1) [D loss: (-23.4)(R 37.6, F -71.4, G 1.0)] [G loss: 59.1]\n",
            "284 (5, 1) [D loss: (-25.0)(R 30.0, F -60.9, G 0.6)] [G loss: 82.0]\n",
            "285 (5, 1) [D loss: (-23.6)(R 33.1, F -63.0, G 0.6)] [G loss: 63.5]\n",
            "286 (5, 1) [D loss: (-25.0)(R 35.5, F -67.0, G 0.6)] [G loss: 83.7]\n",
            "287 (5, 1) [D loss: (-22.4)(R 5.1, F -31.7, G 0.4)] [G loss: 114.7]\n",
            "288 (5, 1) [D loss: (-24.2)(R 113.9, F -146.2, G 0.8)] [G loss: 146.1]\n",
            "289 (5, 1) [D loss: (-23.3)(R 81.5, F -110.5, G 0.6)] [G loss: 113.0]\n",
            "290 (5, 1) [D loss: (-23.9)(R 94.5, F -131.6, G 1.3)] [G loss: 103.4]\n",
            "291 (5, 1) [D loss: (-23.8)(R 75.5, F -103.4, G 0.4)] [G loss: 126.5]\n",
            "292 (5, 1) [D loss: (-24.1)(R 58.7, F -87.1, G 0.4)] [G loss: 105.2]\n",
            "293 (5, 1) [D loss: (-25.4)(R 65.4, F -98.5, G 0.8)] [G loss: 105.4]\n",
            "294 (5, 1) [D loss: (-22.9)(R 56.8, F -86.5, G 0.7)] [G loss: 83.6]\n",
            "295 (5, 1) [D loss: (-21.7)(R 101.4, F -142.7, G 2.0)] [G loss: 79.1]\n",
            "296 (5, 1) [D loss: (-21.7)(R 29.9, F -55.1, G 0.3)] [G loss: 54.1]\n",
            "297 (5, 1) [D loss: (-22.7)(R 50.0, F -82.4, G 1.0)] [G loss: 67.0]\n",
            "298 (5, 1) [D loss: (-23.3)(R 44.8, F -76.5, G 0.9)] [G loss: 65.5]\n",
            "299 (5, 1) [D loss: (-20.6)(R 27.1, F -48.9, G 0.1)] [G loss: 63.6]\n",
            "300 (5, 1) [D loss: (-22.9)(R 53.2, F -83.7, G 0.8)] [G loss: 78.0]\n",
            "301 (5, 1) [D loss: (-22.2)(R 50.8, F -83.5, G 1.0)] [G loss: 60.1]\n",
            "302 (5, 1) [D loss: (-22.0)(R 46.3, F -75.7, G 0.7)] [G loss: 66.0]\n",
            "303 (5, 1) [D loss: (-23.3)(R 24.4, F -53.7, G 0.6)] [G loss: 63.7]\n",
            "304 (5, 1) [D loss: (-19.8)(R 15.8, F -36.7, G 0.1)] [G loss: 78.4]\n",
            "305 (5, 1) [D loss: (-23.7)(R 61.3, F -91.6, G 0.7)] [G loss: 96.3]\n",
            "306 (5, 1) [D loss: (-23.1)(R 53.4, F -81.8, G 0.5)] [G loss: 88.0]\n",
            "307 (5, 1) [D loss: (-22.3)(R 53.2, F -82.9, G 0.7)] [G loss: 64.6]\n",
            "308 (5, 1) [D loss: (-23.2)(R 56.8, F -87.0, G 0.7)] [G loss: 118.9]\n",
            "309 (5, 1) [D loss: (-20.3)(R 37.2, F -62.1, G 0.5)] [G loss: 63.6]\n",
            "310 (5, 1) [D loss: (-22.5)(R 39.1, F -66.3, G 0.5)] [G loss: 79.6]\n",
            "311 (5, 1) [D loss: (-23.3)(R 65.4, F -95.0, G 0.6)] [G loss: 96.1]\n",
            "312 (5, 1) [D loss: (-22.5)(R 21.3, F -49.3, G 0.6)] [G loss: 58.8]\n",
            "313 (5, 1) [D loss: (-23.2)(R 28.7, F -57.0, G 0.5)] [G loss: 63.6]\n",
            "314 (5, 1) [D loss: (-23.3)(R 27.7, F -58.4, G 0.7)] [G loss: 54.9]\n",
            "315 (5, 1) [D loss: (-22.3)(R 40.2, F -69.3, G 0.7)] [G loss: 69.8]\n",
            "316 (5, 1) [D loss: (-22.2)(R 22.6, F -57.4, G 1.3)] [G loss: 31.7]\n",
            "317 (5, 1) [D loss: (-22.3)(R 76.4, F -101.9, G 0.3)] [G loss: 116.4]\n",
            "318 (5, 1) [D loss: (-23.0)(R 49.9, F -76.3, G 0.3)] [G loss: 90.1]\n",
            "319 (5, 1) [D loss: (-22.4)(R 71.1, F -103.7, G 1.0)] [G loss: 92.4]\n",
            "320 (5, 1) [D loss: (-21.6)(R 41.8, F -66.0, G 0.2)] [G loss: 89.7]\n",
            "321 (5, 1) [D loss: (-23.9)(R 57.6, F -89.8, G 0.8)] [G loss: 89.0]\n",
            "322 (5, 1) [D loss: (-23.2)(R 39.2, F -68.5, G 0.6)] [G loss: 84.0]\n",
            "323 (5, 1) [D loss: (-22.8)(R 50.3, F -77.6, G 0.4)] [G loss: 81.1]\n",
            "324 (5, 1) [D loss: (-21.7)(R 78.4, F -115.3, G 1.5)] [G loss: 61.1]\n",
            "325 (5, 1) [D loss: (-19.9)(R 37.9, F -59.3, G 0.1)] [G loss: 88.0]\n",
            "326 (5, 1) [D loss: (-23.2)(R 41.9, F -71.2, G 0.6)] [G loss: 82.3]\n",
            "327 (5, 1) [D loss: (-23.9)(R 32.6, F -62.7, G 0.6)] [G loss: 67.9]\n",
            "328 (5, 1) [D loss: (-22.7)(R 21.4, F -50.0, G 0.6)] [G loss: 47.8]\n",
            "329 (5, 1) [D loss: (-22.8)(R 15.9, F -45.4, G 0.7)] [G loss: 37.3]\n",
            "330 (5, 1) [D loss: (-20.5)(R 81.3, F -118.6, G 1.7)] [G loss: 66.9]\n",
            "331 (5, 1) [D loss: (-22.0)(R 62.5, F -87.9, G 0.3)] [G loss: 94.7]\n",
            "332 (5, 1) [D loss: (-22.8)(R 54.1, F -84.5, G 0.8)] [G loss: 84.1]\n",
            "333 (5, 1) [D loss: (-23.6)(R 31.7, F -63.4, G 0.8)] [G loss: 55.9]\n",
            "334 (5, 1) [D loss: (-21.8)(R 51.7, F -82.3, G 0.9)] [G loss: 73.3]\n",
            "335 (5, 1) [D loss: (-22.8)(R 42.5, F -70.6, G 0.5)] [G loss: 76.2]\n",
            "336 (5, 1) [D loss: (-22.5)(R 45.6, F -76.8, G 0.9)] [G loss: 65.3]\n",
            "337 (5, 1) [D loss: (-23.0)(R 28.3, F -60.2, G 0.9)] [G loss: 49.3]\n",
            "338 (5, 1) [D loss: (-22.6)(R 24.2, F -51.3, G 0.4)] [G loss: 59.9]\n",
            "339 (5, 1) [D loss: (-24.0)(R 29.3, F -57.8, G 0.5)] [G loss: 86.2]\n",
            "340 (5, 1) [D loss: (-23.6)(R 10.8, F -43.8, G 0.9)] [G loss: 48.8]\n",
            "341 (5, 1) [D loss: (-23.0)(R 36.5, F -68.5, G 0.9)] [G loss: 48.2]\n",
            "342 (5, 1) [D loss: (-23.5)(R 68.9, F -98.8, G 0.6)] [G loss: 112.0]\n",
            "343 (5, 1) [D loss: (-22.2)(R 73.9, F -106.8, G 1.1)] [G loss: 91.9]\n",
            "344 (5, 1) [D loss: (-24.2)(R 50.1, F -81.1, G 0.7)] [G loss: 88.5]\n",
            "345 (5, 1) [D loss: (-23.0)(R 40.9, F -71.9, G 0.8)] [G loss: 70.4]\n",
            "346 (5, 1) [D loss: (-21.8)(R 23.7, F -57.9, G 1.2)] [G loss: 35.0]\n",
            "347 (5, 1) [D loss: (-21.8)(R 23.8, F -48.6, G 0.3)] [G loss: 58.5]\n",
            "348 (5, 1) [D loss: (-22.7)(R 19.7, F -50.1, G 0.8)] [G loss: 48.3]\n",
            "349 (5, 1) [D loss: (-23.0)(R 32.0, F -59.9, G 0.5)] [G loss: 67.5]\n",
            "350 (5, 1) [D loss: (-23.1)(R 24.9, F -56.0, G 0.8)] [G loss: 55.2]\n",
            "351 (5, 1) [D loss: (-24.4)(R 27.9, F -60.0, G 0.8)] [G loss: 63.6]\n",
            "352 (5, 1) [D loss: (-24.2)(R 44.1, F -76.4, G 0.8)] [G loss: 74.3]\n",
            "353 (5, 1) [D loss: (-23.6)(R 38.6, F -73.3, G 1.1)] [G loss: 61.5]\n",
            "354 (5, 1) [D loss: (-23.8)(R 4.2, F -33.4, G 0.5)] [G loss: 77.1]\n",
            "355 (5, 1) [D loss: (-23.1)(R 46.3, F -76.1, G 0.7)] [G loss: 74.6]\n",
            "356 (5, 1) [D loss: (-22.6)(R 31.3, F -61.9, G 0.8)] [G loss: 48.7]\n",
            "357 (5, 1) [D loss: (-24.0)(R 68.3, F -101.7, G 0.9)] [G loss: 77.1]\n",
            "358 (5, 1) [D loss: (-21.0)(R 7.7, F -30.4, G 0.2)] [G loss: 86.6]\n",
            "359 (5, 1) [D loss: (-23.0)(R 32.0, F -60.9, G 0.6)] [G loss: 59.7]\n",
            "360 (5, 1) [D loss: (-23.9)(R 32.5, F -64.8, G 0.8)] [G loss: 69.6]\n",
            "361 (5, 1) [D loss: (-24.2)(R 15.2, F -44.7, G 0.5)] [G loss: 54.5]\n",
            "362 (5, 1) [D loss: (-24.0)(R 41.8, F -70.3, G 0.5)] [G loss: 76.4]\n",
            "363 (5, 1) [D loss: (-24.4)(R 61.7, F -93.2, G 0.7)] [G loss: 105.2]\n",
            "364 (5, 1) [D loss: (-23.7)(R 30.4, F -58.5, G 0.4)] [G loss: 62.2]\n",
            "365 (5, 1) [D loss: (-22.6)(R 30.9, F -61.7, G 0.8)] [G loss: 54.6]\n",
            "366 (5, 1) [D loss: (-23.6)(R 32.7, F -64.4, G 0.8)] [G loss: 68.2]\n",
            "367 (5, 1) [D loss: (-22.1)(R 34.1, F -67.7, G 1.1)] [G loss: 58.5]\n",
            "368 (5, 1) [D loss: (-22.5)(R 30.9, F -57.1, G 0.4)] [G loss: 70.6]\n",
            "369 (5, 1) [D loss: (-23.9)(R 28.0, F -60.2, G 0.8)] [G loss: 53.9]\n",
            "370 (5, 1) [D loss: (-24.2)(R 25.1, F -55.5, G 0.6)] [G loss: 65.6]\n",
            "371 (5, 1) [D loss: (-19.8)(R 15.2, F -35.9, G 0.1)] [G loss: 35.3]\n",
            "372 (5, 1) [D loss: (-21.8)(R 28.7, F -64.2, G 1.4)] [G loss: 43.2]\n",
            "373 (5, 1) [D loss: (-22.9)(R 16.4, F -43.2, G 0.4)] [G loss: 50.7]\n",
            "374 (5, 1) [D loss: (-23.5)(R 27.8, F -58.2, G 0.7)] [G loss: 60.4]\n",
            "375 (5, 1) [D loss: (-24.3)(R 24.6, F -52.8, G 0.4)] [G loss: 67.3]\n",
            "376 (5, 1) [D loss: (-22.8)(R 15.9, F -43.6, G 0.5)] [G loss: 47.1]\n",
            "377 (5, 1) [D loss: (-22.6)(R 18.6, F -48.4, G 0.7)] [G loss: 48.1]\n",
            "378 (5, 1) [D loss: (-23.0)(R 24.9, F -56.5, G 0.9)] [G loss: 44.0]\n",
            "379 (5, 1) [D loss: (-23.9)(R 39.5, F -72.6, G 0.9)] [G loss: 65.6]\n",
            "380 (5, 1) [D loss: (-22.5)(R 20.0, F -51.9, G 0.9)] [G loss: 40.8]\n",
            "381 (5, 1) [D loss: (-22.8)(R 15.1, F -46.1, G 0.8)] [G loss: 41.2]\n",
            "382 (5, 1) [D loss: (-21.8)(R 37.0, F -75.2, G 1.6)] [G loss: 36.7]\n",
            "383 (5, 1) [D loss: (-19.2)(R 51.8, F -72.5, G 0.1)] [G loss: 121.9]\n",
            "384 (5, 1) [D loss: (-22.7)(R 76.5, F -104.4, G 0.5)] [G loss: 110.7]\n",
            "385 (5, 1) [D loss: (-22.6)(R 58.0, F -90.5, G 1.0)] [G loss: 75.9]\n",
            "386 (5, 1) [D loss: (-23.9)(R 54.4, F -86.0, G 0.8)] [G loss: 85.5]\n",
            "387 (5, 1) [D loss: (-23.3)(R 49.8, F -79.9, G 0.7)] [G loss: 89.2]\n",
            "388 (5, 1) [D loss: (-23.3)(R 45.1, F -73.7, G 0.5)] [G loss: 76.7]\n",
            "389 (5, 1) [D loss: (-23.0)(R 33.6, F -59.4, G 0.3)] [G loss: 78.9]\n",
            "390 (5, 1) [D loss: (-23.2)(R 36.7, F -70.8, G 1.1)] [G loss: 56.6]\n",
            "391 (5, 1) [D loss: (-23.4)(R 26.7, F -55.3, G 0.5)] [G loss: 66.6]\n",
            "392 (5, 1) [D loss: (-23.2)(R 33.6, F -63.4, G 0.7)] [G loss: 64.6]\n",
            "393 (5, 1) [D loss: (-23.1)(R 24.0, F -51.7, G 0.5)] [G loss: 68.0]\n",
            "394 (5, 1) [D loss: (-22.7)(R 0.4, F -30.9, G 0.8)] [G loss: 91.9]\n",
            "395 (5, 1) [D loss: (-21.3)(R 50.7, F -74.6, G 0.3)] [G loss: 83.2]\n",
            "396 (5, 1) [D loss: (-24.2)(R 15.0, F -46.4, G 0.7)] [G loss: 51.9]\n",
            "397 (5, 1) [D loss: (-24.1)(R 23.0, F -54.1, G 0.7)] [G loss: 51.2]\n",
            "398 (5, 1) [D loss: (-22.3)(R -0.6, F -34.4, G 1.3)] [G loss: 29.5]\n",
            "399 (5, 1) [D loss: (-23.0)(R 35.2, F -62.4, G 0.4)] [G loss: 75.6]\n",
            "400 (5, 1) [D loss: (-24.2)(R 56.8, F -88.8, G 0.8)] [G loss: 93.9]\n",
            "401 (5, 1) [D loss: (-23.4)(R 18.7, F -49.6, G 0.8)] [G loss: 51.5]\n",
            "402 (5, 1) [D loss: (-23.9)(R 22.4, F -51.2, G 0.5)] [G loss: 65.7]\n",
            "403 (5, 1) [D loss: (-22.6)(R 20.5, F -46.3, G 0.3)] [G loss: 43.1]\n",
            "404 (5, 1) [D loss: (-23.8)(R 37.3, F -67.8, G 0.7)] [G loss: 76.9]\n",
            "405 (5, 1) [D loss: (-23.6)(R 23.7, F -56.8, G 1.0)] [G loss: 64.9]\n",
            "406 (5, 1) [D loss: (-23.4)(R 14.3, F -47.2, G 1.0)] [G loss: 42.9]\n",
            "407 (5, 1) [D loss: (-23.9)(R 19.4, F -51.2, G 0.8)] [G loss: 57.4]\n",
            "408 (5, 1) [D loss: (-23.1)(R 31.4, F -62.3, G 0.8)] [G loss: 61.3]\n",
            "409 (5, 1) [D loss: (-21.9)(R 28.7, F -53.1, G 0.2)] [G loss: 52.2]\n",
            "410 (5, 1) [D loss: (-23.3)(R -0.2, F -27.4, G 0.4)] [G loss: 64.5]\n",
            "411 (5, 1) [D loss: (-21.7)(R 6.2, F -29.1, G 0.1)] [G loss: 40.3]\n",
            "412 (5, 1) [D loss: (-23.3)(R 21.1, F -51.4, G 0.7)] [G loss: 49.7]\n",
            "413 (5, 1) [D loss: (-23.9)(R 26.9, F -55.7, G 0.5)] [G loss: 68.0]\n",
            "414 (5, 1) [D loss: (-23.0)(R 26.9, F -60.0, G 1.0)] [G loss: 56.1]\n",
            "415 (5, 1) [D loss: (-23.9)(R 22.0, F -52.7, G 0.7)] [G loss: 54.3]\n",
            "416 (5, 1) [D loss: (-23.3)(R 15.5, F -47.7, G 0.9)] [G loss: 40.1]\n",
            "417 (5, 1) [D loss: (-22.5)(R 21.8, F -56.6, G 1.2)] [G loss: 47.8]\n",
            "418 (5, 1) [D loss: (-23.5)(R 26.0, F -58.9, G 0.9)] [G loss: 48.6]\n",
            "419 (5, 1) [D loss: (-23.8)(R 23.3, F -53.2, G 0.6)] [G loss: 63.2]\n",
            "420 (5, 1) [D loss: (-24.0)(R 11.5, F -41.9, G 0.6)] [G loss: 43.1]\n",
            "421 (5, 1) [D loss: (-22.6)(R 50.4, F -82.5, G 1.0)] [G loss: 69.8]\n",
            "422 (5, 1) [D loss: (-23.9)(R 46.9, F -80.2, G 1.0)] [G loss: 74.6]\n",
            "423 (5, 1) [D loss: (-24.3)(R 34.8, F -66.6, G 0.7)] [G loss: 70.3]\n",
            "424 (5, 1) [D loss: (-23.3)(R 38.7, F -67.4, G 0.5)] [G loss: 66.0]\n",
            "425 (5, 1) [D loss: (-23.1)(R 27.8, F -55.6, G 0.5)] [G loss: 55.8]\n",
            "426 (5, 1) [D loss: (-23.4)(R 38.9, F -71.3, G 0.9)] [G loss: 59.3]\n",
            "427 (5, 1) [D loss: (-23.8)(R 38.8, F -70.8, G 0.8)] [G loss: 68.2]\n",
            "428 (5, 1) [D loss: (-23.3)(R 17.1, F -46.0, G 0.6)] [G loss: 54.1]\n",
            "429 (5, 1) [D loss: (-23.2)(R 14.4, F -41.4, G 0.4)] [G loss: 52.1]\n",
            "430 (5, 1) [D loss: (-24.4)(R 24.2, F -56.3, G 0.8)] [G loss: 58.0]\n",
            "431 (5, 1) [D loss: (-24.3)(R 27.9, F -57.4, G 0.5)] [G loss: 66.6]\n",
            "432 (5, 1) [D loss: (-22.7)(R 25.2, F -51.0, G 0.3)] [G loss: 62.4]\n",
            "433 (5, 1) [D loss: (-23.3)(R 26.8, F -53.9, G 0.4)] [G loss: 74.5]\n",
            "434 (5, 1) [D loss: (-24.0)(R 7.7, F -41.0, G 0.9)] [G loss: 53.2]\n",
            "435 (5, 1) [D loss: (-23.6)(R 8.6, F -37.6, G 0.5)] [G loss: 48.7]\n",
            "436 (5, 1) [D loss: (-20.4)(R 21.3, F -43.3, G 0.2)] [G loss: 40.9]\n",
            "437 (5, 1) [D loss: (-23.5)(R 48.4, F -77.9, G 0.6)] [G loss: 92.0]\n",
            "438 (5, 1) [D loss: (-22.5)(R 46.4, F -80.8, G 1.2)] [G loss: 61.9]\n",
            "439 (5, 1) [D loss: (-24.4)(R 33.9, F -65.2, G 0.7)] [G loss: 71.7]\n",
            "440 (5, 1) [D loss: (-23.6)(R 29.2, F -59.5, G 0.7)] [G loss: 63.2]\n",
            "441 (5, 1) [D loss: (-22.8)(R 19.7, F -45.0, G 0.2)] [G loss: 67.2]\n",
            "442 (5, 1) [D loss: (-23.6)(R 20.5, F -56.3, G 1.2)] [G loss: 48.7]\n",
            "443 (5, 1) [D loss: (-23.4)(R 19.1, F -48.1, G 0.5)] [G loss: 53.3]\n",
            "444 (5, 1) [D loss: (-23.6)(R 29.1, F -63.9, G 1.1)] [G loss: 53.4]\n",
            "445 (5, 1) [D loss: (-24.0)(R 14.7, F -44.9, G 0.6)] [G loss: 52.6]\n",
            "446 (5, 1) [D loss: (-23.5)(R 13.7, F -41.5, G 0.4)] [G loss: 49.1]\n",
            "447 (5, 1) [D loss: (-24.2)(R 25.5, F -58.1, G 0.8)] [G loss: 56.4]\n",
            "448 (5, 1) [D loss: (-23.1)(R 21.1, F -47.5, G 0.3)] [G loss: 60.2]\n",
            "449 (5, 1) [D loss: (-24.8)(R 30.7, F -63.9, G 0.8)] [G loss: 66.2]\n",
            "450 (5, 1) [D loss: (-24.0)(R 19.0, F -52.2, G 0.9)] [G loss: 48.1]\n",
            "451 (5, 1) [D loss: (-22.7)(R 23.9, F -55.5, G 0.9)] [G loss: 50.5]\n",
            "452 (5, 1) [D loss: (-22.9)(R 22.4, F -55.0, G 1.0)] [G loss: 45.0]\n",
            "453 (5, 1) [D loss: (-23.6)(R 23.1, F -52.9, G 0.6)] [G loss: 66.7]\n",
            "454 (5, 1) [D loss: (-22.9)(R 1.2, F -30.3, G 0.6)] [G loss: 72.5]\n",
            "455 (5, 1) [D loss: (-23.5)(R 52.8, F -90.5, G 1.4)] [G loss: 65.1]\n",
            "456 (5, 1) [D loss: (-22.7)(R 41.7, F -73.8, G 0.9)] [G loss: 65.5]\n",
            "457 (5, 1) [D loss: (-23.6)(R 38.9, F -73.6, G 1.1)] [G loss: 64.3]\n",
            "458 (5, 1) [D loss: (-23.4)(R 20.3, F -50.5, G 0.7)] [G loss: 58.1]\n",
            "459 (5, 1) [D loss: (-24.3)(R 25.7, F -56.9, G 0.7)] [G loss: 59.0]\n",
            "460 (5, 1) [D loss: (-23.4)(R 33.5, F -65.7, G 0.9)] [G loss: 62.9]\n",
            "461 (5, 1) [D loss: (-24.0)(R 24.9, F -57.4, G 0.8)] [G loss: 55.5]\n",
            "462 (5, 1) [D loss: (-24.2)(R 20.0, F -52.7, G 0.8)] [G loss: 50.7]\n",
            "463 (5, 1) [D loss: (-22.4)(R 24.8, F -55.6, G 0.8)] [G loss: 55.1]\n",
            "464 (5, 1) [D loss: (-23.9)(R 21.7, F -53.7, G 0.8)] [G loss: 59.4]\n",
            "465 (5, 1) [D loss: (-23.0)(R 25.9, F -53.3, G 0.4)] [G loss: 53.6]\n",
            "466 (5, 1) [D loss: (-24.0)(R 27.4, F -58.8, G 0.7)] [G loss: 57.1]\n",
            "467 (5, 1) [D loss: (-23.7)(R 31.3, F -60.5, G 0.6)] [G loss: 75.0]\n",
            "468 (5, 1) [D loss: (-23.3)(R 12.4, F -41.3, G 0.6)] [G loss: 53.8]\n",
            "469 (5, 1) [D loss: (-23.2)(R 21.3, F -50.0, G 0.5)] [G loss: 59.6]\n",
            "470 (5, 1) [D loss: (-23.0)(R 26.8, F -59.5, G 1.0)] [G loss: 52.5]\n",
            "471 (5, 1) [D loss: (-23.0)(R 18.7, F -49.6, G 0.8)] [G loss: 49.2]\n",
            "472 (5, 1) [D loss: (-22.5)(R 23.4, F -50.8, G 0.5)] [G loss: 71.2]\n",
            "473 (5, 1) [D loss: (-22.5)(R 5.9, F -32.0, G 0.4)] [G loss: 66.8]\n",
            "474 (5, 1) [D loss: (-24.0)(R 60.5, F -92.5, G 0.8)] [G loss: 89.2]\n",
            "475 (5, 1) [D loss: (-22.5)(R 42.7, F -68.4, G 0.3)] [G loss: 80.6]\n",
            "476 (5, 1) [D loss: (-24.4)(R 37.1, F -70.7, G 0.9)] [G loss: 66.4]\n",
            "477 (5, 1) [D loss: (-23.5)(R 27.1, F -57.7, G 0.7)] [G loss: 59.7]\n",
            "478 (5, 1) [D loss: (-24.0)(R 27.5, F -56.4, G 0.5)] [G loss: 69.6]\n",
            "479 (5, 1) [D loss: (-23.3)(R 27.9, F -56.3, G 0.5)] [G loss: 64.0]\n",
            "480 (5, 1) [D loss: (-24.0)(R 28.0, F -61.8, G 1.0)] [G loss: 55.6]\n",
            "481 (5, 1) [D loss: (-22.3)(R 23.4, F -49.1, G 0.3)] [G loss: 58.9]\n",
            "482 (5, 1) [D loss: (-24.3)(R 24.6, F -55.7, G 0.7)] [G loss: 57.7]\n",
            "483 (5, 1) [D loss: (-22.8)(R 23.1, F -49.9, G 0.4)] [G loss: 54.0]\n",
            "484 (5, 1) [D loss: (-22.6)(R 21.1, F -54.7, G 1.1)] [G loss: 41.9]\n",
            "485 (5, 1) [D loss: (-23.5)(R 11.3, F -43.7, G 0.9)] [G loss: 42.5]\n",
            "486 (5, 1) [D loss: (-23.1)(R 25.3, F -57.7, G 0.9)] [G loss: 53.3]\n",
            "487 (5, 1) [D loss: (-22.6)(R 25.7, F -51.2, G 0.3)] [G loss: 60.6]\n",
            "488 (5, 1) [D loss: (-24.5)(R 17.7, F -48.2, G 0.6)] [G loss: 53.7]\n",
            "489 (5, 1) [D loss: (-23.9)(R 13.4, F -45.2, G 0.8)] [G loss: 40.2]\n",
            "490 (5, 1) [D loss: (-24.1)(R 13.8, F -43.7, G 0.6)] [G loss: 51.0]\n",
            "491 (5, 1) [D loss: (-23.9)(R 14.4, F -48.4, G 1.0)] [G loss: 48.0]\n",
            "492 (5, 1) [D loss: (-22.6)(R 18.8, F -54.1, G 1.3)] [G loss: 41.4]\n",
            "493 (5, 1) [D loss: (-23.1)(R 20.6, F -54.8, G 1.1)] [G loss: 45.4]\n",
            "494 (5, 1) [D loss: (-24.0)(R 15.6, F -48.0, G 0.8)] [G loss: 41.5]\n",
            "495 (5, 1) [D loss: (-22.8)(R 16.5, F -43.3, G 0.4)] [G loss: 50.7]\n",
            "496 (5, 1) [D loss: (-23.6)(R 6.7, F -35.2, G 0.5)] [G loss: 51.0]\n",
            "497 (5, 1) [D loss: (-23.4)(R 19.4, F -50.7, G 0.8)] [G loss: 47.1]\n",
            "498 (5, 1) [D loss: (-23.0)(R 21.1, F -52.5, G 0.8)] [G loss: 47.4]\n",
            "499 (5, 1) [D loss: (-22.4)(R 17.9, F -48.6, G 0.8)] [G loss: 42.1]\n",
            "500 (5, 1) [D loss: (-22.8)(R 21.8, F -54.2, G 1.0)] [G loss: 53.8]\n",
            "501 (5, 1) [D loss: (-23.3)(R 15.4, F -44.7, G 0.6)] [G loss: 49.3]\n",
            "502 (5, 1) [D loss: (-23.5)(R 14.9, F -48.3, G 1.0)] [G loss: 42.5]\n",
            "503 (5, 1) [D loss: (-22.2)(R 16.4, F -46.9, G 0.8)] [G loss: 40.5]\n",
            "504 (5, 1) [D loss: (-23.5)(R 16.9, F -46.4, G 0.6)] [G loss: 49.8]\n",
            "505 (5, 1) [D loss: (-23.6)(R 17.4, F -45.9, G 0.5)] [G loss: 54.3]\n",
            "506 (5, 1) [D loss: (-23.5)(R 18.0, F -50.7, G 0.9)] [G loss: 45.5]\n",
            "507 (5, 1) [D loss: (-23.4)(R 19.9, F -48.9, G 0.6)] [G loss: 53.0]\n",
            "508 (5, 1) [D loss: (-22.8)(R 18.4, F -43.8, G 0.3)] [G loss: 45.6]\n",
            "509 (5, 1) [D loss: (-23.6)(R 12.3, F -40.0, G 0.4)] [G loss: 53.8]\n",
            "510 (5, 1) [D loss: (-23.4)(R 13.2, F -43.3, G 0.7)] [G loss: 46.4]\n",
            "511 (5, 1) [D loss: (-22.6)(R 8.6, F -33.6, G 0.2)] [G loss: 52.2]\n",
            "512 (5, 1) [D loss: (-23.1)(R 13.3, F -40.7, G 0.4)] [G loss: 46.7]\n",
            "513 (5, 1) [D loss: (-24.9)(R 16.7, F -49.4, G 0.8)] [G loss: 58.5]\n",
            "514 (5, 1) [D loss: (-23.8)(R 14.6, F -45.9, G 0.7)] [G loss: 50.9]\n",
            "515 (5, 1) [D loss: (-23.9)(R 13.8, F -44.4, G 0.7)] [G loss: 48.4]\n",
            "516 (5, 1) [D loss: (-23.9)(R 20.4, F -51.6, G 0.7)] [G loss: 54.8]\n",
            "517 (5, 1) [D loss: (-24.3)(R 14.8, F -45.5, G 0.6)] [G loss: 88.7]\n",
            "518 (5, 1) [D loss: (-23.8)(R 24.0, F -55.6, G 0.8)] [G loss: 55.2]\n",
            "519 (5, 1) [D loss: (-23.3)(R 9.3, F -44.8, G 1.2)] [G loss: 36.6]\n",
            "520 (5, 1) [D loss: (-23.7)(R 24.9, F -57.2, G 0.9)] [G loss: 51.8]\n",
            "521 (5, 1) [D loss: (-23.6)(R 12.7, F -43.9, G 0.8)] [G loss: 44.7]\n",
            "522 (5, 1) [D loss: (-21.0)(R 20.0, F -42.7, G 0.2)] [G loss: 52.4]\n",
            "523 (5, 1) [D loss: (-24.4)(R 21.8, F -54.0, G 0.8)] [G loss: 62.0]\n",
            "524 (5, 1) [D loss: (-23.5)(R 12.0, F -39.1, G 0.4)] [G loss: 53.8]\n",
            "525 (5, 1) [D loss: (-23.8)(R 20.9, F -50.3, G 0.6)] [G loss: 50.6]\n",
            "526 (5, 1) [D loss: (-24.0)(R 14.6, F -46.3, G 0.8)] [G loss: 47.6]\n",
            "527 (5, 1) [D loss: (-24.2)(R 16.6, F -48.7, G 0.8)] [G loss: 54.0]\n",
            "528 (5, 1) [D loss: (-23.4)(R 12.4, F -41.8, G 0.6)] [G loss: 46.4]\n",
            "529 (5, 1) [D loss: (-23.3)(R 16.5, F -47.5, G 0.8)] [G loss: 42.7]\n",
            "530 (5, 1) [D loss: (-23.3)(R 14.8, F -41.9, G 0.4)] [G loss: 51.7]\n",
            "531 (5, 1) [D loss: (-23.2)(R 19.7, F -47.3, G 0.4)] [G loss: 53.4]\n",
            "532 (5, 1) [D loss: (-23.8)(R 15.7, F -47.5, G 0.8)] [G loss: 47.2]\n",
            "533 (5, 1) [D loss: (-23.1)(R 7.6, F -36.1, G 0.5)] [G loss: 39.0]\n",
            "534 (5, 1) [D loss: (-22.6)(R 14.5, F -44.9, G 0.8)] [G loss: 41.8]\n",
            "535 (5, 1) [D loss: (-23.0)(R 9.1, F -35.4, G 0.3)] [G loss: 49.8]\n",
            "536 (5, 1) [D loss: (-23.0)(R 16.4, F -46.2, G 0.7)] [G loss: 44.3]\n",
            "537 (5, 1) [D loss: (-23.6)(R 8.3, F -38.8, G 0.7)] [G loss: 37.2]\n",
            "538 (5, 1) [D loss: (-23.6)(R 15.6, F -43.9, G 0.5)] [G loss: 47.8]\n",
            "539 (5, 1) [D loss: (-23.1)(R 11.7, F -40.1, G 0.5)] [G loss: 44.2]\n",
            "540 (5, 1) [D loss: (-23.9)(R 21.0, F -49.5, G 0.5)] [G loss: 57.5]\n",
            "541 (5, 1) [D loss: (-23.7)(R 19.3, F -49.6, G 0.7)] [G loss: 55.1]\n",
            "542 (5, 1) [D loss: (-23.8)(R 14.7, F -46.3, G 0.8)] [G loss: 43.7]\n",
            "543 (5, 1) [D loss: (-24.1)(R 10.1, F -40.9, G 0.7)] [G loss: 38.2]\n",
            "544 (5, 1) [D loss: (-23.5)(R 13.4, F -43.1, G 0.6)] [G loss: 44.3]\n",
            "545 (5, 1) [D loss: (-23.3)(R 12.7, F -43.3, G 0.7)] [G loss: 44.6]\n",
            "546 (5, 1) [D loss: (-24.0)(R 13.0, F -46.1, G 0.9)] [G loss: 39.0]\n",
            "547 (5, 1) [D loss: (-24.1)(R 12.4, F -43.0, G 0.7)] [G loss: 41.5]\n",
            "548 (5, 1) [D loss: (-23.2)(R 30.0, F -57.9, G 0.5)] [G loss: 61.3]\n",
            "549 (5, 1) [D loss: (-23.9)(R 14.5, F -44.5, G 0.6)] [G loss: 47.6]\n",
            "550 (5, 1) [D loss: (-24.1)(R 7.8, F -43.2, G 1.1)] [G loss: 43.5]\n",
            "551 (5, 1) [D loss: (-23.6)(R 15.2, F -47.6, G 0.9)] [G loss: 44.0]\n",
            "552 (5, 1) [D loss: (-23.0)(R 9.1, F -35.2, G 0.3)] [G loss: 49.2]\n",
            "553 (5, 1) [D loss: (-24.4)(R 9.3, F -39.6, G 0.6)] [G loss: 44.3]\n",
            "554 (5, 1) [D loss: (-22.5)(R 16.3, F -47.0, G 0.8)] [G loss: 42.5]\n",
            "555 (5, 1) [D loss: (-24.8)(R 22.0, F -55.5, G 0.9)] [G loss: 60.4]\n",
            "556 (5, 1) [D loss: (-25.1)(R 18.8, F -53.4, G 1.0)] [G loss: 53.4]\n",
            "557 (5, 1) [D loss: (-23.1)(R 20.5, F -53.5, G 1.0)] [G loss: 48.1]\n",
            "558 (5, 1) [D loss: (-22.3)(R 18.8, F -54.4, G 1.3)] [G loss: 41.9]\n",
            "559 (5, 1) [D loss: (-24.1)(R 10.6, F -40.3, G 0.6)] [G loss: 44.5]\n",
            "560 (5, 1) [D loss: (-23.9)(R 10.0, F -38.5, G 0.5)] [G loss: 47.2]\n",
            "561 (5, 1) [D loss: (-23.0)(R 16.3, F -45.3, G 0.6)] [G loss: 48.4]\n",
            "562 (5, 1) [D loss: (-24.0)(R 14.4, F -48.1, G 1.0)] [G loss: 47.0]\n",
            "563 (5, 1) [D loss: (-24.4)(R 15.2, F -46.7, G 0.7)] [G loss: 47.4]\n",
            "564 (5, 1) [D loss: (-23.3)(R 27.3, F -61.6, G 1.1)] [G loss: 44.6]\n",
            "565 (5, 1) [D loss: (-22.9)(R 31.6, F -65.0, G 1.0)] [G loss: 36.7]\n",
            "566 (5, 1) [D loss: (-22.9)(R 21.9, F -53.9, G 0.9)] [G loss: 46.2]\n",
            "567 (5, 1) [D loss: (-23.2)(R 15.1, F -40.9, G 0.3)] [G loss: 48.5]\n",
            "568 (5, 1) [D loss: (-25.9)(R 11.8, F -45.3, G 0.8)] [G loss: 52.0]\n",
            "569 (5, 1) [D loss: (-23.0)(R 11.7, F -37.9, G 0.3)] [G loss: 42.1]\n",
            "570 (5, 1) [D loss: (-23.0)(R 22.4, F -54.5, G 0.9)] [G loss: 47.5]\n",
            "571 (5, 1) [D loss: (-24.1)(R 9.1, F -42.7, G 0.9)] [G loss: 48.1]\n",
            "572 (5, 1) [D loss: (-23.5)(R 12.2, F -45.0, G 0.9)] [G loss: 33.7]\n",
            "573 (5, 1) [D loss: (-22.7)(R 33.0, F -65.1, G 0.9)] [G loss: 52.5]\n",
            "574 (5, 1) [D loss: (-23.1)(R 13.9, F -44.0, G 0.7)] [G loss: 47.5]\n",
            "575 (5, 1) [D loss: (-23.3)(R 14.9, F -42.7, G 0.5)] [G loss: 46.5]\n",
            "576 (5, 1) [D loss: (-23.5)(R 17.9, F -46.5, G 0.5)] [G loss: 43.9]\n",
            "577 (5, 1) [D loss: (-24.0)(R 21.7, F -54.2, G 0.8)] [G loss: 48.2]\n",
            "578 (5, 1) [D loss: (-23.8)(R 6.2, F -36.5, G 0.7)] [G loss: 39.2]\n",
            "579 (5, 1) [D loss: (-24.0)(R 16.5, F -46.8, G 0.6)] [G loss: 44.9]\n",
            "580 (5, 1) [D loss: (-22.5)(R 23.0, F -57.1, G 1.2)] [G loss: 35.4]\n",
            "581 (5, 1) [D loss: (-25.1)(R 15.6, F -48.4, G 0.8)] [G loss: 51.9]\n",
            "582 (5, 1) [D loss: (-23.3)(R 15.4, F -45.0, G 0.6)] [G loss: 50.4]\n",
            "583 (5, 1) [D loss: (-24.5)(R 21.4, F -57.3, G 1.1)] [G loss: 48.9]\n",
            "584 (5, 1) [D loss: (-23.0)(R 13.3, F -46.7, G 1.0)] [G loss: 44.3]\n",
            "585 (5, 1) [D loss: (-23.5)(R 14.2, F -43.4, G 0.6)] [G loss: 52.6]\n",
            "586 (5, 1) [D loss: (-24.7)(R 17.7, F -48.9, G 0.6)] [G loss: 56.2]\n",
            "587 (5, 1) [D loss: (-22.7)(R 10.9, F -47.4, G 1.4)] [G loss: 38.2]\n",
            "588 (5, 1) [D loss: (-23.6)(R 6.6, F -38.1, G 0.8)] [G loss: 36.2]\n",
            "589 (5, 1) [D loss: (-23.6)(R 15.1, F -44.4, G 0.6)] [G loss: 49.5]\n",
            "590 (5, 1) [D loss: (-24.0)(R 17.5, F -49.9, G 0.8)] [G loss: 45.9]\n",
            "591 (5, 1) [D loss: (-24.1)(R 15.8, F -44.3, G 0.4)] [G loss: 60.1]\n",
            "592 (5, 1) [D loss: (-23.2)(R -1.1, F -26.0, G 0.4)] [G loss: 43.9]\n",
            "593 (5, 1) [D loss: (-23.0)(R 18.2, F -47.5, G 0.6)] [G loss: 46.7]\n",
            "594 (5, 1) [D loss: (-24.1)(R 16.0, F -47.3, G 0.7)] [G loss: 44.4]\n",
            "595 (5, 1) [D loss: (-23.2)(R 20.6, F -52.4, G 0.9)] [G loss: 50.2]\n",
            "596 (5, 1) [D loss: (-23.9)(R 13.2, F -47.7, G 1.1)] [G loss: 38.7]\n",
            "597 (5, 1) [D loss: (-24.3)(R 8.5, F -41.7, G 0.9)] [G loss: 41.3]\n",
            "598 (5, 1) [D loss: (-24.0)(R 20.9, F -52.4, G 0.7)] [G loss: 49.7]\n",
            "599 (5, 1) [D loss: (-23.5)(R 10.3, F -40.6, G 0.7)] [G loss: 43.0]\n",
            "600 (5, 1) [D loss: (-23.8)(R 11.6, F -39.6, G 0.4)] [G loss: 49.5]\n",
            "601 (5, 1) [D loss: (-23.2)(R 3.6, F -32.4, G 0.6)] [G loss: 49.3]\n",
            "602 (5, 1) [D loss: (-23.5)(R 22.2, F -57.1, G 1.1)] [G loss: 51.5]\n",
            "603 (5, 1) [D loss: (-22.9)(R 20.9, F -50.5, G 0.7)] [G loss: 48.4]\n",
            "604 (5, 1) [D loss: (-23.7)(R 15.9, F -46.3, G 0.7)] [G loss: 49.2]\n",
            "605 (5, 1) [D loss: (-23.5)(R 11.2, F -41.3, G 0.7)] [G loss: 44.6]\n",
            "606 (5, 1) [D loss: (-23.4)(R 9.4, F -38.4, G 0.6)] [G loss: 46.3]\n",
            "607 (5, 1) [D loss: (-22.5)(R 4.6, F -29.5, G 0.2)] [G loss: 47.2]\n",
            "608 (5, 1) [D loss: (-25.1)(R 16.6, F -50.8, G 0.9)] [G loss: 45.3]\n",
            "609 (5, 1) [D loss: (-23.4)(R 12.6, F -47.7, G 1.2)] [G loss: 43.9]\n",
            "610 (5, 1) [D loss: (-22.9)(R 11.5, F -40.7, G 0.6)] [G loss: 45.9]\n",
            "611 (5, 1) [D loss: (-24.2)(R 9.7, F -43.3, G 0.9)] [G loss: 38.2]\n",
            "612 (5, 1) [D loss: (-24.7)(R 14.7, F -45.9, G 0.7)] [G loss: 50.5]\n",
            "613 (5, 1) [D loss: (-23.7)(R 5.0, F -35.7, G 0.7)] [G loss: 39.3]\n",
            "614 (5, 1) [D loss: (-23.9)(R 11.6, F -45.2, G 1.0)] [G loss: 37.2]\n",
            "615 (5, 1) [D loss: (-23.2)(R 21.6, F -55.3, G 1.1)] [G loss: 38.7]\n",
            "616 (5, 1) [D loss: (-23.8)(R 26.0, F -58.4, G 0.8)] [G loss: 56.8]\n",
            "617 (5, 1) [D loss: (-24.4)(R 12.6, F -43.3, G 0.6)] [G loss: 55.5]\n",
            "618 (5, 1) [D loss: (-23.3)(R 47.1, F -74.7, G 0.4)] [G loss: 70.5]\n",
            "619 (5, 1) [D loss: (-24.2)(R 38.8, F -69.4, G 0.6)] [G loss: 72.2]\n",
            "620 (5, 1) [D loss: (-23.9)(R 30.3, F -62.7, G 0.9)] [G loss: 56.5]\n",
            "621 (5, 1) [D loss: (-23.9)(R 36.3, F -69.4, G 0.9)] [G loss: 63.9]\n",
            "622 (5, 1) [D loss: (-24.1)(R 30.0, F -61.1, G 0.7)] [G loss: 66.5]\n",
            "623 (5, 1) [D loss: (-23.6)(R 22.5, F -56.5, G 1.0)] [G loss: 47.4]\n",
            "624 (5, 1) [D loss: (-23.6)(R 24.3, F -52.4, G 0.4)] [G loss: 54.0]\n",
            "625 (5, 1) [D loss: (-22.4)(R 26.0, F -61.5, G 1.3)] [G loss: 48.1]\n",
            "626 (5, 1) [D loss: (-23.1)(R 23.0, F -54.2, G 0.8)] [G loss: 51.4]\n",
            "627 (5, 1) [D loss: (-24.3)(R 18.8, F -49.6, G 0.6)] [G loss: 55.0]\n",
            "628 (5, 1) [D loss: (-22.8)(R 17.5, F -43.7, G 0.3)] [G loss: 53.6]\n",
            "629 (5, 1) [D loss: (-25.3)(R 8.8, F -46.5, G 1.2)] [G loss: 39.8]\n",
            "630 (5, 1) [D loss: (-24.8)(R 14.7, F -45.8, G 0.6)] [G loss: 48.0]\n",
            "631 (5, 1) [D loss: (-24.1)(R 13.0, F -45.8, G 0.9)] [G loss: 45.2]\n",
            "632 (5, 1) [D loss: (-23.9)(R 11.4, F -38.5, G 0.3)] [G loss: 54.7]\n",
            "633 (5, 1) [D loss: (-23.7)(R 15.0, F -48.0, G 0.9)] [G loss: 40.1]\n",
            "634 (5, 1) [D loss: (-25.0)(R 19.8, F -54.4, G 1.0)] [G loss: 49.8]\n",
            "635 (5, 1) [D loss: (-23.9)(R 15.9, F -43.8, G 0.4)] [G loss: 49.0]\n",
            "636 (5, 1) [D loss: (-25.4)(R 31.2, F -64.9, G 0.8)] [G loss: 67.1]\n",
            "637 (5, 1) [D loss: (-24.4)(R 26.1, F -57.1, G 0.7)] [G loss: 58.9]\n",
            "638 (5, 1) [D loss: (-23.1)(R 23.5, F -57.2, G 1.0)] [G loss: 48.2]\n",
            "639 (5, 1) [D loss: (-23.6)(R 22.8, F -60.0, G 1.4)] [G loss: 47.7]\n",
            "640 (5, 1) [D loss: (-24.8)(R 8.8, F -42.7, G 0.9)] [G loss: 33.2]\n",
            "641 (5, 1) [D loss: (-24.3)(R 12.9, F -46.3, G 0.9)] [G loss: 46.6]\n",
            "642 (5, 1) [D loss: (-23.6)(R 14.7, F -44.5, G 0.6)] [G loss: 44.8]\n",
            "643 (5, 1) [D loss: (-25.0)(R 6.2, F -39.1, G 0.8)] [G loss: 42.2]\n",
            "644 (5, 1) [D loss: (-23.6)(R 0.2, F -36.8, G 1.3)] [G loss: 34.3]\n",
            "645 (5, 1) [D loss: (-23.7)(R 1.5, F -31.8, G 0.7)] [G loss: 62.3]\n",
            "646 (5, 1) [D loss: (-24.2)(R 31.3, F -62.7, G 0.7)] [G loss: 60.3]\n",
            "647 (5, 1) [D loss: (-24.6)(R 22.5, F -54.8, G 0.8)] [G loss: 53.2]\n",
            "648 (5, 1) [D loss: (-23.3)(R 22.1, F -53.0, G 0.8)] [G loss: 51.0]\n",
            "649 (5, 1) [D loss: (-24.8)(R 11.2, F -42.9, G 0.7)] [G loss: 47.1]\n",
            "650 (5, 1) [D loss: (-25.0)(R 15.1, F -51.4, G 1.1)] [G loss: 45.0]\n",
            "651 (5, 1) [D loss: (-23.9)(R 15.0, F -49.0, G 1.0)] [G loss: 52.6]\n",
            "652 (5, 1) [D loss: (-24.4)(R 14.7, F -49.6, G 1.0)] [G loss: 46.8]\n",
            "653 (5, 1) [D loss: (-24.1)(R 13.6, F -45.0, G 0.7)] [G loss: 46.0]\n",
            "654 (5, 1) [D loss: (-25.2)(R 13.0, F -45.1, G 0.7)] [G loss: 49.7]\n",
            "655 (5, 1) [D loss: (-23.7)(R 13.3, F -44.8, G 0.8)] [G loss: 48.0]\n",
            "656 (5, 1) [D loss: (-24.8)(R 14.0, F -47.3, G 0.9)] [G loss: 49.3]\n",
            "657 (5, 1) [D loss: (-25.3)(R 8.7, F -40.4, G 0.6)] [G loss: 49.1]\n",
            "658 (5, 1) [D loss: (-22.8)(R 3.0, F -28.2, G 0.2)] [G loss: 41.9]\n",
            "659 (5, 1) [D loss: (-23.9)(R 11.7, F -46.0, G 1.0)] [G loss: 38.4]\n",
            "660 (5, 1) [D loss: (-23.9)(R 10.8, F -42.8, G 0.8)] [G loss: 40.7]\n",
            "661 (5, 1) [D loss: (-24.3)(R 11.6, F -45.5, G 1.0)] [G loss: 45.5]\n",
            "662 (5, 1) [D loss: (-25.3)(R 14.3, F -47.6, G 0.8)] [G loss: 56.2]\n",
            "663 (5, 1) [D loss: (-24.4)(R 10.0, F -42.4, G 0.8)] [G loss: 41.8]\n",
            "664 (5, 1) [D loss: (-25.4)(R -0.4, F -35.7, G 1.1)] [G loss: 36.6]\n",
            "665 (5, 1) [D loss: (-24.6)(R 11.3, F -39.6, G 0.4)] [G loss: 48.9]\n",
            "666 (5, 1) [D loss: (-22.3)(R 13.3, F -37.6, G 0.2)] [G loss: 37.6]\n",
            "667 (5, 1) [D loss: (-23.9)(R 16.0, F -50.3, G 1.0)] [G loss: 48.9]\n",
            "668 (5, 1) [D loss: (-24.2)(R 17.0, F -49.3, G 0.8)] [G loss: 45.7]\n",
            "669 (5, 1) [D loss: (-24.1)(R 8.0, F -45.7, G 1.4)] [G loss: 37.9]\n",
            "670 (5, 1) [D loss: (-24.4)(R 5.7, F -38.5, G 0.8)] [G loss: 51.2]\n",
            "671 (5, 1) [D loss: (-25.8)(R 21.4, F -55.4, G 0.8)] [G loss: 56.1]\n",
            "672 (5, 1) [D loss: (-25.0)(R 12.1, F -45.0, G 0.8)] [G loss: 48.9]\n",
            "673 (5, 1) [D loss: (-23.6)(R 5.8, F -35.5, G 0.6)] [G loss: 35.3]\n",
            "674 (5, 1) [D loss: (-23.8)(R 11.4, F -41.7, G 0.7)] [G loss: 47.3]\n",
            "675 (5, 1) [D loss: (-24.3)(R 13.4, F -45.7, G 0.8)] [G loss: 50.8]\n",
            "676 (5, 1) [D loss: (-24.4)(R 13.5, F -43.7, G 0.6)] [G loss: 49.4]\n",
            "677 (5, 1) [D loss: (-25.7)(R 15.4, F -47.4, G 0.6)] [G loss: 53.2]\n",
            "678 (5, 1) [D loss: (-24.0)(R 4.6, F -38.3, G 1.0)] [G loss: 55.0]\n",
            "679 (5, 1) [D loss: (-23.3)(R 29.0, F -62.9, G 1.1)] [G loss: 44.8]\n",
            "680 (5, 1) [D loss: (-25.2)(R 20.6, F -52.6, G 0.7)] [G loss: 64.9]\n",
            "681 (5, 1) [D loss: (-22.8)(R 5.3, F -31.3, G 0.3)] [G loss: 34.6]\n",
            "682 (5, 1) [D loss: (-24.7)(R 7.9, F -41.4, G 0.9)] [G loss: 42.3]\n",
            "683 (5, 1) [D loss: (-24.5)(R 9.9, F -44.3, G 1.0)] [G loss: 41.8]\n",
            "684 (5, 1) [D loss: (-24.5)(R 7.4, F -42.7, G 1.1)] [G loss: 35.6]\n",
            "685 (5, 1) [D loss: (-23.8)(R 6.1, F -35.5, G 0.6)] [G loss: 36.7]\n",
            "686 (5, 1) [D loss: (-24.6)(R 0.4, F -32.2, G 0.7)] [G loss: 46.0]\n",
            "687 (5, 1) [D loss: (-23.9)(R 14.8, F -42.7, G 0.4)] [G loss: 50.4]\n",
            "688 (5, 1) [D loss: (-23.2)(R 14.9, F -44.1, G 0.6)] [G loss: 41.9]\n",
            "689 (5, 1) [D loss: (-23.3)(R 20.8, F -57.3, G 1.3)] [G loss: 44.6]\n",
            "690 (5, 1) [D loss: (-23.8)(R 12.0, F -44.8, G 0.9)] [G loss: 44.4]\n",
            "691 (5, 1) [D loss: (-24.4)(R 11.6, F -44.2, G 0.8)] [G loss: 42.5]\n",
            "692 (5, 1) [D loss: (-24.1)(R 14.8, F -46.9, G 0.8)] [G loss: 43.1]\n",
            "693 (5, 1) [D loss: (-23.3)(R 10.5, F -42.7, G 0.9)] [G loss: 33.1]\n",
            "694 (5, 1) [D loss: (-24.5)(R 25.0, F -56.2, G 0.7)] [G loss: 64.3]\n",
            "695 (5, 1) [D loss: (-23.5)(R 14.9, F -42.9, G 0.5)] [G loss: 44.9]\n",
            "696 (5, 1) [D loss: (-24.5)(R 6.2, F -36.6, G 0.6)] [G loss: 42.8]\n",
            "697 (5, 1) [D loss: (-24.1)(R 8.1, F -42.4, G 1.0)] [G loss: 39.4]\n",
            "698 (5, 1) [D loss: (-24.5)(R 5.3, F -37.5, G 0.8)] [G loss: 39.8]\n",
            "699 (5, 1) [D loss: (-23.4)(R 9.8, F -44.9, G 1.2)] [G loss: 30.0]\n",
            "700 (5, 1) [D loss: (-25.0)(R 15.0, F -47.8, G 0.8)] [G loss: 48.0]\n",
            "701 (5, 1) [D loss: (-23.5)(R 7.5, F -41.1, G 1.0)] [G loss: 32.0]\n",
            "702 (5, 1) [D loss: (-24.7)(R 13.7, F -45.6, G 0.7)] [G loss: 46.7]\n",
            "703 (5, 1) [D loss: (-24.1)(R 17.1, F -47.2, G 0.6)] [G loss: 48.1]\n",
            "704 (5, 1) [D loss: (-23.8)(R 7.4, F -43.2, G 1.2)] [G loss: 41.3]\n",
            "705 (5, 1) [D loss: (-24.6)(R 1.6, F -34.2, G 0.8)] [G loss: 46.0]\n",
            "706 (5, 1) [D loss: (-25.0)(R 10.4, F -42.9, G 0.7)] [G loss: 43.1]\n",
            "707 (5, 1) [D loss: (-24.9)(R 5.5, F -39.2, G 0.9)] [G loss: 37.3]\n",
            "708 (5, 1) [D loss: (-23.0)(R 17.8, F -52.4, G 1.2)] [G loss: 40.6]\n",
            "709 (5, 1) [D loss: (-24.2)(R 16.2, F -45.8, G 0.5)] [G loss: 51.1]\n",
            "710 (5, 1) [D loss: (-24.8)(R 7.7, F -39.1, G 0.7)] [G loss: 43.9]\n",
            "711 (5, 1) [D loss: (-24.3)(R 7.6, F -37.5, G 0.6)] [G loss: 38.8]\n",
            "712 (5, 1) [D loss: (-24.7)(R 7.0, F -38.7, G 0.7)] [G loss: 45.1]\n",
            "713 (5, 1) [D loss: (-24.5)(R 7.5, F -40.0, G 0.8)] [G loss: 42.1]\n",
            "714 (5, 1) [D loss: (-24.6)(R 15.2, F -47.3, G 0.7)] [G loss: 51.9]\n",
            "715 (5, 1) [D loss: (-25.4)(R 12.3, F -48.0, G 1.0)] [G loss: 49.4]\n",
            "716 (5, 1) [D loss: (-23.4)(R 18.8, F -47.6, G 0.5)] [G loss: 60.5]\n",
            "717 (5, 1) [D loss: (-24.3)(R 7.2, F -36.8, G 0.5)] [G loss: 46.2]\n",
            "718 (5, 1) [D loss: (-24.7)(R 8.2, F -41.6, G 0.9)] [G loss: 43.6]\n",
            "719 (5, 1) [D loss: (-24.0)(R 17.8, F -50.3, G 0.9)] [G loss: 48.2]\n",
            "720 (5, 1) [D loss: (-23.5)(R 14.5, F -49.0, G 1.1)] [G loss: 33.8]\n",
            "721 (5, 1) [D loss: (-24.3)(R 14.8, F -45.4, G 0.6)] [G loss: 53.2]\n",
            "722 (5, 1) [D loss: (-23.2)(R 19.0, F -52.9, G 1.1)] [G loss: 45.1]\n",
            "723 (5, 1) [D loss: (-25.4)(R 24.7, F -56.2, G 0.6)] [G loss: 58.3]\n",
            "724 (5, 1) [D loss: (-24.2)(R 9.4, F -41.5, G 0.8)] [G loss: 39.5]\n",
            "725 (5, 1) [D loss: (-25.0)(R 11.1, F -41.4, G 0.5)] [G loss: 46.5]\n",
            "726 (5, 1) [D loss: (-24.3)(R 12.4, F -42.9, G 0.6)] [G loss: 49.2]\n",
            "727 (5, 1) [D loss: (-24.8)(R 8.0, F -42.2, G 0.9)] [G loss: 38.6]\n",
            "728 (5, 1) [D loss: (-24.4)(R 3.4, F -32.8, G 0.5)] [G loss: 40.6]\n",
            "729 (5, 1) [D loss: (-24.0)(R 16.9, F -45.6, G 0.5)] [G loss: 55.7]\n",
            "730 (5, 1) [D loss: (-25.1)(R 12.8, F -47.0, G 0.9)] [G loss: 40.0]\n",
            "731 (5, 1) [D loss: (-24.1)(R 16.5, F -51.2, G 1.1)] [G loss: 39.4]\n",
            "732 (5, 1) [D loss: (-24.6)(R 10.3, F -40.4, G 0.6)] [G loss: 45.1]\n",
            "733 (5, 1) [D loss: (-24.6)(R 6.7, F -42.1, G 1.1)] [G loss: 34.7]\n",
            "734 (5, 1) [D loss: (-24.5)(R 7.6, F -37.5, G 0.5)] [G loss: 40.6]\n",
            "735 (5, 1) [D loss: (-23.8)(R 8.7, F -39.9, G 0.7)] [G loss: 33.2]\n",
            "736 (5, 1) [D loss: (-25.3)(R 16.9, F -50.7, G 0.8)] [G loss: 47.0]\n",
            "737 (5, 1) [D loss: (-23.0)(R 16.2, F -42.5, G 0.3)] [G loss: 45.2]\n",
            "738 (5, 1) [D loss: (-24.6)(R 8.1, F -39.5, G 0.7)] [G loss: 44.1]\n",
            "739 (5, 1) [D loss: (-25.2)(R 6.4, F -38.7, G 0.7)] [G loss: 42.8]\n",
            "740 (5, 1) [D loss: (-25.0)(R 11.2, F -46.1, G 1.0)] [G loss: 40.7]\n",
            "741 (5, 1) [D loss: (-24.2)(R 8.5, F -37.8, G 0.5)] [G loss: 45.6]\n",
            "742 (5, 1) [D loss: (-23.8)(R 6.7, F -39.5, G 0.9)] [G loss: 35.8]\n",
            "743 (5, 1) [D loss: (-24.7)(R 6.4, F -35.5, G 0.4)] [G loss: 44.1]\n",
            "744 (5, 1) [D loss: (-24.2)(R 8.7, F -39.8, G 0.7)] [G loss: 38.6]\n",
            "745 (5, 1) [D loss: (-23.8)(R 11.7, F -46.5, G 1.1)] [G loss: 38.7]\n",
            "746 (5, 1) [D loss: (-24.8)(R 7.9, F -42.8, G 1.0)] [G loss: 37.0]\n",
            "747 (5, 1) [D loss: (-24.9)(R 12.8, F -45.1, G 0.7)] [G loss: 50.0]\n",
            "748 (5, 1) [D loss: (-25.9)(R 7.1, F -41.2, G 0.8)] [G loss: 47.1]\n",
            "749 (5, 1) [D loss: (-24.7)(R 7.4, F -38.8, G 0.7)] [G loss: 39.4]\n",
            "750 (5, 1) [D loss: (-24.0)(R 12.2, F -44.9, G 0.9)] [G loss: 39.0]\n",
            "751 (5, 1) [D loss: (-24.9)(R 12.5, F -44.0, G 0.7)] [G loss: 51.1]\n",
            "752 (5, 1) [D loss: (-24.7)(R 7.0, F -40.2, G 0.8)] [G loss: 36.6]\n",
            "753 (5, 1) [D loss: (-25.0)(R 9.1, F -44.1, G 1.0)] [G loss: 41.1]\n",
            "754 (5, 1) [D loss: (-24.4)(R 7.1, F -40.7, G 0.9)] [G loss: 38.3]\n",
            "755 (5, 1) [D loss: (-23.7)(R 9.2, F -41.1, G 0.8)] [G loss: 40.9]\n",
            "756 (5, 1) [D loss: (-25.5)(R 5.8, F -39.1, G 0.8)] [G loss: 40.5]\n",
            "757 (5, 1) [D loss: (-24.7)(R 2.1, F -33.8, G 0.7)] [G loss: 37.0]\n",
            "758 (5, 1) [D loss: (-25.1)(R 3.3, F -38.6, G 1.0)] [G loss: 48.2]\n",
            "759 (5, 1) [D loss: (-24.2)(R 15.1, F -42.8, G 0.4)] [G loss: 52.6]\n",
            "760 (5, 1) [D loss: (-25.0)(R 11.9, F -44.2, G 0.7)] [G loss: 44.2]\n",
            "761 (5, 1) [D loss: (-23.8)(R 7.0, F -43.0, G 1.2)] [G loss: 44.2]\n",
            "762 (5, 1) [D loss: (-24.7)(R 4.9, F -37.1, G 0.8)] [G loss: 37.9]\n",
            "763 (5, 1) [D loss: (-23.8)(R 6.4, F -36.4, G 0.6)] [G loss: 39.1]\n",
            "764 (5, 1) [D loss: (-24.7)(R 6.9, F -41.5, G 1.0)] [G loss: 42.7]\n",
            "765 (5, 1) [D loss: (-24.8)(R 9.1, F -40.7, G 0.7)] [G loss: 47.1]\n",
            "766 (5, 1) [D loss: (-25.0)(R 4.3, F -35.9, G 0.7)] [G loss: 38.0]\n",
            "767 (5, 1) [D loss: (-25.1)(R 8.4, F -40.9, G 0.7)] [G loss: 38.9]\n",
            "768 (5, 1) [D loss: (-24.3)(R 4.6, F -35.7, G 0.7)] [G loss: 33.9]\n",
            "769 (5, 1) [D loss: (-24.4)(R 11.0, F -42.0, G 0.7)] [G loss: 40.0]\n",
            "770 (5, 1) [D loss: (-25.3)(R 10.8, F -46.5, G 1.0)] [G loss: 43.4]\n",
            "771 (5, 1) [D loss: (-24.3)(R 3.4, F -38.8, G 1.1)] [G loss: 32.6]\n",
            "772 (5, 1) [D loss: (-24.8)(R 1.1, F -34.5, G 0.9)] [G loss: 32.8]\n",
            "773 (5, 1) [D loss: (-25.5)(R 8.9, F -40.4, G 0.6)] [G loss: 51.4]\n",
            "774 (5, 1) [D loss: (-24.5)(R -7.6, F -21.3, G 0.5)] [G loss: 47.5]\n",
            "775 (5, 1) [D loss: (-25.3)(R 17.4, F -50.4, G 0.8)] [G loss: 50.4]\n",
            "776 (5, 1) [D loss: (-24.8)(R 8.8, F -41.0, G 0.7)] [G loss: 45.0]\n",
            "777 (5, 1) [D loss: (-24.8)(R 3.7, F -34.9, G 0.6)] [G loss: 38.4]\n",
            "778 (5, 1) [D loss: (-25.0)(R -3.6, F -27.5, G 0.6)] [G loss: 34.3]\n",
            "779 (5, 1) [D loss: (-24.4)(R 1.4, F -35.5, G 1.0)] [G loss: 30.0]\n",
            "780 (5, 1) [D loss: (-24.9)(R 3.2, F -36.0, G 0.8)] [G loss: 35.4]\n",
            "781 (5, 1) [D loss: (-25.2)(R 2.4, F -35.4, G 0.8)] [G loss: 37.4]\n",
            "782 (5, 1) [D loss: (-24.4)(R 1.8, F -36.9, G 1.1)] [G loss: 36.7]\n",
            "783 (5, 1) [D loss: (-24.2)(R 4.6, F -35.6, G 0.7)] [G loss: 39.3]\n",
            "784 (5, 1) [D loss: (-21.7)(R 4.9, F -47.1, G 2.0)] [G loss: 33.3]\n",
            "785 (5, 1) [D loss: (-24.7)(R -0.3, F -30.4, G 0.6)] [G loss: 32.1]\n",
            "786 (5, 1) [D loss: (-24.7)(R 1.8, F -31.6, G 0.5)] [G loss: 36.0]\n",
            "787 (5, 1) [D loss: (-25.6)(R 5.1, F -37.5, G 0.7)] [G loss: 39.2]\n",
            "788 (5, 1) [D loss: (-25.4)(R 2.9, F -38.7, G 1.0)] [G loss: 36.8]\n",
            "789 (5, 1) [D loss: (-24.5)(R -0.8, F -33.6, G 1.0)] [G loss: 33.1]\n",
            "790 (5, 1) [D loss: (-25.5)(R -0.8, F -37.2, G 1.2)] [G loss: 30.1]\n",
            "791 (5, 1) [D loss: (-25.1)(R 4.6, F -37.6, G 0.8)] [G loss: 35.9]\n",
            "792 (5, 1) [D loss: (-23.1)(R 4.3, F -29.6, G 0.2)] [G loss: 36.7]\n",
            "793 (5, 1) [D loss: (-25.6)(R 16.8, F -52.4, G 1.0)] [G loss: 40.9]\n",
            "794 (5, 1) [D loss: (-25.4)(R 5.2, F -39.5, G 0.9)] [G loss: 38.0]\n",
            "795 (5, 1) [D loss: (-24.4)(R 0.8, F -38.2, G 1.3)] [G loss: 29.3]\n",
            "796 (5, 1) [D loss: (-24.6)(R 0.3, F -30.8, G 0.6)] [G loss: 30.9]\n",
            "797 (5, 1) [D loss: (-25.9)(R 11.0, F -46.6, G 1.0)] [G loss: 42.8]\n",
            "798 (5, 1) [D loss: (-25.3)(R 0.0, F -34.6, G 0.9)] [G loss: 38.9]\n",
            "799 (5, 1) [D loss: (-24.6)(R -2.2, F -30.0, G 0.8)] [G loss: 26.4]\n",
            "800 (5, 1) [D loss: (-24.8)(R -1.8, F -31.2, G 0.8)] [G loss: 38.3]\n",
            "801 (5, 1) [D loss: (-24.2)(R -0.8, F -31.5, G 0.8)] [G loss: 30.1]\n",
            "802 (5, 1) [D loss: (-26.5)(R 3.0, F -36.6, G 0.7)] [G loss: 41.8]\n",
            "803 (5, 1) [D loss: (-25.2)(R 6.2, F -37.5, G 0.6)] [G loss: 42.4]\n",
            "804 (5, 1) [D loss: (-25.5)(R 6.8, F -42.3, G 1.0)] [G loss: 34.1]\n",
            "805 (5, 1) [D loss: (-25.1)(R 8.0, F -40.0, G 0.7)] [G loss: 38.0]\n",
            "806 (5, 1) [D loss: (-25.2)(R -0.3, F -35.7, G 1.1)] [G loss: 34.8]\n",
            "807 (5, 1) [D loss: (-25.7)(R 1.0, F -32.6, G 0.6)] [G loss: 44.1]\n",
            "808 (5, 1) [D loss: (-24.4)(R -6.0, F -29.2, G 1.1)] [G loss: 29.2]\n",
            "809 (5, 1) [D loss: (-25.4)(R -0.2, F -35.4, G 1.0)] [G loss: 31.1]\n",
            "810 (5, 1) [D loss: (-24.7)(R -1.2, F -35.3, G 1.2)] [G loss: 33.1]\n",
            "811 (5, 1) [D loss: (-25.2)(R 7.4, F -38.9, G 0.6)] [G loss: 46.3]\n",
            "812 (5, 1) [D loss: (-24.5)(R 7.7, F -40.0, G 0.8)] [G loss: 41.6]\n",
            "813 (5, 1) [D loss: (-25.7)(R -1.2, F -29.6, G 0.5)] [G loss: 38.2]\n",
            "814 (5, 1) [D loss: (-25.8)(R 7.7, F -38.5, G 0.5)] [G loss: 42.3]\n",
            "815 (5, 1) [D loss: (-25.8)(R 1.5, F -36.0, G 0.9)] [G loss: 37.0]\n",
            "816 (5, 1) [D loss: (-25.5)(R -3.9, F -31.1, G 0.9)] [G loss: 28.1]\n",
            "817 (5, 1) [D loss: (-26.3)(R 0.7, F -37.6, G 1.1)] [G loss: 41.7]\n",
            "818 (5, 1) [D loss: (-25.5)(R 6.7, F -39.9, G 0.8)] [G loss: 44.1]\n",
            "819 (5, 1) [D loss: (-25.0)(R -1.3, F -27.8, G 0.4)] [G loss: 36.3]\n",
            "820 (5, 1) [D loss: (-25.5)(R 3.7, F -35.1, G 0.6)] [G loss: 37.1]\n",
            "821 (5, 1) [D loss: (-24.7)(R 8.0, F -41.0, G 0.8)] [G loss: 40.4]\n",
            "822 (5, 1) [D loss: (-25.1)(R 1.6, F -33.0, G 0.6)] [G loss: 38.0]\n",
            "823 (5, 1) [D loss: (-25.3)(R -4.7, F -25.5, G 0.5)] [G loss: 38.6]\n",
            "824 (5, 1) [D loss: (-25.5)(R -3.1, F -30.4, G 0.8)] [G loss: 35.5]\n",
            "825 (5, 1) [D loss: (-25.1)(R -0.7, F -35.0, G 1.1)] [G loss: 32.3]\n",
            "826 (5, 1) [D loss: (-25.8)(R 5.3, F -38.0, G 0.7)] [G loss: 37.3]\n",
            "827 (5, 1) [D loss: (-24.8)(R -3.4, F -31.6, G 1.0)] [G loss: 28.9]\n",
            "828 (5, 1) [D loss: (-25.1)(R 0.4, F -31.8, G 0.6)] [G loss: 33.0]\n",
            "829 (5, 1) [D loss: (-25.8)(R 5.2, F -36.7, G 0.6)] [G loss: 45.8]\n",
            "830 (5, 1) [D loss: (-25.6)(R 2.9, F -33.3, G 0.5)] [G loss: 44.6]\n",
            "831 (5, 1) [D loss: (-24.8)(R 1.3, F -37.6, G 1.1)] [G loss: 37.1]\n",
            "832 (5, 1) [D loss: (-25.8)(R -5.1, F -28.8, G 0.8)] [G loss: 28.4]\n",
            "833 (5, 1) [D loss: (-25.0)(R -0.9, F -34.8, G 1.1)] [G loss: 30.8]\n",
            "834 (5, 1) [D loss: (-25.7)(R 2.6, F -34.4, G 0.6)] [G loss: 35.6]\n",
            "835 (5, 1) [D loss: (-25.3)(R -0.1, F -34.0, G 0.9)] [G loss: 37.1]\n",
            "836 (5, 1) [D loss: (-25.0)(R -2.0, F -36.4, G 1.3)] [G loss: 34.8]\n",
            "837 (5, 1) [D loss: (-25.8)(R -3.9, F -28.6, G 0.7)] [G loss: 39.1]\n",
            "838 (5, 1) [D loss: (-24.7)(R -2.1, F -30.1, G 0.8)] [G loss: 26.9]\n",
            "839 (5, 1) [D loss: (-24.8)(R 8.8, F -47.6, G 1.4)] [G loss: 27.1]\n",
            "840 (5, 1) [D loss: (-25.5)(R 1.2, F -34.3, G 0.8)] [G loss: 36.8]\n",
            "841 (5, 1) [D loss: (-25.1)(R -5.7, F -25.4, G 0.6)] [G loss: 30.5]\n",
            "842 (5, 1) [D loss: (-24.8)(R -2.9, F -34.3, G 1.2)] [G loss: 25.5]\n",
            "843 (5, 1) [D loss: (-25.7)(R 3.3, F -36.2, G 0.7)] [G loss: 39.4]\n",
            "844 (5, 1) [D loss: (-25.2)(R -11.0, F -20.7, G 0.6)] [G loss: 34.4]\n",
            "845 (5, 1) [D loss: (-24.9)(R -5.2, F -31.8, G 1.2)] [G loss: 30.8]\n",
            "846 (5, 1) [D loss: (-25.4)(R -6.2, F -29.8, G 1.1)] [G loss: 29.6]\n",
            "847 (5, 1) [D loss: (-26.3)(R -2.7, F -36.5, G 1.3)] [G loss: 32.3]\n",
            "848 (5, 1) [D loss: (-25.3)(R -1.8, F -30.9, G 0.7)] [G loss: 33.1]\n",
            "849 (5, 1) [D loss: (-26.2)(R 2.5, F -35.7, G 0.7)] [G loss: 38.0]\n",
            "850 (5, 1) [D loss: (-22.0)(R -7.0, F -16.4, G 0.1)] [G loss: 22.8]\n",
            "851 (5, 1) [D loss: (-25.2)(R 2.3, F -36.7, G 0.9)] [G loss: 33.1]\n",
            "852 (5, 1) [D loss: (-25.8)(R -3.0, F -35.6, G 1.3)] [G loss: 28.4]\n",
            "853 (5, 1) [D loss: (-25.7)(R 0.2, F -33.9, G 0.8)] [G loss: 35.0]\n",
            "854 (5, 1) [D loss: (-25.2)(R -6.2, F -26.8, G 0.8)] [G loss: 28.5]\n",
            "855 (5, 1) [D loss: (-24.6)(R -4.4, F -23.9, G 0.4)] [G loss: 37.0]\n",
            "856 (5, 1) [D loss: (-25.3)(R -8.4, F -26.9, G 1.0)] [G loss: 27.8]\n",
            "857 (5, 1) [D loss: (-26.4)(R -8.3, F -28.0, G 1.0)] [G loss: 30.7]\n",
            "858 (5, 1) [D loss: (-25.3)(R -5.1, F -29.7, G 1.0)] [G loss: 26.6]\n",
            "859 (5, 1) [D loss: (-25.2)(R 1.9, F -32.0, G 0.5)] [G loss: 37.2]\n",
            "860 (5, 1) [D loss: (-25.3)(R -14.8, F -21.4, G 1.1)] [G loss: 37.9]\n",
            "861 (5, 1) [D loss: (-24.4)(R 2.2, F -33.3, G 0.7)] [G loss: 43.1]\n",
            "862 (5, 1) [D loss: (-25.9)(R -2.1, F -29.0, G 0.5)] [G loss: 33.1]\n",
            "863 (5, 1) [D loss: (-24.1)(R -6.0, F -29.1, G 1.1)] [G loss: 29.7]\n",
            "864 (5, 1) [D loss: (-25.5)(R -10.6, F -24.3, G 0.9)] [G loss: 22.4]\n",
            "865 (5, 1) [D loss: (-25.4)(R -9.8, F -22.8, G 0.7)] [G loss: 30.1]\n",
            "866 (5, 1) [D loss: (-25.6)(R -16.5, F -20.1, G 1.1)] [G loss: 29.9]\n",
            "867 (5, 1) [D loss: (-25.2)(R -2.8, F -30.5, G 0.8)] [G loss: 26.9]\n",
            "868 (5, 1) [D loss: (-25.4)(R -9.6, F -24.3, G 0.8)] [G loss: 23.4]\n",
            "869 (5, 1) [D loss: (-24.7)(R -4.8, F -26.4, G 0.7)] [G loss: 27.8]\n",
            "870 (5, 1) [D loss: (-26.1)(R -0.4, F -33.7, G 0.8)] [G loss: 39.9]\n",
            "871 (5, 1) [D loss: (-25.7)(R 4.0, F -39.2, G 1.0)] [G loss: 40.2]\n",
            "872 (5, 1) [D loss: (-25.8)(R 1.2, F -34.2, G 0.7)] [G loss: 36.7]\n",
            "873 (5, 1) [D loss: (-24.7)(R -2.1, F -26.4, G 0.4)] [G loss: 38.0]\n",
            "874 (5, 1) [D loss: (-24.4)(R -7.6, F -29.2, G 1.2)] [G loss: 36.4]\n",
            "875 (5, 1) [D loss: (-26.1)(R -10.8, F -23.3, G 0.8)] [G loss: 26.1]\n",
            "876 (5, 1) [D loss: (-25.1)(R -6.2, F -28.6, G 1.0)] [G loss: 28.8]\n",
            "877 (5, 1) [D loss: (-26.1)(R -9.3, F -23.0, G 0.6)] [G loss: 24.0]\n",
            "878 (5, 1) [D loss: (-24.5)(R -7.1, F -22.6, G 0.5)] [G loss: 28.7]\n",
            "879 (5, 1) [D loss: (-24.5)(R -1.6, F -33.5, G 1.1)] [G loss: 32.3]\n",
            "880 (5, 1) [D loss: (-25.6)(R -1.1, F -32.5, G 0.8)] [G loss: 32.7]\n",
            "881 (5, 1) [D loss: (-25.4)(R -9.1, F -28.2, G 1.2)] [G loss: 28.2]\n",
            "882 (5, 1) [D loss: (-24.4)(R -4.0, F -29.4, G 0.9)] [G loss: 30.6]\n",
            "883 (5, 1) [D loss: (-24.8)(R -2.9, F -27.3, G 0.5)] [G loss: 31.0]\n",
            "884 (5, 1) [D loss: (-24.4)(R -10.7, F -24.5, G 1.1)] [G loss: 24.3]\n",
            "885 (5, 1) [D loss: (-25.2)(R -8.0, F -22.7, G 0.5)] [G loss: 27.2]\n",
            "886 (5, 1) [D loss: (-26.0)(R -13.4, F -18.6, G 0.6)] [G loss: 25.8]\n",
            "887 (5, 1) [D loss: (-24.4)(R -4.6, F -28.3, G 0.9)] [G loss: 26.6]\n",
            "888 (5, 1) [D loss: (-25.0)(R -9.1, F -25.0, G 0.9)] [G loss: 32.8]\n",
            "889 (5, 1) [D loss: (-25.3)(R -8.9, F -26.3, G 1.0)] [G loss: 28.5]\n",
            "890 (5, 1) [D loss: (-25.2)(R -12.4, F -21.7, G 0.9)] [G loss: 27.0]\n",
            "891 (5, 1) [D loss: (-25.5)(R -8.5, F -26.9, G 1.0)] [G loss: 17.8]\n",
            "892 (5, 1) [D loss: (-25.5)(R -5.8, F -25.0, G 0.5)] [G loss: 21.5]\n",
            "893 (5, 1) [D loss: (-25.2)(R -6.1, F -25.8, G 0.7)] [G loss: 24.5]\n",
            "894 (5, 1) [D loss: (-25.2)(R -3.8, F -29.4, G 0.8)] [G loss: 27.1]\n",
            "895 (5, 1) [D loss: (-24.6)(R -4.7, F -29.2, G 0.9)] [G loss: 22.2]\n",
            "896 (5, 1) [D loss: (-26.4)(R -2.8, F -29.6, G 0.6)] [G loss: 29.2]\n",
            "897 (5, 1) [D loss: (-24.8)(R -10.0, F -21.7, G 0.7)] [G loss: 20.2]\n",
            "898 (5, 1) [D loss: (-25.6)(R -6.0, F -28.7, G 0.9)] [G loss: 32.2]\n",
            "899 (5, 1) [D loss: (-25.4)(R -9.3, F -24.5, G 0.8)] [G loss: 29.8]\n",
            "900 (5, 1) [D loss: (-25.4)(R -11.7, F -20.8, G 0.7)] [G loss: 22.3]\n",
            "901 (5, 1) [D loss: (-25.1)(R -15.1, F -13.9, G 0.4)] [G loss: 22.7]\n",
            "902 (5, 1) [D loss: (-24.7)(R -10.3, F -25.3, G 1.1)] [G loss: 23.4]\n",
            "903 (5, 1) [D loss: (-25.5)(R -10.1, F -23.8, G 0.8)] [G loss: 24.1]\n",
            "904 (5, 1) [D loss: (-24.7)(R -8.0, F -21.2, G 0.5)] [G loss: 29.4]\n",
            "905 (5, 1) [D loss: (-25.6)(R -12.7, F -20.0, G 0.7)] [G loss: 25.1]\n",
            "906 (5, 1) [D loss: (-24.7)(R -6.4, F -25.2, G 0.7)] [G loss: 26.5]\n",
            "907 (5, 1) [D loss: (-25.5)(R -10.0, F -23.0, G 0.7)] [G loss: 26.5]\n",
            "908 (5, 1) [D loss: (-25.7)(R -11.6, F -22.1, G 0.8)] [G loss: 26.3]\n",
            "909 (5, 1) [D loss: (-25.3)(R -7.8, F -25.9, G 0.8)] [G loss: 30.6]\n",
            "910 (5, 1) [D loss: (-25.8)(R -10.2, F -21.7, G 0.6)] [G loss: 27.4]\n",
            "911 (5, 1) [D loss: (-24.9)(R -10.6, F -17.4, G 0.3)] [G loss: 29.9]\n",
            "912 (5, 1) [D loss: (-25.4)(R -10.7, F -21.9, G 0.7)] [G loss: 25.0]\n",
            "913 (5, 1) [D loss: (-26.4)(R -13.0, F -21.8, G 0.8)] [G loss: 31.9]\n",
            "914 (5, 1) [D loss: (-25.2)(R -20.2, F -18.4, G 1.3)] [G loss: 24.3]\n",
            "915 (5, 1) [D loss: (-25.2)(R -11.2, F -19.9, G 0.6)] [G loss: 22.1]\n",
            "916 (5, 1) [D loss: (-25.2)(R -11.7, F -19.0, G 0.6)] [G loss: 15.7]\n",
            "917 (5, 1) [D loss: (-25.7)(R -5.3, F -30.6, G 1.0)] [G loss: 23.5]\n",
            "918 (5, 1) [D loss: (-25.9)(R -16.4, F -18.0, G 0.8)] [G loss: 17.5]\n",
            "919 (5, 1) [D loss: (-25.6)(R -13.7, F -16.6, G 0.5)] [G loss: 23.0]\n",
            "920 (5, 1) [D loss: (-24.7)(R -5.4, F -24.4, G 0.5)] [G loss: 23.1]\n",
            "921 (5, 1) [D loss: (-24.2)(R -5.1, F -22.5, G 0.3)] [G loss: 23.4]\n",
            "922 (5, 1) [D loss: (-25.8)(R -1.0, F -34.4, G 1.0)] [G loss: 27.8]\n",
            "923 (5, 1) [D loss: (-24.6)(R -7.7, F -20.8, G 0.4)] [G loss: 26.3]\n",
            "924 (5, 1) [D loss: (-26.4)(R -8.9, F -26.1, G 0.9)] [G loss: 26.6]\n",
            "925 (5, 1) [D loss: (-25.4)(R -14.4, F -17.9, G 0.7)] [G loss: 20.8]\n",
            "926 (5, 1) [D loss: (-25.5)(R -9.6, F -22.7, G 0.7)] [G loss: 27.1]\n",
            "927 (5, 1) [D loss: (-26.0)(R -11.9, F -23.5, G 0.9)] [G loss: 20.8]\n",
            "928 (5, 1) [D loss: (-26.1)(R -8.8, F -26.5, G 0.9)] [G loss: 25.9]\n",
            "929 (5, 1) [D loss: (-24.5)(R -8.8, F -20.5, G 0.5)] [G loss: 26.2]\n",
            "930 (5, 1) [D loss: (-25.3)(R -1.9, F -29.6, G 0.6)] [G loss: 27.7]\n",
            "931 (5, 1) [D loss: (-24.8)(R -12.7, F -24.0, G 1.2)] [G loss: 25.9]\n",
            "932 (5, 1) [D loss: (-26.4)(R -11.7, F -22.6, G 0.8)] [G loss: 24.5]\n",
            "933 (5, 1) [D loss: (-24.9)(R -10.9, F -19.9, G 0.6)] [G loss: 20.4]\n",
            "934 (5, 1) [D loss: (-25.0)(R -14.5, F -20.4, G 1.0)] [G loss: 15.3]\n",
            "935 (5, 1) [D loss: (-24.5)(R -13.8, F -22.7, G 1.2)] [G loss: 20.0]\n",
            "936 (5, 1) [D loss: (-25.7)(R -8.6, F -24.8, G 0.8)] [G loss: 20.1]\n",
            "937 (5, 1) [D loss: (-26.2)(R -4.6, F -28.2, G 0.7)] [G loss: 32.5]\n",
            "938 (5, 1) [D loss: (-25.9)(R -14.4, F -21.7, G 1.0)] [G loss: 25.0]\n",
            "939 (5, 1) [D loss: (-26.0)(R -9.7, F -26.1, G 1.0)] [G loss: 21.7]\n",
            "940 (5, 1) [D loss: (-24.5)(R -8.7, F -28.2, G 1.2)] [G loss: 23.7]\n",
            "941 (5, 1) [D loss: (-25.9)(R -14.4, F -19.9, G 0.8)] [G loss: 20.5]\n",
            "942 (5, 1) [D loss: (-25.9)(R -11.2, F -21.3, G 0.7)] [G loss: 18.3]\n",
            "943 (5, 1) [D loss: (-25.2)(R -7.5, F -22.7, G 0.5)] [G loss: 20.3]\n",
            "944 (5, 1) [D loss: (-25.8)(R -6.8, F -30.1, G 1.1)] [G loss: 21.6]\n",
            "945 (5, 1) [D loss: (-26.4)(R -11.6, F -23.5, G 0.9)] [G loss: 25.5]\n",
            "946 (5, 1) [D loss: (-25.3)(R -14.4, F -21.5, G 1.1)] [G loss: 24.1]\n",
            "947 (5, 1) [D loss: (-25.4)(R -14.7, F -20.2, G 1.0)] [G loss: 20.0]\n",
            "948 (5, 1) [D loss: (-24.7)(R -5.8, F -26.5, G 0.8)] [G loss: 24.9]\n",
            "949 (5, 1) [D loss: (-26.1)(R -4.9, F -27.6, G 0.6)] [G loss: 27.9]\n",
            "950 (5, 1) [D loss: (-25.5)(R -13.8, F -23.5, G 1.2)] [G loss: 22.0]\n",
            "951 (5, 1) [D loss: (-25.9)(R -16.4, F -21.5, G 1.2)] [G loss: 22.7]\n",
            "952 (5, 1) [D loss: (-27.4)(R -13.0, F -24.6, G 1.0)] [G loss: 22.6]\n",
            "953 (5, 1) [D loss: (-26.0)(R -15.6, F -17.7, G 0.7)] [G loss: 17.8]\n",
            "954 (5, 1) [D loss: (-24.6)(R -13.2, F -21.5, G 1.0)] [G loss: 19.2]\n",
            "955 (5, 1) [D loss: (-25.5)(R -14.3, F -21.6, G 1.0)] [G loss: 20.9]\n",
            "956 (5, 1) [D loss: (-25.3)(R -8.8, F -27.8, G 1.1)] [G loss: 27.8]\n",
            "957 (5, 1) [D loss: (-25.7)(R -5.8, F -27.6, G 0.8)] [G loss: 31.7]\n",
            "958 (5, 1) [D loss: (-25.5)(R -7.3, F -23.2, G 0.5)] [G loss: 25.8]\n",
            "959 (5, 1) [D loss: (-26.8)(R -12.1, F -22.4, G 0.8)] [G loss: 24.5]\n",
            "960 (5, 1) [D loss: (-25.6)(R -16.1, F -17.1, G 0.8)] [G loss: 18.6]\n",
            "961 (5, 1) [D loss: (-25.8)(R -8.0, F -26.8, G 0.9)] [G loss: 23.4]\n",
            "962 (5, 1) [D loss: (-25.5)(R -12.3, F -19.2, G 0.6)] [G loss: 27.2]\n",
            "963 (5, 1) [D loss: (-23.5)(R -26.2, F -13.5, G 1.6)] [G loss: 17.6]\n",
            "964 (5, 1) [D loss: (-25.7)(R -17.3, F -16.6, G 0.8)] [G loss: 18.8]\n",
            "965 (5, 1) [D loss: (-26.2)(R -17.8, F -18.6, G 1.0)] [G loss: 20.3]\n",
            "966 (5, 1) [D loss: (-25.3)(R -12.5, F -18.3, G 0.5)] [G loss: 18.0]\n",
            "967 (5, 1) [D loss: (-26.1)(R -12.9, F -20.8, G 0.8)] [G loss: 22.0]\n",
            "968 (5, 1) [D loss: (-25.7)(R -12.5, F -18.0, G 0.5)] [G loss: 20.1]\n",
            "969 (5, 1) [D loss: (-25.4)(R -12.0, F -19.7, G 0.6)] [G loss: 23.2]\n",
            "970 (5, 1) [D loss: (-25.7)(R -16.1, F -16.5, G 0.7)] [G loss: 17.9]\n",
            "971 (5, 1) [D loss: (-25.6)(R -14.9, F -18.9, G 0.8)] [G loss: 19.8]\n",
            "972 (5, 1) [D loss: (-25.0)(R -11.7, F -26.3, G 1.3)] [G loss: 20.6]\n",
            "973 (5, 1) [D loss: (-24.8)(R -12.3, F -19.4, G 0.7)] [G loss: 17.8]\n",
            "974 (5, 1) [D loss: (-24.9)(R -4.9, F -24.1, G 0.4)] [G loss: 26.7]\n",
            "975 (5, 1) [D loss: (-25.5)(R -10.5, F -21.4, G 0.6)] [G loss: 23.6]\n",
            "976 (5, 1) [D loss: (-25.6)(R -11.9, F -21.0, G 0.7)] [G loss: 22.6]\n",
            "977 (5, 1) [D loss: (-25.5)(R -13.6, F -20.0, G 0.8)] [G loss: 24.0]\n",
            "978 (5, 1) [D loss: (-25.0)(R -9.0, F -23.3, G 0.7)] [G loss: 24.4]\n",
            "979 (5, 1) [D loss: (-25.6)(R -10.4, F -22.9, G 0.8)] [G loss: 27.2]\n",
            "980 (5, 1) [D loss: (-25.2)(R -10.4, F -19.5, G 0.5)] [G loss: 41.4]\n",
            "981 (5, 1) [D loss: (-25.8)(R -9.3, F -28.9, G 1.3)] [G loss: 21.9]\n",
            "982 (5, 1) [D loss: (-26.0)(R -14.7, F -19.2, G 0.8)] [G loss: 20.7]\n",
            "983 (5, 1) [D loss: (-24.7)(R -12.1, F -16.9, G 0.4)] [G loss: 18.7]\n",
            "984 (5, 1) [D loss: (-24.6)(R -17.2, F -16.7, G 0.9)] [G loss: 15.9]\n",
            "985 (5, 1) [D loss: (-25.8)(R -14.1, F -20.6, G 0.9)] [G loss: 19.4]\n",
            "986 (5, 1) [D loss: (-25.7)(R -13.6, F -19.3, G 0.7)] [G loss: 16.2]\n",
            "987 (5, 1) [D loss: (-25.5)(R -11.8, F -21.9, G 0.8)] [G loss: 18.6]\n",
            "988 (5, 1) [D loss: (-24.3)(R -11.6, F -18.1, G 0.5)] [G loss: 18.7]\n",
            "989 (5, 1) [D loss: (-25.8)(R -11.9, F -25.6, G 1.2)] [G loss: 20.8]\n",
            "990 (5, 1) [D loss: (-26.3)(R -11.6, F -22.4, G 0.8)] [G loss: 29.8]\n",
            "991 (5, 1) [D loss: (-24.9)(R -11.5, F -18.5, G 0.5)] [G loss: 19.8]\n",
            "992 (5, 1) [D loss: (-26.1)(R -11.7, F -22.2, G 0.8)] [G loss: 22.2]\n",
            "993 (5, 1) [D loss: (-26.3)(R -14.2, F -19.4, G 0.7)] [G loss: 18.2]\n",
            "994 (5, 1) [D loss: (-25.0)(R -13.0, F -15.4, G 0.3)] [G loss: 22.9]\n",
            "995 (5, 1) [D loss: (-24.8)(R -20.1, F -18.7, G 1.4)] [G loss: 13.6]\n",
            "996 (5, 1) [D loss: (-25.7)(R -10.6, F -22.3, G 0.7)] [G loss: 19.6]\n",
            "997 (5, 1) [D loss: (-26.0)(R -19.5, F -16.4, G 1.0)] [G loss: 18.8]\n",
            "998 (5, 1) [D loss: (-25.7)(R -16.8, F -19.0, G 1.0)] [G loss: 22.6]\n",
            "999 (5, 1) [D loss: (-25.5)(R -13.9, F -18.6, G 0.7)] [G loss: 21.6]\n",
            "1000 (5, 1) [D loss: (-25.3)(R -16.7, F -17.4, G 0.9)] [G loss: 18.1]\n",
            "1001 (5, 1) [D loss: (-25.7)(R -17.5, F -16.3, G 0.8)] [G loss: 17.7]\n",
            "1002 (5, 1) [D loss: (-25.5)(R -17.8, F -14.8, G 0.7)] [G loss: 19.5]\n",
            "1003 (5, 1) [D loss: (-25.1)(R -18.6, F -18.7, G 1.2)] [G loss: 15.4]\n",
            "1004 (5, 1) [D loss: (-25.9)(R -15.9, F -17.4, G 0.7)] [G loss: 19.7]\n",
            "1005 (5, 1) [D loss: (-24.5)(R -10.2, F -19.3, G 0.5)] [G loss: 20.9]\n",
            "1006 (5, 1) [D loss: (-26.2)(R -10.9, F -20.3, G 0.5)] [G loss: 19.0]\n",
            "1007 (5, 1) [D loss: (-25.5)(R -15.1, F -15.9, G 0.6)] [G loss: 21.1]\n",
            "1008 (5, 1) [D loss: (-26.6)(R -16.6, F -18.7, G 0.9)] [G loss: 20.5]\n",
            "1009 (5, 1) [D loss: (-24.9)(R -13.5, F -17.6, G 0.6)] [G loss: 20.9]\n",
            "1010 (5, 1) [D loss: (-26.1)(R -19.9, F -17.4, G 1.1)] [G loss: 19.6]\n",
            "1011 (5, 1) [D loss: (-24.7)(R -20.9, F -9.5, G 0.6)] [G loss: 15.3]\n",
            "1012 (5, 1) [D loss: (-25.6)(R -15.1, F -19.4, G 0.9)] [G loss: 16.7]\n",
            "1013 (5, 1) [D loss: (-25.3)(R -20.9, F -14.5, G 1.0)] [G loss: 16.9]\n",
            "1014 (5, 1) [D loss: (-26.2)(R -16.5, F -16.5, G 0.7)] [G loss: 19.3]\n",
            "1015 (5, 1) [D loss: (-25.1)(R -17.8, F -17.3, G 1.0)] [G loss: 17.2]\n",
            "1016 (5, 1) [D loss: (-26.1)(R -16.4, F -18.6, G 0.9)] [G loss: 22.4]\n",
            "1017 (5, 1) [D loss: (-25.0)(R -27.4, F -8.6, G 1.1)] [G loss: 15.4]\n",
            "1018 (5, 1) [D loss: (-26.2)(R -18.2, F -20.6, G 1.3)] [G loss: 15.4]\n",
            "1019 (5, 1) [D loss: (-24.4)(R -10.1, F -19.8, G 0.6)] [G loss: 23.2]\n",
            "1020 (5, 1) [D loss: (-26.0)(R -12.3, F -20.7, G 0.7)] [G loss: 25.9]\n",
            "1021 (5, 1) [D loss: (-25.8)(R -11.3, F -22.4, G 0.8)] [G loss: 24.5]\n",
            "1022 (5, 1) [D loss: (-25.5)(R -12.8, F -25.2, G 1.2)] [G loss: 22.9]\n",
            "1023 (5, 1) [D loss: (-25.9)(R -10.6, F -21.2, G 0.6)] [G loss: 25.4]\n",
            "1024 (5, 1) [D loss: (-25.9)(R -16.2, F -18.0, G 0.8)] [G loss: 20.0]\n",
            "1025 (5, 1) [D loss: (-26.3)(R -10.1, F -22.7, G 0.7)] [G loss: 29.7]\n",
            "1026 (5, 1) [D loss: (-25.2)(R -12.1, F -17.9, G 0.5)] [G loss: 20.7]\n",
            "1027 (5, 1) [D loss: (-25.8)(R -13.7, F -17.7, G 0.6)] [G loss: 20.3]\n",
            "1028 (5, 1) [D loss: (-25.2)(R -15.4, F -18.4, G 0.9)] [G loss: 16.7]\n",
            "1029 (5, 1) [D loss: (-25.3)(R -12.2, F -18.9, G 0.6)] [G loss: 19.1]\n",
            "1030 (5, 1) [D loss: (-26.1)(R -18.3, F -16.9, G 0.9)] [G loss: 18.0]\n",
            "1031 (5, 1) [D loss: (-24.6)(R -16.2, F -16.2, G 0.8)] [G loss: 14.4]\n",
            "1032 (5, 1) [D loss: (-24.5)(R -17.5, F -21.9, G 1.5)] [G loss: 19.7]\n",
            "1033 (5, 1) [D loss: (-25.7)(R -14.5, F -19.4, G 0.8)] [G loss: 20.7]\n",
            "1034 (5, 1) [D loss: (-24.7)(R -17.1, F -17.5, G 1.0)] [G loss: 16.3]\n",
            "1035 (5, 1) [D loss: (-25.1)(R -15.4, F -19.1, G 0.9)] [G loss: 20.0]\n",
            "1036 (5, 1) [D loss: (-24.0)(R -19.1, F -18.8, G 1.4)] [G loss: 18.6]\n",
            "1037 (5, 1) [D loss: (-25.9)(R -13.2, F -20.3, G 0.8)] [G loss: 28.3]\n",
            "1038 (5, 1) [D loss: (-25.7)(R -14.1, F -20.4, G 0.9)] [G loss: 19.9]\n",
            "1039 (5, 1) [D loss: (-26.8)(R -15.7, F -17.4, G 0.6)] [G loss: 21.5]\n",
            "1040 (5, 1) [D loss: (-24.3)(R -19.5, F -15.9, G 1.1)] [G loss: 14.9]\n",
            "1041 (5, 1) [D loss: (-24.9)(R -17.3, F -17.0, G 0.9)] [G loss: 16.7]\n",
            "1042 (5, 1) [D loss: (-23.7)(R -17.9, F -19.4, G 1.4)] [G loss: 12.2]\n",
            "1043 (5, 1) [D loss: (-25.3)(R -13.8, F -18.4, G 0.7)] [G loss: 19.8]\n",
            "1044 (5, 1) [D loss: (-25.8)(R -15.9, F -16.8, G 0.7)] [G loss: 16.8]\n",
            "1045 (5, 1) [D loss: (-26.0)(R -11.4, F -26.6, G 1.2)] [G loss: 18.5]\n",
            "1046 (5, 1) [D loss: (-25.6)(R -14.0, F -19.8, G 0.8)] [G loss: 21.2]\n",
            "1047 (5, 1) [D loss: (-25.6)(R -17.6, F -15.8, G 0.8)] [G loss: 16.7]\n",
            "1048 (5, 1) [D loss: (-26.4)(R -16.5, F -15.2, G 0.5)] [G loss: 19.7]\n",
            "1049 (5, 1) [D loss: (-24.2)(R -19.7, F -16.5, G 1.2)] [G loss: 14.3]\n",
            "1050 (5, 1) [D loss: (-24.6)(R -16.1, F -15.0, G 0.6)] [G loss: 13.2]\n",
            "1051 (5, 1) [D loss: (-25.1)(R -16.8, F -17.7, G 0.9)] [G loss: 18.5]\n",
            "1052 (5, 1) [D loss: (-25.1)(R -21.7, F -17.1, G 1.4)] [G loss: 17.9]\n",
            "1053 (5, 1) [D loss: (-25.8)(R -22.2, F -14.6, G 1.1)] [G loss: 15.5]\n",
            "1054 (5, 1) [D loss: (-25.7)(R -17.4, F -16.1, G 0.8)] [G loss: 19.4]\n",
            "1055 (5, 1) [D loss: (-24.8)(R -14.6, F -21.8, G 1.2)] [G loss: 20.9]\n",
            "1056 (5, 1) [D loss: (-26.1)(R -16.1, F -17.0, G 0.7)] [G loss: 24.7]\n",
            "1057 (5, 1) [D loss: (-25.6)(R -12.5, F -18.4, G 0.5)] [G loss: 20.7]\n",
            "1058 (5, 1) [D loss: (-26.1)(R -18.1, F -14.6, G 0.7)] [G loss: 18.2]\n",
            "1059 (5, 1) [D loss: (-25.6)(R -13.3, F -19.7, G 0.7)] [G loss: 18.9]\n",
            "1060 (5, 1) [D loss: (-26.3)(R -6.2, F -29.3, G 0.9)] [G loss: 34.2]\n",
            "1061 (5, 1) [D loss: (-25.2)(R 7.9, F -40.9, G 0.8)] [G loss: 34.0]\n",
            "1062 (5, 1) [D loss: (-26.0)(R -6.5, F -24.9, G 0.5)] [G loss: 34.8]\n",
            "1063 (5, 1) [D loss: (-26.9)(R -11.1, F -29.8, G 1.4)] [G loss: 28.0]\n",
            "1064 (5, 1) [D loss: (-25.7)(R -10.0, F -23.7, G 0.8)] [G loss: 26.2]\n",
            "1065 (5, 1) [D loss: (-25.2)(R -9.2, F -22.0, G 0.6)] [G loss: 26.7]\n",
            "1066 (5, 1) [D loss: (-25.6)(R -3.2, F -28.8, G 0.6)] [G loss: 30.5]\n",
            "1067 (5, 1) [D loss: (-24.9)(R -5.9, F -26.6, G 0.8)] [G loss: 27.0]\n",
            "1068 (5, 1) [D loss: (-24.1)(R -8.1, F -21.3, G 0.5)] [G loss: 25.1]\n",
            "1069 (5, 1) [D loss: (-26.1)(R 1.2, F -35.1, G 0.8)] [G loss: 33.0]\n",
            "1070 (5, 1) [D loss: (-26.0)(R -3.9, F -30.0, G 0.8)] [G loss: 30.0]\n",
            "1071 (5, 1) [D loss: (-25.4)(R -4.4, F -27.7, G 0.7)] [G loss: 27.4]\n",
            "1072 (5, 1) [D loss: (-25.4)(R -6.7, F -26.2, G 0.7)] [G loss: 27.3]\n",
            "1073 (5, 1) [D loss: (-26.2)(R -3.0, F -30.9, G 0.8)] [G loss: 28.7]\n",
            "1074 (5, 1) [D loss: (-25.4)(R -6.7, F -24.1, G 0.5)] [G loss: 33.2]\n",
            "1075 (5, 1) [D loss: (-26.4)(R -8.7, F -29.5, G 1.2)] [G loss: 27.8]\n",
            "1076 (5, 1) [D loss: (-25.9)(R -10.2, F -24.7, G 0.9)] [G loss: 24.1]\n",
            "1077 (5, 1) [D loss: (-26.2)(R -7.0, F -27.7, G 0.9)] [G loss: 28.7]\n",
            "1078 (5, 1) [D loss: (-25.4)(R -10.0, F -19.7, G 0.4)] [G loss: 29.0]\n",
            "1079 (5, 1) [D loss: (-26.4)(R -13.6, F -20.5, G 0.8)] [G loss: 24.4]\n",
            "1080 (5, 1) [D loss: (-25.5)(R -14.3, F -17.2, G 0.6)] [G loss: 21.8]\n",
            "1081 (5, 1) [D loss: (-24.7)(R -11.5, F -22.2, G 0.9)] [G loss: 16.0]\n",
            "1082 (5, 1) [D loss: (-25.3)(R -6.5, F -29.8, G 1.1)] [G loss: 24.0]\n",
            "1083 (5, 1) [D loss: (-25.1)(R -8.5, F -26.5, G 1.0)] [G loss: 28.1]\n",
            "1084 (5, 1) [D loss: (-25.7)(R -9.4, F -25.5, G 0.9)] [G loss: 24.5]\n",
            "1085 (5, 1) [D loss: (-25.2)(R -12.0, F -25.0, G 1.2)] [G loss: 21.8]\n",
            "1086 (5, 1) [D loss: (-26.6)(R -5.2, F -26.5, G 0.5)] [G loss: 33.1]\n",
            "1087 (5, 1) [D loss: (-26.1)(R -9.6, F -23.4, G 0.7)] [G loss: 27.0]\n",
            "1088 (5, 1) [D loss: (-25.3)(R -10.7, F -24.1, G 1.0)] [G loss: 25.9]\n",
            "1089 (5, 1) [D loss: (-25.4)(R -12.6, F -21.6, G 0.9)] [G loss: 16.0]\n",
            "1090 (5, 1) [D loss: (-26.3)(R -12.4, F -25.0, G 1.1)] [G loss: 18.6]\n",
            "1091 (5, 1) [D loss: (-25.6)(R -14.7, F -18.7, G 0.8)] [G loss: 23.1]\n",
            "1092 (5, 1) [D loss: (-25.7)(R -12.5, F -21.3, G 0.8)] [G loss: 21.8]\n",
            "1093 (5, 1) [D loss: (-26.4)(R -11.2, F -22.3, G 0.7)] [G loss: 23.8]\n",
            "1094 (5, 1) [D loss: (-25.3)(R -11.0, F -19.9, G 0.6)] [G loss: 18.4]\n",
            "1095 (5, 1) [D loss: (-26.5)(R -9.6, F -26.4, G 0.9)] [G loss: 27.2]\n",
            "1096 (5, 1) [D loss: (-25.6)(R -8.7, F -23.7, G 0.7)] [G loss: 26.0]\n",
            "1097 (5, 1) [D loss: (-25.1)(R -9.8, F -22.0, G 0.7)] [G loss: 23.3]\n",
            "1098 (5, 1) [D loss: (-25.0)(R -11.7, F -23.3, G 1.0)] [G loss: 25.2]\n",
            "1099 (5, 1) [D loss: (-25.5)(R -13.3, F -18.6, G 0.6)] [G loss: 23.2]\n",
            "1100 (5, 1) [D loss: (-25.4)(R -13.4, F -24.6, G 1.3)] [G loss: 24.5]\n",
            "1101 (5, 1) [D loss: (-23.9)(R -11.9, F -28.1, G 1.6)] [G loss: 20.9]\n",
            "1102 (5, 1) [D loss: (-25.4)(R -13.4, F -19.9, G 0.8)] [G loss: 19.4]\n",
            "1103 (5, 1) [D loss: (-25.7)(R -14.6, F -20.0, G 0.9)] [G loss: 21.8]\n",
            "1104 (5, 1) [D loss: (-24.9)(R -16.8, F -18.3, G 1.0)] [G loss: 16.7]\n",
            "1105 (5, 1) [D loss: (-27.0)(R -13.2, F -20.2, G 0.6)] [G loss: 20.8]\n",
            "1106 (5, 1) [D loss: (-26.3)(R -10.6, F -25.5, G 1.0)] [G loss: 22.9]\n",
            "1107 (5, 1) [D loss: (-26.5)(R -15.2, F -22.6, G 1.1)] [G loss: 20.2]\n",
            "1108 (5, 1) [D loss: (-25.2)(R -14.9, F -17.7, G 0.7)] [G loss: 18.2]\n",
            "1109 (5, 1) [D loss: (-26.0)(R -12.3, F -19.7, G 0.6)] [G loss: 19.6]\n",
            "1110 (5, 1) [D loss: (-25.5)(R -7.2, F -24.0, G 0.6)] [G loss: 28.0]\n",
            "1111 (5, 1) [D loss: (-26.2)(R -15.4, F -22.7, G 1.2)] [G loss: 20.9]\n",
            "1112 (5, 1) [D loss: (-26.1)(R -15.2, F -19.7, G 0.9)] [G loss: 19.1]\n",
            "1113 (5, 1) [D loss: (-26.3)(R -12.0, F -21.6, G 0.7)] [G loss: 23.9]\n",
            "1114 (5, 1) [D loss: (-26.7)(R -14.9, F -19.3, G 0.7)] [G loss: 24.2]\n",
            "1115 (5, 1) [D loss: (-25.3)(R -16.0, F -20.7, G 1.1)] [G loss: 21.6]\n",
            "1116 (5, 1) [D loss: (-25.5)(R -16.5, F -16.4, G 0.7)] [G loss: 20.0]\n",
            "1117 (5, 1) [D loss: (-26.0)(R -18.1, F -13.3, G 0.5)] [G loss: 22.4]\n",
            "1118 (5, 1) [D loss: (-25.7)(R -17.8, F -17.1, G 0.9)] [G loss: 18.4]\n",
            "1119 (5, 1) [D loss: (-25.4)(R -13.5, F -19.3, G 0.7)] [G loss: 19.8]\n",
            "1120 (5, 1) [D loss: (-25.7)(R -11.6, F -20.5, G 0.6)] [G loss: 21.2]\n",
            "1121 (5, 1) [D loss: (-25.7)(R -10.4, F -19.4, G 0.4)] [G loss: 24.4]\n",
            "1122 (5, 1) [D loss: (-24.7)(R -18.3, F -19.5, G 1.3)] [G loss: 21.4]\n",
            "1123 (5, 1) [D loss: (-26.4)(R -16.0, F -17.1, G 0.7)] [G loss: 20.1]\n",
            "1124 (5, 1) [D loss: (-27.1)(R -19.0, F -18.3, G 1.0)] [G loss: 21.7]\n",
            "1125 (5, 1) [D loss: (-25.7)(R -13.7, F -21.3, G 0.9)] [G loss: 18.1]\n",
            "1126 (5, 1) [D loss: (-26.4)(R -14.9, F -18.7, G 0.7)] [G loss: 19.8]\n",
            "1127 (5, 1) [D loss: (-25.2)(R -13.9, F -19.9, G 0.9)] [G loss: 18.3]\n",
            "1128 (5, 1) [D loss: (-25.6)(R -15.8, F -24.0, G 1.4)] [G loss: 19.5]\n",
            "1129 (5, 1) [D loss: (-24.9)(R -12.5, F -25.3, G 1.3)] [G loss: 23.2]\n",
            "1130 (5, 1) [D loss: (-25.8)(R -12.8, F -22.9, G 1.0)] [G loss: 23.8]\n",
            "1131 (5, 1) [D loss: (-25.6)(R -16.5, F -20.9, G 1.2)] [G loss: 13.8]\n",
            "1132 (5, 1) [D loss: (-27.6)(R -13.7, F -21.0, G 0.7)] [G loss: 24.5]\n",
            "1133 (5, 1) [D loss: (-26.7)(R -15.7, F -17.2, G 0.6)] [G loss: 17.9]\n",
            "1134 (5, 1) [D loss: (-26.2)(R -17.8, F -18.3, G 1.0)] [G loss: 15.9]\n",
            "1135 (5, 1) [D loss: (-24.6)(R -16.0, F -20.4, G 1.2)] [G loss: 16.6]\n",
            "1136 (5, 1) [D loss: (-27.2)(R -13.7, F -20.3, G 0.7)] [G loss: 21.3]\n",
            "1137 (5, 1) [D loss: (-25.9)(R -15.5, F -17.5, G 0.7)] [G loss: 18.9]\n",
            "1138 (5, 1) [D loss: (-25.8)(R -10.3, F -21.2, G 0.6)] [G loss: 14.8]\n",
            "1139 (5, 1) [D loss: (-26.0)(R -20.8, F -13.5, G 0.8)] [G loss: 17.5]\n",
            "1140 (5, 1) [D loss: (-25.8)(R -12.3, F -22.6, G 0.9)] [G loss: 17.4]\n",
            "1141 (5, 1) [D loss: (-26.5)(R -19.6, F -18.1, G 1.1)] [G loss: 21.6]\n",
            "1142 (5, 1) [D loss: (-26.0)(R -19.8, F -13.4, G 0.7)] [G loss: 18.0]\n",
            "1143 (5, 1) [D loss: (-24.9)(R -17.5, F -12.2, G 0.5)] [G loss: 19.2]\n",
            "1144 (5, 1) [D loss: (-25.1)(R -13.7, F -19.4, G 0.8)] [G loss: 19.3]\n",
            "1145 (5, 1) [D loss: (-25.8)(R -15.5, F -19.4, G 0.9)] [G loss: 17.0]\n",
            "1146 (5, 1) [D loss: (-25.2)(R -15.4, F -15.9, G 0.6)] [G loss: 18.1]\n",
            "1147 (5, 1) [D loss: (-26.3)(R -17.4, F -18.3, G 0.9)] [G loss: 20.6]\n",
            "1148 (5, 1) [D loss: (-26.8)(R -17.3, F -16.7, G 0.7)] [G loss: 19.5]\n",
            "1149 (5, 1) [D loss: (-24.6)(R -21.5, F -17.7, G 1.5)] [G loss: 15.9]\n",
            "1150 (5, 1) [D loss: (-26.6)(R -17.4, F -15.7, G 0.6)] [G loss: 17.4]\n",
            "1151 (5, 1) [D loss: (-26.8)(R -14.2, F -19.3, G 0.7)] [G loss: 19.1]\n",
            "1152 (5, 1) [D loss: (-25.0)(R -20.2, F -13.1, G 0.8)] [G loss: 15.6]\n",
            "1153 (5, 1) [D loss: (-26.0)(R -20.6, F -18.5, G 1.3)] [G loss: 17.3]\n",
            "1154 (5, 1) [D loss: (-26.1)(R -24.0, F -12.7, G 1.1)] [G loss: 16.4]\n",
            "1155 (5, 1) [D loss: (-25.3)(R -21.0, F -13.0, G 0.9)] [G loss: 11.8]\n",
            "1156 (5, 1) [D loss: (-25.5)(R -21.1, F -10.9, G 0.7)] [G loss: 12.5]\n",
            "1157 (5, 1) [D loss: (-26.0)(R -17.5, F -14.3, G 0.6)] [G loss: 16.0]\n",
            "1158 (5, 1) [D loss: (-25.5)(R -18.4, F -15.6, G 0.8)] [G loss: 14.8]\n",
            "1159 (5, 1) [D loss: (-25.6)(R -24.9, F -13.8, G 1.3)] [G loss: 15.9]\n",
            "1160 (5, 1) [D loss: (-24.8)(R -16.4, F -15.2, G 0.7)] [G loss: 15.8]\n",
            "1161 (5, 1) [D loss: (-26.5)(R -18.1, F -18.3, G 1.0)] [G loss: 17.1]\n",
            "1162 (5, 1) [D loss: (-25.6)(R -22.5, F -11.9, G 0.9)] [G loss: 14.9]\n",
            "1163 (5, 1) [D loss: (-27.1)(R -19.4, F -17.4, G 1.0)] [G loss: 18.2]\n",
            "1164 (5, 1) [D loss: (-25.0)(R -14.8, F -17.3, G 0.7)] [G loss: 15.4]\n",
            "1165 (5, 1) [D loss: (-26.7)(R -17.9, F -20.2, G 1.1)] [G loss: 16.3]\n",
            "1166 (5, 1) [D loss: (-26.2)(R -18.7, F -16.2, G 0.9)] [G loss: 14.4]\n",
            "1167 (5, 1) [D loss: (-25.9)(R -19.2, F -16.5, G 1.0)] [G loss: 16.2]\n",
            "1168 (5, 1) [D loss: (-25.1)(R -16.5, F -13.4, G 0.5)] [G loss: 17.8]\n",
            "1169 (5, 1) [D loss: (-25.8)(R -16.8, F -15.6, G 0.7)] [G loss: 15.2]\n",
            "1170 (5, 1) [D loss: (-25.0)(R -19.5, F -14.0, G 0.9)] [G loss: 14.0]\n",
            "1171 (5, 1) [D loss: (-25.5)(R -15.9, F -19.9, G 1.0)] [G loss: 13.1]\n",
            "1172 (5, 1) [D loss: (-26.4)(R -18.0, F -18.0, G 1.0)] [G loss: 17.2]\n",
            "1173 (5, 1) [D loss: (-24.8)(R -17.1, F -14.2, G 0.7)] [G loss: 15.9]\n",
            "1174 (5, 1) [D loss: (-26.4)(R -25.0, F -12.7, G 1.1)] [G loss: 13.7]\n",
            "1175 (5, 1) [D loss: (-26.0)(R -23.9, F -9.0, G 0.7)] [G loss: 13.0]\n",
            "1176 (5, 1) [D loss: (-26.3)(R -23.8, F -14.9, G 1.2)] [G loss: 13.3]\n",
            "1177 (5, 1) [D loss: (-26.9)(R -22.0, F -13.5, G 0.9)] [G loss: 13.8]\n",
            "1178 (5, 1) [D loss: (-25.4)(R -19.7, F -12.3, G 0.7)] [G loss: 13.0]\n",
            "1179 (5, 1) [D loss: (-25.9)(R -21.1, F -15.5, G 1.1)] [G loss: 13.7]\n",
            "1180 (5, 1) [D loss: (-26.2)(R -19.0, F -13.2, G 0.6)] [G loss: 13.9]\n",
            "1181 (5, 1) [D loss: (-25.7)(R -26.6, F -9.9, G 1.1)] [G loss: 14.4]\n",
            "1182 (5, 1) [D loss: (-26.5)(R -18.3, F -17.3, G 0.9)] [G loss: 14.3]\n",
            "1183 (5, 1) [D loss: (-26.1)(R -21.7, F -13.4, G 0.9)] [G loss: 15.6]\n",
            "1184 (5, 1) [D loss: (-25.9)(R -20.1, F -15.4, G 1.0)] [G loss: 15.0]\n",
            "1185 (5, 1) [D loss: (-25.9)(R -16.4, F -16.6, G 0.7)] [G loss: 18.5]\n",
            "1186 (5, 1) [D loss: (-25.8)(R -17.4, F -15.0, G 0.7)] [G loss: 14.2]\n",
            "1187 (5, 1) [D loss: (-25.4)(R -15.4, F -17.0, G 0.7)] [G loss: 16.2]\n",
            "1188 (5, 1) [D loss: (-26.4)(R -24.4, F -11.9, G 1.0)] [G loss: 12.4]\n",
            "1189 (5, 1) [D loss: (-24.6)(R -17.3, F -10.7, G 0.3)] [G loss: 8.4]\n",
            "1190 (5, 1) [D loss: (-25.9)(R -25.2, F -13.1, G 1.2)] [G loss: 14.3]\n",
            "1191 (5, 1) [D loss: (-25.1)(R -22.1, F -13.1, G 1.0)] [G loss: 6.2]\n",
            "1192 (5, 1) [D loss: (-26.2)(R -19.9, F -17.5, G 1.1)] [G loss: 15.4]\n",
            "1193 (5, 1) [D loss: (-26.0)(R -21.6, F -14.2, G 1.0)] [G loss: 13.9]\n",
            "1194 (5, 1) [D loss: (-25.7)(R -17.4, F -14.9, G 0.7)] [G loss: 20.8]\n",
            "1195 (5, 1) [D loss: (-26.9)(R -21.5, F -13.7, G 0.8)] [G loss: 16.3]\n",
            "1196 (5, 1) [D loss: (-26.2)(R -23.4, F -13.1, G 1.0)] [G loss: 15.5]\n",
            "1197 (5, 1) [D loss: (-25.7)(R -26.7, F -10.4, G 1.1)] [G loss: 15.1]\n",
            "1198 (5, 1) [D loss: (-25.9)(R -20.8, F -12.8, G 0.8)] [G loss: 13.4]\n",
            "1199 (5, 1) [D loss: (-25.4)(R -19.6, F -13.9, G 0.8)] [G loss: 11.8]\n",
            "1200 (5, 1) [D loss: (-25.9)(R -22.2, F -13.5, G 1.0)] [G loss: 11.5]\n",
            "1201 (5, 1) [D loss: (-24.7)(R -15.4, F -13.5, G 0.4)] [G loss: 12.0]\n",
            "1202 (5, 1) [D loss: (-25.9)(R -23.2, F -11.1, G 0.8)] [G loss: 10.5]\n",
            "1203 (5, 1) [D loss: (-25.8)(R -22.1, F -14.3, G 1.1)] [G loss: 11.5]\n",
            "1204 (5, 1) [D loss: (-26.5)(R -21.4, F -13.0, G 0.8)] [G loss: 14.7]\n",
            "1205 (5, 1) [D loss: (-24.8)(R -27.0, F -9.3, G 1.1)] [G loss: 11.2]\n",
            "1206 (5, 1) [D loss: (-26.1)(R -22.7, F -11.8, G 0.8)] [G loss: 15.6]\n",
            "1207 (5, 1) [D loss: (-26.2)(R -25.7, F -7.4, G 0.7)] [G loss: 8.5]\n",
            "1208 (5, 1) [D loss: (-25.7)(R -19.2, F -14.4, G 0.8)] [G loss: 11.0]\n",
            "1209 (5, 1) [D loss: (-26.3)(R -21.4, F -13.0, G 0.8)] [G loss: 15.0]\n",
            "1210 (5, 1) [D loss: (-25.8)(R -16.9, F -14.2, G 0.5)] [G loss: 11.9]\n",
            "1211 (5, 1) [D loss: (-25.9)(R -22.1, F -11.9, G 0.8)] [G loss: 14.6]\n",
            "1212 (5, 1) [D loss: (-25.9)(R -25.9, F -13.1, G 1.3)] [G loss: 10.3]\n",
            "1213 (5, 1) [D loss: (-26.7)(R -24.3, F -10.2, G 0.8)] [G loss: 13.8]\n",
            "1214 (5, 1) [D loss: (-26.2)(R -22.2, F -10.4, G 0.6)] [G loss: 12.3]\n",
            "1215 (5, 1) [D loss: (-26.9)(R -22.8, F -9.9, G 0.6)] [G loss: 13.1]\n",
            "1216 (5, 1) [D loss: (-25.5)(R -22.4, F -12.1, G 0.9)] [G loss: 10.5]\n",
            "1217 (5, 1) [D loss: (-25.0)(R -22.1, F -9.9, G 0.7)] [G loss: 11.8]\n",
            "1218 (5, 1) [D loss: (-26.0)(R -19.6, F -14.5, G 0.8)] [G loss: 14.0]\n",
            "1219 (5, 1) [D loss: (-25.6)(R -20.4, F -14.9, G 1.0)] [G loss: 15.8]\n",
            "1220 (5, 1) [D loss: (-26.2)(R -22.4, F -13.2, G 1.0)] [G loss: 14.5]\n",
            "1221 (5, 1) [D loss: (-25.6)(R -28.0, F -5.6, G 0.8)] [G loss: 7.1]\n",
            "1222 (5, 1) [D loss: (-24.7)(R -25.2, F -14.0, G 1.4)] [G loss: 10.8]\n",
            "1223 (5, 1) [D loss: (-25.5)(R -17.3, F -13.7, G 0.6)] [G loss: 17.4]\n",
            "1224 (5, 1) [D loss: (-25.1)(R -19.1, F -13.7, G 0.8)] [G loss: 10.2]\n",
            "1225 (5, 1) [D loss: (-26.3)(R -22.2, F -9.8, G 0.6)] [G loss: 10.7]\n",
            "1226 (5, 1) [D loss: (-26.4)(R -18.6, F -17.4, G 1.0)] [G loss: 15.5]\n",
            "1227 (5, 1) [D loss: (-27.4)(R -23.1, F -11.5, G 0.7)] [G loss: 12.9]\n",
            "1228 (5, 1) [D loss: (-26.5)(R -25.8, F -10.0, G 0.9)] [G loss: 11.8]\n",
            "1229 (5, 1) [D loss: (-25.2)(R -26.1, F -9.2, G 1.0)] [G loss: 9.1]\n",
            "1230 (5, 1) [D loss: (-25.4)(R -21.5, F -11.7, G 0.8)] [G loss: 11.3]\n",
            "1231 (5, 1) [D loss: (-25.6)(R -31.7, F -1.2, G 0.7)] [G loss: 4.9]\n",
            "1232 (5, 1) [D loss: (-25.6)(R -21.2, F -11.7, G 0.7)] [G loss: 12.5]\n",
            "1233 (5, 1) [D loss: (-26.2)(R -24.5, F -10.0, G 0.8)] [G loss: 10.8]\n",
            "1234 (5, 1) [D loss: (-26.4)(R -24.9, F -8.8, G 0.7)] [G loss: 9.3]\n",
            "1235 (5, 1) [D loss: (-25.3)(R -22.0, F -11.6, G 0.8)] [G loss: 10.0]\n",
            "1236 (5, 1) [D loss: (-25.4)(R -19.6, F -9.9, G 0.4)] [G loss: 13.1]\n",
            "1237 (5, 1) [D loss: (-26.5)(R -21.2, F -13.5, G 0.8)] [G loss: 13.0]\n",
            "1238 (5, 1) [D loss: (-25.7)(R -27.1, F -7.6, G 0.9)] [G loss: 10.0]\n",
            "1239 (5, 1) [D loss: (-26.1)(R -31.3, F -5.4, G 1.1)] [G loss: 8.2]\n",
            "1240 (5, 1) [D loss: (-26.2)(R -25.2, F -12.5, G 1.1)] [G loss: 6.9]\n",
            "1241 (5, 1) [D loss: (-27.0)(R -24.1, F -10.3, G 0.7)] [G loss: 11.2]\n",
            "1242 (5, 1) [D loss: (-26.6)(R -20.3, F -13.9, G 0.8)] [G loss: 7.2]\n",
            "1243 (5, 1) [D loss: (-25.6)(R -27.6, F -7.9, G 1.0)] [G loss: 11.4]\n",
            "1244 (5, 1) [D loss: (-25.3)(R -22.4, F -9.7, G 0.7)] [G loss: 10.8]\n",
            "1245 (5, 1) [D loss: (-24.7)(R -26.3, F -11.3, G 1.3)] [G loss: 12.8]\n",
            "1246 (5, 1) [D loss: (-25.7)(R -19.7, F -14.5, G 0.9)] [G loss: 9.3]\n",
            "1247 (5, 1) [D loss: (-25.4)(R -26.2, F -8.3, G 0.9)] [G loss: 9.8]\n",
            "1248 (5, 1) [D loss: (-24.9)(R -26.6, F -12.0, G 1.4)] [G loss: 5.9]\n",
            "1249 (5, 1) [D loss: (-25.7)(R -21.9, F -10.2, G 0.6)] [G loss: 7.6]\n",
            "1250 (5, 1) [D loss: (-25.7)(R -20.8, F -11.8, G 0.7)] [G loss: 11.2]\n",
            "1251 (5, 1) [D loss: (-26.3)(R -29.8, F -7.5, G 1.1)] [G loss: 10.2]\n",
            "1252 (5, 1) [D loss: (-25.1)(R -28.2, F -6.8, G 1.0)] [G loss: 7.3]\n",
            "1253 (5, 1) [D loss: (-26.3)(R -22.2, F -10.5, G 0.6)] [G loss: 9.5]\n",
            "1254 (5, 1) [D loss: (-26.1)(R -21.0, F -13.3, G 0.8)] [G loss: 12.2]\n",
            "1255 (5, 1) [D loss: (-26.0)(R -21.6, F -11.8, G 0.7)] [G loss: 12.9]\n",
            "1256 (5, 1) [D loss: (-26.8)(R -24.7, F -10.9, G 0.9)] [G loss: 11.8]\n",
            "1257 (5, 1) [D loss: (-25.4)(R -21.3, F -9.3, G 0.5)] [G loss: 13.8]\n",
            "1258 (5, 1) [D loss: (-26.3)(R -27.5, F -9.1, G 1.0)] [G loss: 8.6]\n",
            "1259 (5, 1) [D loss: (-25.8)(R -22.1, F -13.5, G 1.0)] [G loss: 13.4]\n",
            "1260 (5, 1) [D loss: (-26.3)(R -25.7, F -6.0, G 0.5)] [G loss: 7.4]\n",
            "1261 (5, 1) [D loss: (-26.5)(R -25.5, F -10.2, G 0.9)] [G loss: 11.0]\n",
            "1262 (5, 1) [D loss: (-25.3)(R -22.2, F -16.0, G 1.3)] [G loss: 8.0]\n",
            "1263 (5, 1) [D loss: (-26.8)(R -22.7, F -11.3, G 0.7)] [G loss: 11.1]\n",
            "1264 (5, 1) [D loss: (-25.4)(R -27.4, F -9.3, G 1.1)] [G loss: 9.5]\n",
            "1265 (5, 1) [D loss: (-25.5)(R -23.7, F -10.1, G 0.8)] [G loss: 9.2]\n",
            "1266 (5, 1) [D loss: (-25.9)(R -26.9, F -8.7, G 1.0)] [G loss: 9.6]\n",
            "1267 (5, 1) [D loss: (-25.4)(R -26.9, F -9.5, G 1.1)] [G loss: 8.4]\n",
            "1268 (5, 1) [D loss: (-25.6)(R -27.1, F -11.6, G 1.3)] [G loss: 6.3]\n",
            "1269 (5, 1) [D loss: (-25.6)(R -23.3, F -10.6, G 0.8)] [G loss: 8.7]\n",
            "1270 (5, 1) [D loss: (-26.9)(R -25.2, F -11.2, G 1.0)] [G loss: 10.4]\n",
            "1271 (5, 1) [D loss: (-26.3)(R -24.5, F -9.3, G 0.7)] [G loss: 13.2]\n",
            "1272 (5, 1) [D loss: (-25.6)(R -26.3, F -8.4, G 0.9)] [G loss: 11.0]\n",
            "1273 (5, 1) [D loss: (-26.5)(R -23.7, F -11.7, G 0.9)] [G loss: 13.6]\n",
            "1274 (5, 1) [D loss: (-25.8)(R -25.1, F -5.9, G 0.5)] [G loss: 7.8]\n",
            "1275 (5, 1) [D loss: (-26.1)(R -32.3, F -2.2, G 0.8)] [G loss: 2.9]\n",
            "1276 (5, 1) [D loss: (-25.7)(R -24.7, F -7.9, G 0.7)] [G loss: 9.7]\n",
            "1277 (5, 1) [D loss: (-26.6)(R -28.9, F -7.2, G 1.0)] [G loss: 7.7]\n",
            "1278 (5, 1) [D loss: (-26.1)(R -27.1, F -9.1, G 1.0)] [G loss: 8.3]\n",
            "1279 (5, 1) [D loss: (-25.7)(R -28.0, F -7.1, G 0.9)] [G loss: 8.7]\n",
            "1280 (5, 1) [D loss: (-25.9)(R -24.3, F -7.3, G 0.6)] [G loss: 4.6]\n",
            "1281 (5, 1) [D loss: (-25.4)(R -26.0, F -8.8, G 0.9)] [G loss: 7.6]\n",
            "1282 (5, 1) [D loss: (-26.1)(R -23.4, F -10.0, G 0.7)] [G loss: 10.7]\n",
            "1283 (5, 1) [D loss: (-26.2)(R -23.4, F -8.8, G 0.6)] [G loss: 9.8]\n",
            "1284 (5, 1) [D loss: (-26.3)(R -28.0, F -7.5, G 0.9)] [G loss: 9.5]\n",
            "1285 (5, 1) [D loss: (-26.1)(R -23.6, F -8.7, G 0.6)] [G loss: 11.2]\n",
            "1286 (5, 1) [D loss: (-26.3)(R -26.4, F -7.5, G 0.8)] [G loss: 6.5]\n",
            "1287 (5, 1) [D loss: (-25.8)(R -31.9, F -6.9, G 1.3)] [G loss: 5.8]\n",
            "1288 (5, 1) [D loss: (-26.2)(R -27.9, F -7.4, G 0.9)] [G loss: 6.9]\n",
            "1289 (5, 1) [D loss: (-25.7)(R -26.1, F -6.3, G 0.7)] [G loss: 5.8]\n",
            "1290 (5, 1) [D loss: (-25.1)(R -25.0, F -6.9, G 0.7)] [G loss: 6.7]\n",
            "1291 (5, 1) [D loss: (-26.9)(R -27.8, F -7.2, G 0.8)] [G loss: 9.4]\n",
            "1292 (5, 1) [D loss: (-26.1)(R -23.5, F -9.9, G 0.7)] [G loss: 13.7]\n",
            "1293 (5, 1) [D loss: (-25.6)(R -25.5, F -6.1, G 0.6)] [G loss: 7.1]\n",
            "1294 (5, 1) [D loss: (-26.2)(R -21.9, F -11.3, G 0.7)] [G loss: 7.8]\n",
            "1295 (5, 1) [D loss: (-26.3)(R -24.8, F -6.1, G 0.5)] [G loss: 4.2]\n",
            "1296 (5, 1) [D loss: (-26.0)(R -24.8, F -9.6, G 0.8)] [G loss: 10.5]\n",
            "1297 (5, 1) [D loss: (-26.7)(R -29.5, F -5.4, G 0.8)] [G loss: 8.8]\n",
            "1298 (5, 1) [D loss: (-26.3)(R -25.3, F -8.1, G 0.7)] [G loss: 6.6]\n",
            "1299 (5, 1) [D loss: (-25.9)(R -29.6, F -5.0, G 0.9)] [G loss: 7.2]\n",
            "1300 (5, 1) [D loss: (-26.5)(R -30.3, F -4.0, G 0.8)] [G loss: 5.8]\n",
            "1301 (5, 1) [D loss: (-24.9)(R -28.9, F -6.8, G 1.1)] [G loss: 7.5]\n",
            "1302 (5, 1) [D loss: (-26.9)(R -27.0, F -6.2, G 0.6)] [G loss: 9.7]\n",
            "1303 (5, 1) [D loss: (-25.7)(R -23.5, F -8.8, G 0.7)] [G loss: 3.4]\n",
            "1304 (5, 1) [D loss: (-25.5)(R -26.5, F -5.5, G 0.6)] [G loss: 5.4]\n",
            "1305 (5, 1) [D loss: (-26.2)(R -27.7, F -9.7, G 1.1)] [G loss: 7.7]\n",
            "1306 (5, 1) [D loss: (-26.4)(R -30.0, F -6.3, G 1.0)] [G loss: 8.2]\n",
            "1307 (5, 1) [D loss: (-25.8)(R -28.6, F -5.3, G 0.8)] [G loss: 5.5]\n",
            "1308 (5, 1) [D loss: (-25.4)(R -26.6, F -6.9, G 0.8)] [G loss: 7.4]\n",
            "1309 (5, 1) [D loss: (-25.9)(R -28.2, F -7.0, G 0.9)] [G loss: 7.6]\n",
            "1310 (5, 1) [D loss: (-26.3)(R -32.2, F -0.0, G 0.6)] [G loss: 0.0]\n",
            "1311 (5, 1) [D loss: (-25.8)(R -30.1, F -5.0, G 0.9)] [G loss: 5.2]\n",
            "1312 (5, 1) [D loss: (-26.3)(R -24.4, F -7.9, G 0.6)] [G loss: 8.2]\n",
            "1313 (5, 1) [D loss: (-25.8)(R -29.0, F -6.4, G 1.0)] [G loss: 4.3]\n",
            "1314 (5, 1) [D loss: (-26.6)(R -25.9, F -8.1, G 0.7)] [G loss: 6.3]\n",
            "1315 (5, 1) [D loss: (-26.7)(R -25.7, F -7.1, G 0.6)] [G loss: 8.2]\n",
            "1316 (5, 1) [D loss: (-26.0)(R -29.7, F -4.7, G 0.9)] [G loss: 4.2]\n",
            "1317 (5, 1) [D loss: (-25.6)(R -24.0, F -6.7, G 0.5)] [G loss: 2.8]\n",
            "1318 (5, 1) [D loss: (-26.5)(R -30.4, F -7.7, G 1.2)] [G loss: 7.9]\n",
            "1319 (5, 1) [D loss: (-25.8)(R -33.9, F -2.5, G 1.1)] [G loss: 6.6]\n",
            "1320 (5, 1) [D loss: (-25.1)(R -29.9, F -5.8, G 1.1)] [G loss: 2.6]\n",
            "1321 (5, 1) [D loss: (-26.7)(R -25.7, F -8.8, G 0.8)] [G loss: 8.0]\n",
            "1322 (5, 1) [D loss: (-25.7)(R -28.1, F -7.1, G 1.0)] [G loss: 4.5]\n",
            "1323 (5, 1) [D loss: (-26.2)(R -29.3, F -7.1, G 1.0)] [G loss: 6.5]\n",
            "1324 (5, 1) [D loss: (-26.3)(R -25.5, F -7.8, G 0.7)] [G loss: 11.2]\n",
            "1325 (5, 1) [D loss: (-26.2)(R -29.2, F -4.6, G 0.8)] [G loss: 3.3]\n",
            "1326 (5, 1) [D loss: (-26.3)(R -32.5, F -2.4, G 0.9)] [G loss: 3.2]\n",
            "1327 (5, 1) [D loss: (-25.9)(R -29.9, F -4.8, G 0.9)] [G loss: 5.9]\n",
            "1328 (5, 1) [D loss: (-25.9)(R -28.0, F -6.8, G 0.9)] [G loss: 5.7]\n",
            "1329 (5, 1) [D loss: (-25.8)(R -26.1, F -5.3, G 0.6)] [G loss: 3.8]\n",
            "1330 (5, 1) [D loss: (-26.6)(R -28.1, F -5.4, G 0.7)] [G loss: 5.4]\n",
            "1331 (5, 1) [D loss: (-25.9)(R -31.7, F -4.6, G 1.0)] [G loss: 1.9]\n",
            "1332 (5, 1) [D loss: (-25.4)(R -24.4, F -9.5, G 0.9)] [G loss: 7.8]\n",
            "1333 (5, 1) [D loss: (-25.8)(R -29.4, F -2.5, G 0.6)] [G loss: 8.0]\n",
            "1334 (5, 1) [D loss: (-26.4)(R -30.9, F -3.3, G 0.8)] [G loss: 4.0]\n",
            "1335 (5, 1) [D loss: (-26.1)(R -31.2, F -3.7, G 0.9)] [G loss: 1.6]\n",
            "1336 (5, 1) [D loss: (-26.8)(R -27.3, F -6.4, G 0.7)] [G loss: 4.3]\n",
            "1337 (5, 1) [D loss: (-26.0)(R -31.5, F 0.3, G 0.5)] [G loss: 2.1]\n",
            "1338 (5, 1) [D loss: (-25.7)(R -29.4, F -6.3, G 1.0)] [G loss: 5.4]\n",
            "1339 (5, 1) [D loss: (-25.8)(R -26.2, F -6.0, G 0.6)] [G loss: 5.0]\n",
            "1340 (5, 1) [D loss: (-25.8)(R -27.6, F -4.4, G 0.6)] [G loss: 5.8]\n",
            "1341 (5, 1) [D loss: (-27.6)(R -31.7, F -3.5, G 0.8)] [G loss: 5.9]\n",
            "1342 (5, 1) [D loss: (-25.8)(R -34.5, F -1.5, G 1.0)] [G loss: 2.9]\n",
            "1343 (5, 1) [D loss: (-25.0)(R -24.1, F -10.2, G 0.9)] [G loss: 5.5]\n",
            "1344 (5, 1) [D loss: (-25.7)(R -27.7, F -5.6, G 0.8)] [G loss: 4.3]\n",
            "1345 (5, 1) [D loss: (-26.5)(R -32.1, F -3.9, G 0.9)] [G loss: 5.1]\n",
            "1346 (5, 1) [D loss: (-26.5)(R -31.0, F -3.3, G 0.8)] [G loss: 6.0]\n",
            "1347 (5, 1) [D loss: (-25.4)(R -32.9, F -4.0, G 1.2)] [G loss: 5.8]\n",
            "1348 (5, 1) [D loss: (-25.7)(R -30.6, F -4.8, G 1.0)] [G loss: 9.2]\n",
            "1349 (5, 1) [D loss: (-26.1)(R -29.3, F -5.2, G 0.8)] [G loss: 7.6]\n",
            "1350 (5, 1) [D loss: (-26.5)(R -29.5, F -3.2, G 0.6)] [G loss: 3.0]\n",
            "1351 (5, 1) [D loss: (-25.9)(R -27.4, F -5.3, G 0.7)] [G loss: 4.5]\n",
            "1352 (5, 1) [D loss: (-26.8)(R -32.0, F -2.8, G 0.8)] [G loss: 3.4]\n",
            "1353 (5, 1) [D loss: (-25.7)(R -31.7, F 1.4, G 0.5)] [G loss: 4.5]\n",
            "1354 (5, 1) [D loss: (-27.1)(R -29.7, F -4.4, G 0.7)] [G loss: 2.5]\n",
            "1355 (5, 1) [D loss: (-26.4)(R -26.3, F -6.6, G 0.7)] [G loss: 6.0]\n",
            "1356 (5, 1) [D loss: (-26.2)(R -30.2, F -7.6, G 1.2)] [G loss: 6.3]\n",
            "1357 (5, 1) [D loss: (-26.9)(R -32.1, F -4.7, G 1.0)] [G loss: 4.5]\n",
            "1358 (5, 1) [D loss: (-25.5)(R -32.6, F -3.6, G 1.1)] [G loss: 6.9]\n",
            "1359 (5, 1) [D loss: (-26.1)(R -30.2, F -4.9, G 0.9)] [G loss: 4.6]\n",
            "1360 (5, 1) [D loss: (-25.6)(R -31.8, F -3.9, G 1.0)] [G loss: 7.9]\n",
            "1361 (5, 1) [D loss: (-26.4)(R -31.2, F -3.3, G 0.8)] [G loss: 5.6]\n",
            "1362 (5, 1) [D loss: (-25.6)(R -26.7, F -5.1, G 0.6)] [G loss: 5.5]\n",
            "1363 (5, 1) [D loss: (-26.7)(R -35.7, F 0.1, G 0.9)] [G loss: 1.0]\n",
            "1364 (5, 1) [D loss: (-27.1)(R -31.1, F -4.9, G 0.9)] [G loss: 3.2]\n",
            "1365 (5, 1) [D loss: (-26.2)(R -29.4, F -3.9, G 0.7)] [G loss: 5.5]\n",
            "1366 (5, 1) [D loss: (-25.1)(R -39.5, F 1.2, G 1.3)] [G loss: 4.3]\n",
            "1367 (5, 1) [D loss: (-26.3)(R -27.9, F -4.9, G 0.6)] [G loss: 2.6]\n",
            "1368 (5, 1) [D loss: (-24.9)(R -28.5, F -4.4, G 0.8)] [G loss: 3.9]\n",
            "1369 (5, 1) [D loss: (-26.0)(R -33.4, F -2.8, G 1.0)] [G loss: 5.2]\n",
            "1370 (5, 1) [D loss: (-26.5)(R -35.1, F -2.6, G 1.1)] [G loss: 3.4]\n",
            "1371 (5, 1) [D loss: (-26.2)(R -31.3, F -5.2, G 1.0)] [G loss: 5.9]\n",
            "1372 (5, 1) [D loss: (-26.0)(R -31.6, F -4.2, G 1.0)] [G loss: 5.3]\n",
            "1373 (5, 1) [D loss: (-25.8)(R -31.8, F -4.3, G 1.0)] [G loss: 3.9]\n",
            "1374 (5, 1) [D loss: (-25.7)(R -24.9, F -5.5, G 0.5)] [G loss: 4.3]\n",
            "1375 (5, 1) [D loss: (-26.7)(R -29.0, F -8.5, G 1.1)] [G loss: 5.9]\n",
            "1376 (5, 1) [D loss: (-25.3)(R -25.1, F -6.1, G 0.6)] [G loss: 4.0]\n",
            "1377 (5, 1) [D loss: (-26.6)(R -31.3, F -2.0, G 0.7)] [G loss: 3.1]\n",
            "1378 (5, 1) [D loss: (-24.9)(R -26.7, F -3.4, G 0.5)] [G loss: 5.3]\n",
            "1379 (5, 1) [D loss: (-24.2)(R -46.1, F 8.0, G 1.4)] [G loss: 3.0]\n",
            "1380 (5, 1) [D loss: (-26.2)(R -26.3, F -7.1, G 0.7)] [G loss: 5.0]\n",
            "1381 (5, 1) [D loss: (-26.9)(R -36.3, F -0.4, G 1.0)] [G loss: 1.7]\n",
            "1382 (5, 1) [D loss: (-26.7)(R -30.6, F -1.7, G 0.6)] [G loss: 1.0]\n",
            "1383 (5, 1) [D loss: (-26.2)(R -30.8, F -3.7, G 0.8)] [G loss: 4.0]\n",
            "1384 (5, 1) [D loss: (-26.5)(R -33.5, F -3.4, G 1.0)] [G loss: 4.4]\n",
            "1385 (5, 1) [D loss: (-26.0)(R -27.5, F -5.1, G 0.7)] [G loss: 4.4]\n",
            "1386 (5, 1) [D loss: (-26.2)(R -35.6, F -2.6, G 1.2)] [G loss: 1.2]\n",
            "1387 (5, 1) [D loss: (-26.0)(R -28.4, F -4.2, G 0.7)] [G loss: 1.4]\n",
            "1388 (5, 1) [D loss: (-25.7)(R -24.8, F -5.8, G 0.5)] [G loss: 1.6]\n",
            "1389 (5, 1) [D loss: (-26.4)(R -34.4, F -1.4, G 0.9)] [G loss: 1.2]\n",
            "1390 (5, 1) [D loss: (-26.1)(R -32.2, F -5.8, G 1.2)] [G loss: 2.5]\n",
            "1391 (5, 1) [D loss: (-25.8)(R -30.9, F -6.1, G 1.1)] [G loss: 6.3]\n",
            "1392 (5, 1) [D loss: (-25.5)(R -28.7, F -3.0, G 0.6)] [G loss: 4.7]\n",
            "1393 (5, 1) [D loss: (-27.7)(R -34.6, F -3.9, G 1.1)] [G loss: 3.0]\n",
            "1394 (5, 1) [D loss: (-25.0)(R -35.2, F 4.0, G 0.6)] [G loss: -6.4]\n",
            "1395 (5, 1) [D loss: (-25.1)(R -32.4, F 2.1, G 0.5)] [G loss: -2.1]\n",
            "1396 (5, 1) [D loss: (-25.8)(R -33.4, F -4.8, G 1.2)] [G loss: 2.5]\n",
            "1397 (5, 1) [D loss: (-26.1)(R -26.8, F -6.1, G 0.7)] [G loss: 5.5]\n",
            "1398 (5, 1) [D loss: (-26.0)(R -35.1, F -1.1, G 1.0)] [G loss: 4.0]\n",
            "1399 (5, 1) [D loss: (-25.8)(R -29.7, F -2.1, G 0.6)] [G loss: 0.8]\n",
            "1400 (5, 1) [D loss: (-27.4)(R -34.8, F -2.6, G 1.0)] [G loss: 1.2]\n",
            "1401 (5, 1) [D loss: (-26.2)(R -30.1, F -3.6, G 0.7)] [G loss: 3.2]\n",
            "1402 (5, 1) [D loss: (-26.4)(R -33.5, F -1.7, G 0.9)] [G loss: 6.0]\n",
            "1403 (5, 1) [D loss: (-26.7)(R -34.1, F -3.0, G 1.0)] [G loss: 2.9]\n",
            "1404 (5, 1) [D loss: (-25.5)(R -33.3, F -0.8, G 0.9)] [G loss: 1.3]\n",
            "1405 (5, 1) [D loss: (-26.9)(R -31.6, F -2.7, G 0.7)] [G loss: 0.6]\n",
            "1406 (5, 1) [D loss: (-26.8)(R -32.7, F -3.3, G 0.9)] [G loss: 4.7]\n",
            "1407 (5, 1) [D loss: (-27.2)(R -29.8, F -6.1, G 0.9)] [G loss: 6.6]\n",
            "1408 (5, 1) [D loss: (-27.2)(R -30.5, F -4.3, G 0.8)] [G loss: 4.7]\n",
            "1409 (5, 1) [D loss: (-26.4)(R -27.4, F -5.9, G 0.7)] [G loss: 0.3]\n",
            "1410 (5, 1) [D loss: (-26.3)(R -31.5, F -3.1, G 0.8)] [G loss: 6.3]\n",
            "1411 (5, 1) [D loss: (-26.4)(R -32.7, F -1.0, G 0.7)] [G loss: 1.9]\n",
            "1412 (5, 1) [D loss: (-25.6)(R -29.7, F -1.6, G 0.6)] [G loss: 2.2]\n",
            "1413 (5, 1) [D loss: (-26.7)(R -35.8, F -1.1, G 1.0)] [G loss: 1.3]\n",
            "1414 (5, 1) [D loss: (-24.6)(R -40.0, F -2.0, G 1.7)] [G loss: 2.6]\n",
            "1415 (5, 1) [D loss: (-25.4)(R -35.2, F -0.9, G 1.1)] [G loss: 0.2]\n",
            "1416 (5, 1) [D loss: (-26.3)(R -32.9, F -0.9, G 0.8)] [G loss: 1.3]\n",
            "1417 (5, 1) [D loss: (-26.5)(R -31.1, F -4.3, G 0.9)] [G loss: 4.2]\n",
            "1418 (5, 1) [D loss: (-25.0)(R -32.4, F 0.7, G 0.7)] [G loss: 1.4]\n",
            "1419 (5, 1) [D loss: (-26.1)(R -35.2, F -1.6, G 1.1)] [G loss: 0.8]\n",
            "1420 (5, 1) [D loss: (-26.0)(R -27.7, F -4.6, G 0.6)] [G loss: 2.4]\n",
            "1421 (5, 1) [D loss: (-26.3)(R -29.9, F -3.9, G 0.7)] [G loss: 3.0]\n",
            "1422 (5, 1) [D loss: (-26.7)(R -30.6, F -2.8, G 0.7)] [G loss: 5.2]\n",
            "1423 (5, 1) [D loss: (-26.7)(R -38.2, F 2.4, G 0.9)] [G loss: 0.7]\n",
            "1424 (5, 1) [D loss: (-25.9)(R -27.6, F -3.6, G 0.5)] [G loss: -1.0]\n",
            "1425 (5, 1) [D loss: (-25.9)(R -25.7, F -4.8, G 0.5)] [G loss: -0.1]\n",
            "1426 (5, 1) [D loss: (-26.0)(R -34.4, F -2.4, G 1.1)] [G loss: 1.6]\n",
            "1427 (5, 1) [D loss: (-26.4)(R -34.1, F -0.9, G 0.9)] [G loss: 0.0]\n",
            "1428 (5, 1) [D loss: (-26.1)(R -31.7, F -3.9, G 1.0)] [G loss: 3.9]\n",
            "1429 (5, 1) [D loss: (-27.2)(R -35.9, F -1.4, G 1.0)] [G loss: 2.0]\n",
            "1430 (5, 1) [D loss: (-25.5)(R -28.0, F -1.9, G 0.4)] [G loss: -3.1]\n",
            "1431 (5, 1) [D loss: (-27.1)(R -31.5, F -3.9, G 0.8)] [G loss: 3.0]\n",
            "1432 (5, 1) [D loss: (-26.9)(R -30.8, F -3.2, G 0.7)] [G loss: 1.1]\n",
            "1433 (5, 1) [D loss: (-26.3)(R -32.7, F -2.3, G 0.9)] [G loss: 4.0]\n",
            "1434 (5, 1) [D loss: (-25.8)(R -32.5, F -4.2, G 1.1)] [G loss: 1.3]\n",
            "1435 (5, 1) [D loss: (-26.1)(R -29.7, F -3.1, G 0.7)] [G loss: 3.4]\n",
            "1436 (5, 1) [D loss: (-27.1)(R -33.6, F -1.9, G 0.8)] [G loss: 1.9]\n",
            "1437 (5, 1) [D loss: (-26.3)(R -32.8, F -1.5, G 0.8)] [G loss: 2.7]\n",
            "1438 (5, 1) [D loss: (-26.5)(R -35.2, F -1.6, G 1.0)] [G loss: 0.3]\n",
            "1439 (5, 1) [D loss: (-25.8)(R -34.6, F -1.2, G 1.0)] [G loss: 2.3]\n",
            "1440 (5, 1) [D loss: (-25.5)(R -29.7, F -1.1, G 0.5)] [G loss: -0.2]\n",
            "1441 (5, 1) [D loss: (-26.7)(R -35.8, F -0.3, G 0.9)] [G loss: 3.7]\n",
            "1442 (5, 1) [D loss: (-27.5)(R -32.5, F -2.4, G 0.7)] [G loss: 2.2]\n",
            "1443 (5, 1) [D loss: (-26.1)(R -30.2, F -3.9, G 0.8)] [G loss: -0.1]\n",
            "1444 (5, 1) [D loss: (-27.0)(R -34.6, F -2.1, G 1.0)] [G loss: 4.1]\n",
            "1445 (5, 1) [D loss: (-26.1)(R -39.1, F -0.8, G 1.4)] [G loss: 0.3]\n",
            "1446 (5, 1) [D loss: (-26.0)(R -34.0, F -1.4, G 0.9)] [G loss: 3.0]\n",
            "1447 (5, 1) [D loss: (-26.0)(R -33.9, F -3.1, G 1.1)] [G loss: -0.7]\n",
            "1448 (5, 1) [D loss: (-25.8)(R -31.0, F -1.5, G 0.7)] [G loss: 0.2]\n",
            "1449 (5, 1) [D loss: (-26.0)(R -27.3, F -3.0, G 0.4)] [G loss: 1.9]\n",
            "1450 (5, 1) [D loss: (-25.2)(R -30.5, F 0.1, G 0.5)] [G loss: -1.0]\n",
            "1451 (5, 1) [D loss: (-26.6)(R -30.1, F -3.6, G 0.7)] [G loss: 2.2]\n",
            "1452 (5, 1) [D loss: (-26.6)(R -34.2, F -2.9, G 1.0)] [G loss: 4.7]\n",
            "1453 (5, 1) [D loss: (-26.5)(R -35.2, F -1.0, G 1.0)] [G loss: 1.9]\n",
            "1454 (5, 1) [D loss: (-27.6)(R -33.1, F -2.4, G 0.8)] [G loss: 0.7]\n",
            "1455 (5, 1) [D loss: (-25.9)(R -28.1, F -4.3, G 0.7)] [G loss: 2.4]\n",
            "1456 (5, 1) [D loss: (-27.3)(R -32.6, F -3.8, G 0.9)] [G loss: 0.7]\n",
            "1457 (5, 1) [D loss: (-27.2)(R -33.5, F -1.9, G 0.8)] [G loss: 1.4]\n",
            "1458 (5, 1) [D loss: (-26.8)(R -32.6, F -1.5, G 0.7)] [G loss: 2.2]\n",
            "1459 (5, 1) [D loss: (-26.1)(R -35.5, F -1.9, G 1.1)] [G loss: 1.9]\n",
            "1460 (5, 1) [D loss: (-26.3)(R -33.2, F -2.3, G 0.9)] [G loss: 3.0]\n",
            "1461 (5, 1) [D loss: (-26.0)(R -29.8, F -1.3, G 0.5)] [G loss: 1.2]\n",
            "1462 (5, 1) [D loss: (-25.4)(R -35.6, F 0.4, G 1.0)] [G loss: 1.6]\n",
            "1463 (5, 1) [D loss: (-27.2)(R -35.2, F -1.6, G 1.0)] [G loss: 3.2]\n",
            "1464 (5, 1) [D loss: (-25.9)(R -37.7, F -0.4, G 1.2)] [G loss: 3.4]\n",
            "1465 (5, 1) [D loss: (-27.9)(R -34.7, F -2.9, G 1.0)] [G loss: 4.2]\n",
            "1466 (5, 1) [D loss: (-26.2)(R -34.1, F -1.5, G 0.9)] [G loss: 2.4]\n",
            "1467 (5, 1) [D loss: (-26.2)(R -32.4, F -1.9, G 0.8)] [G loss: 3.4]\n",
            "1468 (5, 1) [D loss: (-25.8)(R -31.4, F 0.2, G 0.5)] [G loss: -1.3]\n",
            "1469 (5, 1) [D loss: (-26.7)(R -34.9, F 0.0, G 0.8)] [G loss: 1.4]\n",
            "1470 (5, 1) [D loss: (-26.7)(R -33.5, F -2.1, G 0.9)] [G loss: -0.7]\n",
            "1471 (5, 1) [D loss: (-25.7)(R -30.0, F -2.2, G 0.6)] [G loss: -0.8]\n",
            "1472 (5, 1) [D loss: (-25.8)(R -32.0, F -3.9, G 1.0)] [G loss: 1.0]\n",
            "1473 (5, 1) [D loss: (-25.3)(R -28.2, F -3.1, G 0.6)] [G loss: 0.1]\n",
            "1474 (5, 1) [D loss: (-26.8)(R -35.4, F -2.3, G 1.1)] [G loss: 2.5]\n",
            "1475 (5, 1) [D loss: (-27.4)(R -33.6, F -4.0, G 1.0)] [G loss: 2.8]\n",
            "1476 (5, 1) [D loss: (-27.7)(R -36.7, F -0.6, G 1.0)] [G loss: 2.9]\n",
            "1477 (5, 1) [D loss: (-26.4)(R -35.7, F 1.5, G 0.8)] [G loss: -0.2]\n",
            "1478 (5, 1) [D loss: (-26.1)(R -37.1, F -0.0, G 1.1)] [G loss: 1.0]\n",
            "1479 (5, 1) [D loss: (-27.4)(R -34.0, F -2.4, G 0.9)] [G loss: 2.4]\n",
            "1480 (5, 1) [D loss: (-25.7)(R -30.2, F -1.8, G 0.6)] [G loss: 0.9]\n",
            "1481 (5, 1) [D loss: (-25.9)(R -35.1, F -1.9, G 1.1)] [G loss: 3.1]\n",
            "1482 (5, 1) [D loss: (-26.0)(R -31.5, F -2.6, G 0.8)] [G loss: 2.0]\n",
            "1483 (5, 1) [D loss: (-26.9)(R -33.3, F -0.5, G 0.7)] [G loss: 0.2]\n",
            "1484 (5, 1) [D loss: (-26.5)(R -34.8, F -0.4, G 0.9)] [G loss: 0.9]\n",
            "1485 (5, 1) [D loss: (-26.5)(R -29.5, F -2.3, G 0.5)] [G loss: -1.0]\n",
            "1486 (5, 1) [D loss: (-25.6)(R -30.2, F -1.9, G 0.7)] [G loss: 1.2]\n",
            "1487 (5, 1) [D loss: (-26.9)(R -32.3, F -4.3, G 1.0)] [G loss: 2.8]\n",
            "1488 (5, 1) [D loss: (-26.0)(R -32.3, F -1.8, G 0.8)] [G loss: 3.5]\n",
            "1489 (5, 1) [D loss: (-24.5)(R -40.3, F 1.8, G 1.4)] [G loss: 0.6]\n",
            "1490 (5, 1) [D loss: (-25.5)(R -35.2, F 1.1, G 0.9)] [G loss: 1.1]\n",
            "1491 (5, 1) [D loss: (-26.2)(R -35.5, F 1.2, G 0.8)] [G loss: 0.3]\n",
            "1492 (5, 1) [D loss: (-26.3)(R -30.9, F -2.0, G 0.7)] [G loss: 1.9]\n",
            "1493 (5, 1) [D loss: (-27.1)(R -33.1, F -2.0, G 0.8)] [G loss: 2.9]\n",
            "1494 (5, 1) [D loss: (-26.9)(R -41.1, F 2.6, G 1.2)] [G loss: -1.5]\n",
            "1495 (5, 1) [D loss: (-26.9)(R -31.4, F -2.8, G 0.7)] [G loss: 4.1]\n",
            "1496 (5, 1) [D loss: (-26.1)(R -31.3, F -1.7, G 0.7)] [G loss: 1.1]\n",
            "1497 (5, 1) [D loss: (-27.4)(R -37.8, F -0.4, G 1.1)] [G loss: 1.8]\n",
            "1498 (5, 1) [D loss: (-25.7)(R -31.3, F -0.8, G 0.6)] [G loss: -2.3]\n",
            "1499 (5, 1) [D loss: (-25.5)(R -32.7, F -1.6, G 0.9)] [G loss: 1.7]\n",
            "1500 (5, 1) [D loss: (-26.4)(R -31.4, F -3.2, G 0.8)] [G loss: 1.9]\n",
            "1501 (5, 1) [D loss: (-26.0)(R -27.6, F -6.1, G 0.8)] [G loss: 3.5]\n",
            "1502 (5, 1) [D loss: (-26.3)(R -34.0, F 0.4, G 0.7)] [G loss: 1.9]\n",
            "1503 (5, 1) [D loss: (-26.4)(R -38.6, F 0.9, G 1.1)] [G loss: 2.1]\n",
            "1504 (5, 1) [D loss: (-26.9)(R -36.7, F -0.3, G 1.0)] [G loss: 1.5]\n",
            "1505 (5, 1) [D loss: (-27.2)(R -34.0, F -0.5, G 0.7)] [G loss: -1.3]\n",
            "1506 (5, 1) [D loss: (-27.1)(R -33.6, F -2.6, G 0.9)] [G loss: 2.4]\n",
            "1507 (5, 1) [D loss: (-26.7)(R -31.2, F -2.3, G 0.7)] [G loss: 1.7]\n",
            "1508 (5, 1) [D loss: (-26.1)(R -32.3, F -1.9, G 0.8)] [G loss: 3.0]\n",
            "1509 (5, 1) [D loss: (-26.9)(R -32.8, F -2.6, G 0.9)] [G loss: 3.7]\n",
            "1510 (5, 1) [D loss: (-25.2)(R -40.0, F 1.2, G 1.4)] [G loss: 0.5]\n",
            "1511 (5, 1) [D loss: (-26.3)(R -32.4, F -0.1, G 0.6)] [G loss: -0.3]\n",
            "1512 (5, 1) [D loss: (-26.1)(R -31.7, F -1.0, G 0.7)] [G loss: 1.2]\n",
            "1513 (5, 1) [D loss: (-26.7)(R -32.7, F -0.0, G 0.6)] [G loss: 1.9]\n",
            "1514 (5, 1) [D loss: (-25.7)(R -36.4, F 0.1, G 1.1)] [G loss: -1.7]\n",
            "1515 (5, 1) [D loss: (-24.8)(R -26.5, F -2.9, G 0.5)] [G loss: 1.2]\n",
            "1516 (5, 1) [D loss: (-26.2)(R -32.3, F -3.2, G 0.9)] [G loss: -0.3]\n",
            "1517 (5, 1) [D loss: (-26.7)(R -33.3, F -1.3, G 0.8)] [G loss: 1.1]\n",
            "1518 (5, 1) [D loss: (-25.6)(R -27.4, F -2.6, G 0.4)] [G loss: -2.2]\n",
            "1519 (5, 1) [D loss: (-27.0)(R -32.5, F -1.9, G 0.7)] [G loss: 0.6]\n",
            "1520 (5, 1) [D loss: (-26.6)(R -36.7, F -0.1, G 1.0)] [G loss: 1.5]\n",
            "1521 (5, 1) [D loss: (-27.5)(R -34.3, F -0.6, G 0.7)] [G loss: 1.8]\n",
            "1522 (5, 1) [D loss: (-26.3)(R -33.5, F -0.5, G 0.8)] [G loss: 0.4]\n",
            "1523 (5, 1) [D loss: (-26.1)(R -33.5, F -0.2, G 0.8)] [G loss: 1.5]\n",
            "1524 (5, 1) [D loss: (-26.2)(R -35.7, F 0.3, G 0.9)] [G loss: -1.0]\n",
            "1525 (5, 1) [D loss: (-25.7)(R -31.8, F 0.1, G 0.6)] [G loss: -1.6]\n",
            "1526 (5, 1) [D loss: (-26.9)(R -40.7, F 2.3, G 1.2)] [G loss: -0.7]\n",
            "1527 (5, 1) [D loss: (-26.7)(R -39.5, F 0.6, G 1.2)] [G loss: 0.4]\n",
            "1528 (5, 1) [D loss: (-28.1)(R -37.1, F 1.3, G 0.8)] [G loss: -0.8]\n",
            "1529 (5, 1) [D loss: (-25.3)(R -35.6, F -0.4, G 1.1)] [G loss: -1.1]\n",
            "1530 (5, 1) [D loss: (-25.9)(R -35.3, F 0.2, G 0.9)] [G loss: -0.9]\n",
            "1531 (5, 1) [D loss: (-25.6)(R -33.4, F 2.2, G 0.6)] [G loss: -2.8]\n",
            "1532 (5, 1) [D loss: (-26.4)(R -35.4, F -2.5, G 1.2)] [G loss: -0.4]\n",
            "1533 (5, 1) [D loss: (-27.5)(R -34.1, F -1.2, G 0.8)] [G loss: 1.0]\n",
            "1534 (5, 1) [D loss: (-26.8)(R -33.4, F -0.2, G 0.7)] [G loss: -0.9]\n",
            "1535 (5, 1) [D loss: (-27.1)(R -33.1, F -3.2, G 0.9)] [G loss: 4.7]\n",
            "1536 (5, 1) [D loss: (-25.9)(R -41.7, F 2.3, G 1.3)] [G loss: 5.0]\n",
            "1537 (5, 1) [D loss: (-26.1)(R -36.1, F 0.4, G 1.0)] [G loss: -2.4]\n",
            "1538 (5, 1) [D loss: (-25.4)(R -31.6, F 0.2, G 0.6)] [G loss: 0.1]\n",
            "1539 (5, 1) [D loss: (-26.0)(R -40.5, F 3.0, G 1.1)] [G loss: -2.8]\n",
            "1540 (5, 1) [D loss: (-26.7)(R -31.6, F -1.1, G 0.6)] [G loss: 0.2]\n",
            "1541 (5, 1) [D loss: (-26.2)(R -32.1, F -1.3, G 0.7)] [G loss: -1.6]\n",
            "1542 (5, 1) [D loss: (-26.7)(R -35.5, F -1.7, G 1.1)] [G loss: -0.1]\n",
            "1543 (5, 1) [D loss: (-26.5)(R -36.6, F 0.3, G 1.0)] [G loss: 2.7]\n",
            "1544 (5, 1) [D loss: (-26.4)(R -35.0, F -0.2, G 0.9)] [G loss: 1.8]\n",
            "1545 (5, 1) [D loss: (-27.2)(R -40.1, F 1.7, G 1.1)] [G loss: -1.6]\n",
            "1546 (5, 1) [D loss: (-26.6)(R -37.5, F 0.0, G 1.1)] [G loss: 1.8]\n",
            "1547 (5, 1) [D loss: (-26.6)(R -30.9, F -0.8, G 0.5)] [G loss: -0.9]\n",
            "1548 (5, 1) [D loss: (-27.0)(R -35.5, F 1.5, G 0.7)] [G loss: -1.5]\n",
            "1549 (5, 1) [D loss: (-26.0)(R -37.7, F 1.9, G 1.0)] [G loss: 0.4]\n",
            "1550 (5, 1) [D loss: (-25.0)(R -34.1, F -0.4, G 0.9)] [G loss: -0.3]\n",
            "1551 (5, 1) [D loss: (-26.9)(R -33.2, F -1.8, G 0.8)] [G loss: 1.1]\n",
            "1552 (5, 1) [D loss: (-27.7)(R -39.6, F 0.7, G 1.1)] [G loss: 2.0]\n",
            "1553 (5, 1) [D loss: (-26.5)(R -38.7, F 2.7, G 1.0)] [G loss: 0.6]\n",
            "1554 (5, 1) [D loss: (-27.3)(R -36.0, F 2.2, G 0.7)] [G loss: -1.4]\n",
            "1555 (5, 1) [D loss: (-26.2)(R -36.1, F 0.2, G 1.0)] [G loss: 0.1]\n",
            "1556 (5, 1) [D loss: (-26.4)(R -32.7, F -0.9, G 0.7)] [G loss: -0.2]\n",
            "1557 (5, 1) [D loss: (-25.7)(R -36.1, F 0.4, G 1.0)] [G loss: -0.9]\n",
            "1558 (5, 1) [D loss: (-24.8)(R -36.0, F -2.4, G 1.4)] [G loss: 2.4]\n",
            "1559 (5, 1) [D loss: (-26.9)(R -35.9, F 0.5, G 0.9)] [G loss: -0.8]\n",
            "1560 (5, 1) [D loss: (-25.5)(R -33.1, F 1.5, G 0.6)] [G loss: -1.3]\n",
            "1561 (5, 1) [D loss: (-26.4)(R -32.5, F -1.0, G 0.7)] [G loss: -0.5]\n",
            "1562 (5, 1) [D loss: (-26.5)(R -39.6, F 3.8, G 0.9)] [G loss: -2.2]\n",
            "1563 (5, 1) [D loss: (-25.8)(R -35.0, F 0.4, G 0.9)] [G loss: -4.5]\n",
            "1564 (5, 1) [D loss: (-25.4)(R -32.4, F -0.9, G 0.8)] [G loss: 0.8]\n",
            "1565 (5, 1) [D loss: (-26.2)(R -31.5, F -2.7, G 0.8)] [G loss: -1.7]\n",
            "1566 (5, 1) [D loss: (-25.1)(R -37.5, F -2.0, G 1.4)] [G loss: -1.3]\n",
            "1567 (5, 1) [D loss: (-25.6)(R -31.7, F -2.3, G 0.8)] [G loss: 1.7]\n",
            "1568 (5, 1) [D loss: (-26.5)(R -33.6, F 2.1, G 0.5)] [G loss: -1.8]\n",
            "1569 (5, 1) [D loss: (-27.1)(R -33.7, F -1.5, G 0.8)] [G loss: 1.6]\n",
            "1570 (5, 1) [D loss: (-26.7)(R -38.4, F 3.1, G 0.9)] [G loss: -1.6]\n",
            "1571 (5, 1) [D loss: (-26.1)(R -33.3, F 0.6, G 0.7)] [G loss: -1.2]\n",
            "1572 (5, 1) [D loss: (-26.8)(R -36.4, F 1.5, G 0.8)] [G loss: -1.3]\n",
            "1573 (5, 1) [D loss: (-26.6)(R -36.2, F 0.1, G 1.0)] [G loss: 1.3]\n",
            "1574 (5, 1) [D loss: (-25.9)(R -29.4, F -2.3, G 0.6)] [G loss: -0.1]\n",
            "1575 (5, 1) [D loss: (-26.1)(R -40.8, F 2.3, G 1.2)] [G loss: 0.8]\n",
            "1576 (5, 1) [D loss: (-26.0)(R -31.2, F -2.3, G 0.8)] [G loss: 0.3]\n",
            "1577 (5, 1) [D loss: (-26.2)(R -33.9, F 1.7, G 0.6)] [G loss: -1.9]\n",
            "1578 (5, 1) [D loss: (-26.0)(R -36.1, F -0.2, G 1.0)] [G loss: 0.2]\n",
            "1579 (5, 1) [D loss: (-25.5)(R -34.4, F 0.7, G 0.8)] [G loss: 0.0]\n",
            "1580 (5, 1) [D loss: (-26.0)(R -32.1, F 1.4, G 0.5)] [G loss: 0.8]\n",
            "1581 (5, 1) [D loss: (-26.2)(R -42.9, F 4.1, G 1.3)] [G loss: 0.8]\n",
            "1582 (5, 1) [D loss: (-26.8)(R -34.2, F 0.5, G 0.7)] [G loss: 0.9]\n",
            "1583 (5, 1) [D loss: (-27.1)(R -35.8, F 1.2, G 0.7)] [G loss: -0.6]\n",
            "1584 (5, 1) [D loss: (-26.7)(R -36.7, F 1.5, G 0.8)] [G loss: 0.4]\n",
            "1585 (5, 1) [D loss: (-26.4)(R -44.5, F 2.8, G 1.5)] [G loss: 0.0]\n",
            "1586 (5, 1) [D loss: (-25.8)(R -33.6, F -1.2, G 0.9)] [G loss: 0.7]\n",
            "1587 (5, 1) [D loss: (-27.2)(R -35.7, F 0.1, G 0.8)] [G loss: -0.0]\n",
            "1588 (5, 1) [D loss: (-25.3)(R -35.1, F 0.3, G 0.9)] [G loss: 0.7]\n",
            "1589 (5, 1) [D loss: (-26.2)(R -32.8, F 0.6, G 0.6)] [G loss: -1.3]\n",
            "1590 (5, 1) [D loss: (-26.3)(R -31.9, F -0.4, G 0.6)] [G loss: -1.5]\n",
            "1591 (5, 1) [D loss: (-26.5)(R -39.1, F 1.4, G 1.1)] [G loss: 0.2]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-23b02603c9cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;34m,\u001b[0m \u001b[0mrun_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRUN_FOLDER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n",
            "\u001b[0;32m/content/MuseGAN.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x_train, batch_size, epochs, run_folder, print_every_n_batches, n_critic, using_generator)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcritic_loops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m                 \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_critic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musing_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/MuseGAN.py\u001b[0m in \u001b[0;36mtrain_critic\u001b[0;34m(self, x_train, batch_size, using_generator)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mgroove_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_tracks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrue_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchords_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmelody_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroove_noise\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0md_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1086\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3956\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3957\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3958\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3959\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1480\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1481\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1483\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPD-9Uo42-ws",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "34700416-e9f6-4316-a1a3-305704639320"
      },
      "source": [
        "fig = plt.figure()\n",
        "plt.plot([x[0] for x in gan.d_losses], color='black', linewidth=0.25)\n",
        "\n",
        "plt.plot([x[1] for x in gan.d_losses], color='green', linewidth=0.25)\n",
        "plt.plot([x[2] for x in gan.d_losses], color='red', linewidth=0.25)\n",
        "plt.plot(gan.g_losses, color='orange', linewidth=0.25)\n",
        "\n",
        "plt.xlabel('batch', fontsize=18)\n",
        "plt.ylabel('loss', fontsize=16)\n",
        "\n",
        "plt.xlim(0, len(gan.d_losses))\n",
        "# plt.ylim(0, 2)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 409,
              "height": 269
            },
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unCW4XCRXun5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}